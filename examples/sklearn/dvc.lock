schema: '2.0'
stages:
  train:
    cmd: python -m deckard.layers.experiment train
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
        model:
          _target_: deckard.base.model.Model
          art:
            _target_: deckard.base.model.art_pipeline.ArtPipeline
            initialize:
            library: sklearn-svc
          data:
            _target_: deckard.base.data.Data
            generate:
              n_features: 20
              n_samples: 1100
              name: classification
              random_state: 0
            sample:
              random_state: 0
              stratify: true
              test_size: 1000
              train_size: 100
            sklearn_pipeline:
              preprocessor:
                name: sklearn.preprocessing.StandardScaler
                with_mean: true
                with_std: true
          init:
            C: 1.0
            _target_: deckard.base.model.ModelInitializer
            kernel: rbf
            name: sklearn.svm.SVC
            probability: true
            random_state: 0
          library: sklearn-svc
        scorers:
          _target_: deckard.base.scorer.ScorerDict
          accuracy:
            _target_: deckard.base.scorer.ScorerConfig
            direction: maximize
            name: sklearn.metrics.accuracy_score
          log_loss:
            _target_: deckard.base.scorer.ScorerConfig
            direction: minimize
            name: sklearn.metrics.log_loss
    outs:
    - path: output/data/data.pkl
      md5: 9a58fd530e1d151a5f0ac40c38cbb24a
      size: 180702
    - path: output/models/model.pkl
      md5: 03d0214bba09b1d4042b5923af1e8bcd
      size: 15402
    - path: output/reports/train/default/score_dict.json
      md5: d408e646fbad154347d891538beda08f
      size: 340
  model_optimise:
    cmd: python -m deckard.layers.optimise +stage=train +optimizers=accuracy --multirun
      --config-name model
    deps:
    - path: output/data/data.pkl
      md5: eeabc07006294278801a3906f7016b20
      size: 185102
    - path: output/models/model.pkl
      md5: 11ee9fa397238b26669489c944b361d5
      size: 15402
    params:
      conf/model.yaml:
        hydra:
          run:
            dir: ./${files.directory}
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: false
              warn_independent_sampling: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: maximize
            study_name: model
            storage: sqlite:///model.db
            n_trials: 10
            n_jobs: 1
            params:
              data.generate.n_features: 20
              data.sample.train_size: 1000
              data.sample.test_size: 100
              data.sample.random_state: 0
              data.sample.stratify: true
              model.init.kernel: rbf
              model.init.C: tag(log, int(interval(1, 1e6)))
              +model.init.max_iter: 100
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 10
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: n_jobs
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: model.db
      md5: dc51b4e61037ce5f866f9a02afde26e7
      size: 110592
  attack:
    cmd: python -m deckard.layers.experiment attack
    deps:
    - path: output/data/data.pkl
      md5: eeabc07006294278801a3906f7016b20
      size: 185102
    - path: output/models/model.pkl
      md5: 11ee9fa397238b26669489c944b361d5
      size: 15402
    params:
      params.yaml:
        attack:
          _target_: deckard.base.attack.Attack
          attack_size: 10
          data:
            _target_: deckard.base.data.Data
            generate:
              n_features: 20
              n_samples: 1100
              name: classification
              random_state: 0
            sample:
              random_state: 0
              stratify: true
              test_size: 1000
              train_size: 100
            sklearn_pipeline:
              preprocessor:
                name: sklearn.preprocessing.StandardScaler
                with_mean: true
                with_std: true
          init:
            model:
              _target_: deckard.base.model.Model
              art:
                _target_: deckard.base.model.art_pipeline.ArtPipeline
                initialize:
                library: sklearn-svc
              data:
                _target_: deckard.base.data.Data
                generate:
                  n_features: 20
                  n_samples: 1100
                  name: classification
                  random_state: 0
                sample:
                  random_state: 0
                  stratify: true
                  test_size: 1000
                  train_size: 100
                sklearn_pipeline:
                  preprocessor:
                    name: sklearn.preprocessing.StandardScaler
                    with_mean: true
                    with_std: true
              init:
                C: 1.0
                _target_: deckard.base.model.ModelInitializer
                kernel: rbf
                name: sklearn.svm.SVC
                probability: true
                random_state: 0
              library: sklearn-svc
            name: art.attacks.evasion.HopSkipJump
          method: evasion
          model:
            _target_: deckard.base.model.Model
            art:
              _target_: deckard.base.model.art_pipeline.ArtPipeline
              initialize:
              library: sklearn-svc
            data:
              _target_: deckard.base.data.Data
              generate:
                n_features: 20
                n_samples: 1100
                name: classification
                random_state: 0
              sample:
                random_state: 0
                stratify: true
                test_size: 1000
                train_size: 100
              sklearn_pipeline:
                preprocessor:
                  name: sklearn.preprocessing.StandardScaler
                  with_mean: true
                  with_std: true
            init:
              C: 1.0
              _target_: deckard.base.model.ModelInitializer
              kernel: rbf
              name: sklearn.svm.SVC
              probability: true
              random_state: 0
            library: sklearn-svc
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
        model:
          _target_: deckard.base.model.Model
          art:
            _target_: deckard.base.model.art_pipeline.ArtPipeline
            initialize:
            library: sklearn-svc
          data:
            _target_: deckard.base.data.Data
            generate:
              n_features: 20
              n_samples: 1100
              name: classification
              random_state: 0
            sample:
              random_state: 0
              stratify: true
              test_size: 1000
              train_size: 100
            sklearn_pipeline:
              preprocessor:
                name: sklearn.preprocessing.StandardScaler
                with_mean: true
                with_std: true
          init:
            C: 1.0
            _target_: deckard.base.model.ModelInitializer
            kernel: rbf
            name: sklearn.svm.SVC
            probability: true
            random_state: 0
          library: sklearn-svc
        scorers:
          _target_: deckard.base.scorer.ScorerDict
          accuracy:
            _target_: deckard.base.scorer.ScorerConfig
            direction: maximize
            name: sklearn.metrics.accuracy_score
          log_loss:
            _target_: deckard.base.scorer.ScorerConfig
            direction: minimize
            name: sklearn.metrics.log_loss
    outs:
    - path: output/reports/attack/default/adv_predictions.json
      md5: f2c857c1227f3827ce11db1464be9b63
      size: 426
    - path: output/reports/attack/default/adv_probabilities.json
      md5: f2c857c1227f3827ce11db1464be9b63
      size: 426
    - path: output/reports/attack/default/score_dict.json
      md5: 6cb818492db3f764a2df1f41a513d8f9
      size: 497
  attack_optimise:
    cmd: python -m deckard.layers.optimise +stage=attack +optimizers=adv_accuracy
      model=best --multirun --config-name attack
    deps:
    - path: conf/model/best.yaml
      md5: 8076f951bc284c87f0bbcf2ae8e159b8
      size: 656
    - path: output/data/data.pkl
      md5: eeabc07006294278801a3906f7016b20
      size: 185102
    - path: output/models/model.pkl
      md5: 11ee9fa397238b26669489c944b361d5
      size: 15402
    params:
      conf/attack.yaml:
        hydra:
          run:
            dir: ./${files.directory}
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: false
              warn_independent_sampling: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: minimize
            study_name: attack
            storage: sqlite:///attack.db
            n_trials: 3
            n_jobs: 1
            params:
              data.generate.n_features: 20
              data.sample.train_size: 1000
              data.sample.test_size: 100
              data.sample.random_state: 0
              data.sample.stratify: true
              model.init.kernel: rbf
              model.init.C: tag(log, int(interval(1, 1e6)))
              +model.init.max_iter: 100
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 10
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: n_jobs
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: attack.db
      md5: cdde21203e37d23fafd7a25750c986e9
      size: 110592
  find_best_model:
    cmd: python -m deckard.layers.find_best model.yaml
    deps:
    - path: model.db
      md5: dc51b4e61037ce5f866f9a02afde26e7
      size: 110592
    outs:
    - path: conf/model/best.yaml
      md5: 8076f951bc284c87f0bbcf2ae8e159b8
      size: 656
  find_best_attack:
    cmd: python -m deckard.layers.find_best attack.yaml
    deps:
    - path: attack.db
      md5: cdde21203e37d23fafd7a25750c986e9
      size: 110592
    outs:
    - path: conf/attack/best.yaml
      md5: 4d05c325c57569b497140f774bfd2a2e
      size: 1979
  generate_data@small:
    cmd: python -m deckard.layers.data --data_config_name small
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
    outs:
    - path: output/data/small.pkl
      md5: ea29369c6476a7a45814995cb2e4ff58
      size: 180702
  generate_data@large:
    cmd: python -m deckard.layers.data --data_config_name large
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
    outs:
    - path: output/data/large.pkl
      md5: 94221969b3f3816a14b0cb92ce8a5964
      size: 16564326
  generate_data@medium:
    cmd: python -m deckard.layers.data --data_config_name medium
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
    outs:
    - path: output/data/medium.pkl
      md5: 0ea32658bbb675057f7907091abc827c
      size: 1804313
  train_models@poly:
    cmd: python -m deckard.layers.model --model_config_name poly
    deps:
    - path: output/data/small.pkl
      md5: ea29369c6476a7a45814995cb2e4ff58
      size: 180702
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
        model:
          _target_: deckard.base.model.Model
          art:
            _target_: deckard.base.model.art_pipeline.ArtPipeline
            initialize:
            library: sklearn-svc
          data:
            _target_: deckard.base.data.Data
            generate:
              n_features: 20
              n_samples: 1100
              name: classification
              random_state: 0
            sample:
              random_state: 0
              stratify: true
              test_size: 1000
              train_size: 100
            sklearn_pipeline:
              preprocessor:
                name: sklearn.preprocessing.StandardScaler
                with_mean: true
                with_std: true
          init:
            C: 1.0
            _target_: deckard.base.model.ModelInitializer
            kernel: linear
            name: sklearn.svm.SVC
            probability: true
            random_state: 0
          library: sklearn-svc
        scorers:
          _target_: deckard.base.scorer.ScorerDict
          accuracy:
            _target_: deckard.base.scorer.ScorerConfig
            direction: maximize
            name: sklearn.metrics.accuracy_score
          log_loss:
            _target_: deckard.base.scorer.ScorerConfig
            direction: minimize
            name: sklearn.metrics.log_loss
    outs:
    - path: output/models/poly.pkl
      md5: 4c237eca49b823283ec4e8535a94aa67
      size: 17210
  generate_data@default:
    cmd: python -m deckard.layers.data --data_config_name default
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
    outs:
    - path: output/data/default.pkl
      md5: ea29369c6476a7a45814995cb2e4ff58
      size: 180702
  train_models@linear:
    cmd: python -m deckard.layers.model --model_config_name linear
    deps:
    - path: output/data/small.pkl
      md5: ea29369c6476a7a45814995cb2e4ff58
      size: 180702
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
        model:
          _target_: deckard.base.model.Model
          art:
            _target_: deckard.base.model.art_pipeline.ArtPipeline
            initialize:
            library: sklearn-svc
          data:
            _target_: deckard.base.data.Data
            generate:
              n_features: 20
              n_samples: 1100
              name: classification
              random_state: 0
            sample:
              random_state: 0
              stratify: true
              test_size: 1000
              train_size: 100
            sklearn_pipeline:
              preprocessor:
                name: sklearn.preprocessing.StandardScaler
                with_mean: true
                with_std: true
          init:
            C: 1.0
            _target_: deckard.base.model.ModelInitializer
            kernel: linear
            name: sklearn.svm.SVC
            probability: true
            random_state: 0
          library: sklearn-svc
        scorers:
          _target_: deckard.base.scorer.ScorerDict
          accuracy:
            _target_: deckard.base.scorer.ScorerConfig
            direction: maximize
            name: sklearn.metrics.accuracy_score
          log_loss:
            _target_: deckard.base.scorer.ScorerConfig
            direction: minimize
            name: sklearn.metrics.log_loss
    outs:
    - path: output/models/linear.pkl
      md5: deb853a6f81257a322c06c4beb7ede73
      size: 5319
  train_models@rbf:
    cmd: python -m deckard.layers.model --model_config_name rbf
    deps:
    - path: output/data/small.pkl
      md5: ea29369c6476a7a45814995cb2e4ff58
      size: 180702
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
        model:
          _target_: deckard.base.model.Model
          art:
            _target_: deckard.base.model.art_pipeline.ArtPipeline
            initialize:
            library: sklearn-svc
          data:
            _target_: deckard.base.data.Data
            generate:
              n_features: 20
              n_samples: 1100
              name: classification
              random_state: 0
            sample:
              random_state: 0
              stratify: true
              test_size: 1000
              train_size: 100
            sklearn_pipeline:
              preprocessor:
                name: sklearn.preprocessing.StandardScaler
                with_mean: true
                with_std: true
          init:
            C: 1.0
            _target_: deckard.base.model.ModelInitializer
            kernel: linear
            name: sklearn.svm.SVC
            probability: true
            random_state: 0
          library: sklearn-svc
        scorers:
          _target_: deckard.base.scorer.ScorerDict
          accuracy:
            _target_: deckard.base.scorer.ScorerConfig
            direction: maximize
            name: sklearn.metrics.accuracy_score
          log_loss:
            _target_: deckard.base.scorer.ScorerConfig
            direction: minimize
            name: sklearn.metrics.log_loss
    outs:
    - path: output/models/rbf.pkl
      md5: 97c5321edbc2e178dd3d6a931caf8354
      size: 15402
  data@large:
    cmd: python -m deckard.layers.data --data_config_name large
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
    outs:
    - path: output/data/large.pkl
      md5: 94221969b3f3816a14b0cb92ce8a5964
      size: 16564326
  data@small:
    cmd: python -m deckard.layers.data --data_config_name small
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
    outs:
    - path: output/data/small.pkl
      md5: ea29369c6476a7a45814995cb2e4ff58
      size: 180702
  models@poly:
    cmd: python -m deckard.layers.model --model_config_name poly  --overrides=files.data_file=small
    deps:
    - path: output/data/small.pkl
      md5: ea29369c6476a7a45814995cb2e4ff58
      size: 180702
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
        model:
          _target_: deckard.base.model.Model
          art:
            _target_: deckard.base.model.art_pipeline.ArtPipeline
            initialize:
            library: sklearn-svc
          data:
            _target_: deckard.base.data.Data
            generate:
              n_features: 20
              n_samples: 1100
              name: classification
              random_state: 0
            sample:
              random_state: 0
              stratify: true
              test_size: 1000
              train_size: 100
            sklearn_pipeline:
              preprocessor:
                name: sklearn.preprocessing.StandardScaler
                with_mean: true
                with_std: true
          init:
            C: 1.0
            _target_: deckard.base.model.ModelInitializer
            kernel: linear
            name: sklearn.svm.SVC
            probability: true
            random_state: 0
          library: sklearn-svc
    outs:
    - path: output/models/poly.pkl
      md5: 4c237eca49b823283ec4e8535a94aa67
      size: 17210
  models@linear:
    cmd: python -m deckard.layers.model --model_config_name linear  --overrides=files.data_file=small
    deps:
    - path: output/data/small.pkl
      md5: ea29369c6476a7a45814995cb2e4ff58
      size: 180702
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
        model:
          _target_: deckard.base.model.Model
          art:
            _target_: deckard.base.model.art_pipeline.ArtPipeline
            initialize:
            library: sklearn-svc
          data:
            _target_: deckard.base.data.Data
            generate:
              n_features: 20
              n_samples: 1100
              name: classification
              random_state: 0
            sample:
              random_state: 0
              stratify: true
              test_size: 1000
              train_size: 100
            sklearn_pipeline:
              preprocessor:
                name: sklearn.preprocessing.StandardScaler
                with_mean: true
                with_std: true
          init:
            C: 1.0
            _target_: deckard.base.model.ModelInitializer
            kernel: linear
            name: sklearn.svm.SVC
            probability: true
            random_state: 0
          library: sklearn-svc
    outs:
    - path: output/models/linear.pkl
      md5: deb853a6f81257a322c06c4beb7ede73
      size: 5319
  models@rbf:
    cmd: python -m deckard.layers.model --model_config_name rbf  --overrides=files.data_file=small
    deps:
    - path: output/data/small.pkl
      md5: ea29369c6476a7a45814995cb2e4ff58
      size: 180702
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
        model:
          _target_: deckard.base.model.Model
          art:
            _target_: deckard.base.model.art_pipeline.ArtPipeline
            initialize:
            library: sklearn-svc
          data:
            _target_: deckard.base.data.Data
            generate:
              n_features: 20
              n_samples: 1100
              name: classification
              random_state: 0
            sample:
              random_state: 0
              stratify: true
              test_size: 1000
              train_size: 100
            sklearn_pipeline:
              preprocessor:
                name: sklearn.preprocessing.StandardScaler
                with_mean: true
                with_std: true
          init:
            C: 1.0
            _target_: deckard.base.model.ModelInitializer
            kernel: linear
            name: sklearn.svm.SVC
            probability: true
            random_state: 0
          library: sklearn-svc
    outs:
    - path: output/models/rbf.pkl
      md5: 97c5321edbc2e178dd3d6a931caf8354
      size: 15402
  data@medium:
    cmd: python -m deckard.layers.data --data_config_name medium
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
    outs:
    - path: output/data/medium.pkl
      md5: 0ea32658bbb675057f7907091abc827c
      size: 1804313
  model_search:
    cmd: bash models.sh model=best +stage=train +optimizers=accuracy ++hydra.sweeper.storage=sqlite:///model_grid.db
      ++hydra.sweeper.study_name=model ++hydra.sweeper.direction=maximize ++direction=maximize  --multirun
      --config-name model.yaml
    deps:
    - path: conf/model/best.yaml
      md5: 8076f951bc284c87f0bbcf2ae8e159b8
      size: 656
    outs:
    - path: model_grid.db
      md5: bf2120ffcdb84e926fdee3194258ae7a
      size: 159744
  attack_search:
    cmd: bash attacks.sh model=best ++stage=attack ++optimizers=adv_accuracy ++hydra.sweeper.storage=sqlite:///attack_grid.db
      ++hydra.sweeper.study_name=attack ++hydra.sweeper.direction=minimize ++direction=minimize
      ++attack.init.max_iter=10  --multirun --config-name attack.yaml
    deps:
    - path: conf/model/best.yaml
      md5: 8076f951bc284c87f0bbcf2ae8e159b8
      size: 656
    - path: model_grid.db
      md5: bf2120ffcdb84e926fdee3194258ae7a
      size: 159744
    outs:
    - path: attack_grid.db
      md5: f3ee3cda113eb52922552c8fe975898b
      size: 323584
