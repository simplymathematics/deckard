schema: '2.0'
stages:
  train:
    cmd: python -m deckard.layers.experiment train
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
        model:
          _target_: deckard.base.model.Model
          art:
            _target_: deckard.base.model.art_pipeline.ArtPipeline
            initialize:
            library: sklearn-svc
          data:
            _target_: deckard.base.data.Data
            generate:
              n_features: 20
              n_samples: 1100
              name: classification
              random_state: 0
            sample:
              random_state: 0
              stratify: true
              test_size: 1000
              train_size: 100
            sklearn_pipeline:
              preprocessor:
                name: sklearn.preprocessing.StandardScaler
                with_mean: true
                with_std: true
          init:
            C: 1.0
            _target_: deckard.base.model.ModelInitializer
            kernel: rbf
            name: sklearn.svm.SVC
            probability: true
            random_state: 0
          library: sklearn-svc
        scorers:
          _target_: deckard.base.scorer.ScorerDict
          accuracy:
            _target_: deckard.base.scorer.ScorerConfig
            direction: maximize
            name: sklearn.metrics.accuracy_score
          log_loss:
            _target_: deckard.base.scorer.ScorerConfig
            direction: minimize
            name: sklearn.metrics.log_loss
    outs:
    - path: output/data/data.pkl
      md5: ea29369c6476a7a45814995cb2e4ff58
      size: 180702
    - path: output/models/model.pkl
      md5: 97c5321edbc2e178dd3d6a931caf8354
      size: 15402
    - path: output/reports/train/default/predictions.json
      md5: ee673f125eb8878721afc412badf4483
      size: 43249
    - path: output/reports/train/default/probabilities.json
      md5: ee673f125eb8878721afc412badf4483
      size: 43249
    - path: output/reports/train/default/score_dict.json
      md5: 7bb19b5630473dadc47f94b515de1dc5
      size: 315
    - path: output/reports/train/default/test_labels.json
      md5: 8b08830bcf914dc948fc4b2ecf3ce5aa
      size: 3000
    - path: output/reports/train/default/train_labels.json
      md5: 8e93c1a7db21ebb97ce6e4ed58809240
      size: 300
  model_optimise:
    cmd: python -m deckard.layers.optimise +stage=train +optimizers=accuracy --multirun
      --config-name model
    deps:
    - path: output/data/data.pkl
      md5: ea29369c6476a7a45814995cb2e4ff58
      size: 180702
    - path: output/models/model.pkl
      md5: ca55c4c533fa0d399bdfb53a282927f9
      size: 15436
    params:
      conf/model.yaml:
        hydra:
          run:
            dir: ./${files.directory}
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: false
              warn_independent_sampling: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: maximize
            study_name: model
            storage: sqlite:///model.db
            n_trials: 10
            n_jobs: 1
            params:
              data.generate.n_features: 20
              data.sample.train_size: 1000
              data.sample.test_size: 100
              data.sample.random_state: 0
              data.sample.stratify: true
              model.init.kernel: rbf
              model.init.C: tag(log, int(interval(1, 1e6)))
              +model.init.max_iter: 100
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 10
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: n_jobs
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: model.db
      md5: c9a878900767813ccb60bc755886c9f4
      size: 110592
  attack:
    cmd: python -m deckard.layers.experiment attack
    deps:
    - path: output/data/data.pkl
      md5: ea29369c6476a7a45814995cb2e4ff58
      size: 180702
    - path: output/models/model.pkl
      md5: ca55c4c533fa0d399bdfb53a282927f9
      size: 15436
    params:
      params.yaml:
        attack:
          _target_: deckard.base.attack.Attack
          attack_size: 10
          data:
            _target_: deckard.base.data.Data
            generate:
              n_features: 20
              n_samples: 1100
              name: classification
              random_state: 0
            sample:
              random_state: 0
              stratify: true
              test_size: 1000
              train_size: 100
            sklearn_pipeline:
              preprocessor:
                name: sklearn.preprocessing.StandardScaler
                with_mean: true
                with_std: true
          init:
            model:
              _target_: deckard.base.model.Model
              art:
                _target_: deckard.base.model.art_pipeline.ArtPipeline
                initialize:
                library: sklearn-svc
              data:
                _target_: deckard.base.data.Data
                generate:
                  n_features: 20
                  n_samples: 1100
                  name: classification
                  random_state: 0
                sample:
                  random_state: 0
                  stratify: true
                  test_size: 1000
                  train_size: 100
                sklearn_pipeline:
                  preprocessor:
                    name: sklearn.preprocessing.StandardScaler
                    with_mean: true
                    with_std: true
              init:
                C: 1.0
                _target_: deckard.base.model.ModelInitializer
                kernel: rbf
                name: sklearn.svm.SVC
                probability: true
                random_state: 0
              library: sklearn-svc
            name: art.attacks.evasion.HopSkipJump
          method: evasion
          model:
            _target_: deckard.base.model.Model
            art:
              _target_: deckard.base.model.art_pipeline.ArtPipeline
              initialize:
              library: sklearn-svc
            data:
              _target_: deckard.base.data.Data
              generate:
                n_features: 20
                n_samples: 1100
                name: classification
                random_state: 0
              sample:
                random_state: 0
                stratify: true
                test_size: 1000
                train_size: 100
              sklearn_pipeline:
                preprocessor:
                  name: sklearn.preprocessing.StandardScaler
                  with_mean: true
                  with_std: true
            init:
              C: 1.0
              _target_: deckard.base.model.ModelInitializer
              kernel: rbf
              name: sklearn.svm.SVC
              probability: true
              random_state: 0
            library: sklearn-svc
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
        model:
          _target_: deckard.base.model.Model
          art:
            _target_: deckard.base.model.art_pipeline.ArtPipeline
            initialize:
            library: sklearn-svc
          data:
            _target_: deckard.base.data.Data
            generate:
              n_features: 20
              n_samples: 1100
              name: classification
              random_state: 0
            sample:
              random_state: 0
              stratify: true
              test_size: 1000
              train_size: 100
            sklearn_pipeline:
              preprocessor:
                name: sklearn.preprocessing.StandardScaler
                with_mean: true
                with_std: true
          init:
            C: 1.0
            _target_: deckard.base.model.ModelInitializer
            kernel: rbf
            name: sklearn.svm.SVC
            probability: true
            random_state: 0
          library: sklearn-svc
        scorers:
          _target_: deckard.base.scorer.ScorerDict
          accuracy:
            _target_: deckard.base.scorer.ScorerConfig
            direction: maximize
            name: sklearn.metrics.accuracy_score
          log_loss:
            _target_: deckard.base.scorer.ScorerConfig
            direction: minimize
            name: sklearn.metrics.log_loss
    outs:
    - path: output/reports/attack/default/adv_predictions.json
      md5: ce53463d2dc0ff7c5df246b449ae053f
      size: 424
    - path: output/reports/attack/default/adv_probabilities.json
      md5: ce53463d2dc0ff7c5df246b449ae053f
      size: 424
    - path: output/reports/attack/default/score_dict.json
      md5: 246efdce5c31c3a610f53e6b950f0bd4
      size: 448
  attack_optimise:
    cmd: python -m deckard.layers.optimise +stage=attack +optimizers=adv_accuracy
      model=best --multirun --config-name attack
    deps:
    - path: conf/model/best.yaml
      md5: c18e5944789ca22898f538f001f9d158
      size: 683
    - path: output/data/data.pkl
      md5: ea29369c6476a7a45814995cb2e4ff58
      size: 180702
    - path: output/models/model.pkl
      md5: ca55c4c533fa0d399bdfb53a282927f9
      size: 15436
    params:
      conf/attack.yaml:
        hydra:
          run:
            dir: ./${files.directory}
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: false
              warn_independent_sampling: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: minimize
            study_name: attack
            storage: sqlite:///attack.db
            n_trials: 3
            n_jobs: 1
            params:
              data.generate.n_features: 20
              data.sample.train_size: 1000
              data.sample.test_size: 100
              data.sample.random_state: 0
              data.sample.stratify: true
              model.init.kernel: rbf
              model.init.C: tag(log, int(interval(1, 1e6)))
              +model.init.max_iter: 100
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 10
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: n_jobs
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: attack.db
      md5: 79312bc2bae4f5902833eb3e85ee95f4
      size: 110592
  find_best_model:
    cmd: python -m deckard.layers.find_best model.yaml
    deps:
    - path: model.db
      md5: c9a878900767813ccb60bc755886c9f4
      size: 110592
    outs:
    - path: conf/model/best.yaml
      md5: c18e5944789ca22898f538f001f9d158
      size: 683
  find_best_attack:
    cmd: python -m deckard.layers.find_best attack.yaml
    deps:
    - path: attack.db
      md5: 79312bc2bae4f5902833eb3e85ee95f4
      size: 110592
    outs:
    - path: conf/attack/best.yaml
      md5: f0518e891f88fe02086e02a0e0f9e8b9
      size: 2057
  generate_data@small:
    cmd: python -m deckard.layers.data --data_config_name small
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
    outs:
    - path: output/data/small.pkl
      md5: ea29369c6476a7a45814995cb2e4ff58
      size: 180702
  generate_data@large:
    cmd: python -m deckard.layers.data --data_config_name large
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
    outs:
    - path: output/data/large.pkl
      md5: 94221969b3f3816a14b0cb92ce8a5964
      size: 16564326
  generate_data@medium:
    cmd: python -m deckard.layers.data --data_config_name medium
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
    outs:
    - path: output/data/medium.pkl
      md5: 0ea32658bbb675057f7907091abc827c
      size: 1804313
  train_models@poly:
    cmd: python -m deckard.layers.model --model_config_name poly
    deps:
    - path: output/data/small.pkl
      md5: ea29369c6476a7a45814995cb2e4ff58
      size: 180702
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
        model:
          _target_: deckard.base.model.Model
          art:
            _target_: deckard.base.model.art_pipeline.ArtPipeline
            initialize:
            library: sklearn-svc
          data:
            _target_: deckard.base.data.Data
            generate:
              n_features: 20
              n_samples: 1100
              name: classification
              random_state: 0
            sample:
              random_state: 0
              stratify: true
              test_size: 1000
              train_size: 100
            sklearn_pipeline:
              preprocessor:
                name: sklearn.preprocessing.StandardScaler
                with_mean: true
                with_std: true
          init:
            C: 1.0
            _target_: deckard.base.model.ModelInitializer
            kernel: linear
            name: sklearn.svm.SVC
            probability: true
            random_state: 0
          library: sklearn-svc
        scorers:
          _target_: deckard.base.scorer.ScorerDict
          accuracy:
            _target_: deckard.base.scorer.ScorerConfig
            direction: maximize
            name: sklearn.metrics.accuracy_score
          log_loss:
            _target_: deckard.base.scorer.ScorerConfig
            direction: minimize
            name: sklearn.metrics.log_loss
    outs:
    - path: output/models/poly.pkl
      md5: 4c237eca49b823283ec4e8535a94aa67
      size: 17210
  generate_data@default:
    cmd: python -m deckard.layers.data --data_config_name default
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
    outs:
    - path: output/data/default.pkl
      md5: ea29369c6476a7a45814995cb2e4ff58
      size: 180702
  train_models@linear:
    cmd: python -m deckard.layers.model --model_config_name linear
    deps:
    - path: output/data/small.pkl
      md5: ea29369c6476a7a45814995cb2e4ff58
      size: 180702
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
        model:
          _target_: deckard.base.model.Model
          art:
            _target_: deckard.base.model.art_pipeline.ArtPipeline
            initialize:
            library: sklearn-svc
          data:
            _target_: deckard.base.data.Data
            generate:
              n_features: 20
              n_samples: 1100
              name: classification
              random_state: 0
            sample:
              random_state: 0
              stratify: true
              test_size: 1000
              train_size: 100
            sklearn_pipeline:
              preprocessor:
                name: sklearn.preprocessing.StandardScaler
                with_mean: true
                with_std: true
          init:
            C: 1.0
            _target_: deckard.base.model.ModelInitializer
            kernel: linear
            name: sklearn.svm.SVC
            probability: true
            random_state: 0
          library: sklearn-svc
        scorers:
          _target_: deckard.base.scorer.ScorerDict
          accuracy:
            _target_: deckard.base.scorer.ScorerConfig
            direction: maximize
            name: sklearn.metrics.accuracy_score
          log_loss:
            _target_: deckard.base.scorer.ScorerConfig
            direction: minimize
            name: sklearn.metrics.log_loss
    outs:
    - path: output/models/linear.pkl
      md5: deb853a6f81257a322c06c4beb7ede73
      size: 5319
  train_models@rbf:
    cmd: python -m deckard.layers.model --model_config_name rbf
    deps:
    - path: output/data/small.pkl
      md5: ea29369c6476a7a45814995cb2e4ff58
      size: 180702
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
        model:
          _target_: deckard.base.model.Model
          art:
            _target_: deckard.base.model.art_pipeline.ArtPipeline
            initialize:
            library: sklearn-svc
          data:
            _target_: deckard.base.data.Data
            generate:
              n_features: 20
              n_samples: 1100
              name: classification
              random_state: 0
            sample:
              random_state: 0
              stratify: true
              test_size: 1000
              train_size: 100
            sklearn_pipeline:
              preprocessor:
                name: sklearn.preprocessing.StandardScaler
                with_mean: true
                with_std: true
          init:
            C: 1.0
            _target_: deckard.base.model.ModelInitializer
            kernel: linear
            name: sklearn.svm.SVC
            probability: true
            random_state: 0
          library: sklearn-svc
        scorers:
          _target_: deckard.base.scorer.ScorerDict
          accuracy:
            _target_: deckard.base.scorer.ScorerConfig
            direction: maximize
            name: sklearn.metrics.accuracy_score
          log_loss:
            _target_: deckard.base.scorer.ScorerConfig
            direction: minimize
            name: sklearn.metrics.log_loss
    outs:
    - path: output/models/rbf.pkl
      md5: 97c5321edbc2e178dd3d6a931caf8354
      size: 15402
  data@large:
    cmd: python -m deckard.layers.data --data_config_name large
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
    outs:
    - path: output/data/large.pkl
      md5: 94221969b3f3816a14b0cb92ce8a5964
      size: 16564326
  data@small:
    cmd: python -m deckard.layers.data --data_config_name small
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
    outs:
    - path: output/data/small.pkl
      md5: ea29369c6476a7a45814995cb2e4ff58
      size: 180702
  models@poly:
    cmd: python -m deckard.layers.model --model_config_name poly  --overrides=files.data_file=small
    deps:
    - path: output/data/small.pkl
      md5: ea29369c6476a7a45814995cb2e4ff58
      size: 180702
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
        model:
          _target_: deckard.base.model.Model
          art:
            _target_: deckard.base.model.art_pipeline.ArtPipeline
            initialize:
            library: sklearn-svc
          data:
            _target_: deckard.base.data.Data
            generate:
              n_features: 20
              n_samples: 1100
              name: classification
              random_state: 0
            sample:
              random_state: 0
              stratify: true
              test_size: 1000
              train_size: 100
            sklearn_pipeline:
              preprocessor:
                name: sklearn.preprocessing.StandardScaler
                with_mean: true
                with_std: true
          init:
            C: 1.0
            _target_: deckard.base.model.ModelInitializer
            kernel: linear
            name: sklearn.svm.SVC
            probability: true
            random_state: 0
          library: sklearn-svc
    outs:
    - path: output/models/poly.pkl
      md5: 4c237eca49b823283ec4e8535a94aa67
      size: 17210
  models@linear:
    cmd: python -m deckard.layers.model --model_config_name linear  --overrides=files.data_file=small
    deps:
    - path: output/data/small.pkl
      md5: ea29369c6476a7a45814995cb2e4ff58
      size: 180702
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
        model:
          _target_: deckard.base.model.Model
          art:
            _target_: deckard.base.model.art_pipeline.ArtPipeline
            initialize:
            library: sklearn-svc
          data:
            _target_: deckard.base.data.Data
            generate:
              n_features: 20
              n_samples: 1100
              name: classification
              random_state: 0
            sample:
              random_state: 0
              stratify: true
              test_size: 1000
              train_size: 100
            sklearn_pipeline:
              preprocessor:
                name: sklearn.preprocessing.StandardScaler
                with_mean: true
                with_std: true
          init:
            C: 1.0
            _target_: deckard.base.model.ModelInitializer
            kernel: linear
            name: sklearn.svm.SVC
            probability: true
            random_state: 0
          library: sklearn-svc
    outs:
    - path: output/models/linear.pkl
      md5: deb853a6f81257a322c06c4beb7ede73
      size: 5319
  models@rbf:
    cmd: python -m deckard.layers.model --model_config_name rbf  --overrides=files.data_file=small
    deps:
    - path: output/data/small.pkl
      md5: ea29369c6476a7a45814995cb2e4ff58
      size: 180702
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
        model:
          _target_: deckard.base.model.Model
          art:
            _target_: deckard.base.model.art_pipeline.ArtPipeline
            initialize:
            library: sklearn-svc
          data:
            _target_: deckard.base.data.Data
            generate:
              n_features: 20
              n_samples: 1100
              name: classification
              random_state: 0
            sample:
              random_state: 0
              stratify: true
              test_size: 1000
              train_size: 100
            sklearn_pipeline:
              preprocessor:
                name: sklearn.preprocessing.StandardScaler
                with_mean: true
                with_std: true
          init:
            C: 1.0
            _target_: deckard.base.model.ModelInitializer
            kernel: linear
            name: sklearn.svm.SVC
            probability: true
            random_state: 0
          library: sklearn-svc
    outs:
    - path: output/models/rbf.pkl
      md5: 97c5321edbc2e178dd3d6a931caf8354
      size: 15402
  data@medium:
    cmd: python -m deckard.layers.data --data_config_name medium
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          generate:
            n_features: 20
            n_samples: 1100
            name: classification
            random_state: 0
          sample:
            random_state: 0
            stratify: true
            test_size: 1000
            train_size: 100
          sklearn_pipeline:
            preprocessor:
              name: sklearn.preprocessing.StandardScaler
              with_mean: true
              with_std: true
        files:
          _target_: deckard.base.files.FileConfig
          adv_predictions_file: adv_predictions.json
          adv_probabilities_file: adv_probabilities.json
          attack_dir: attacks
          attack_file: attack
          attack_type: .pkl
          data_dir: data
          data_file: data
          data_type: .pkl
          directory: output
          model_dir: models
          model_file: model
          model_type: .pkl
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          probabilities_file: probabilities.json
          reports: reports
          score_dict_file: score_dict.json
          test_labels_file: test_labels.json
          train_labels_file: train_labels.json
    outs:
    - path: output/data/medium.pkl
      md5: 0ea32658bbb675057f7907091abc827c
      size: 1804313
