schema: '2.0'
stages:
  clean@sms_spam-gzip_knn:
    cmd: python -m deckard.layers.clean_data  -i sms_spam/reports/gzip_knn.csv -o
      sms_spam/plots/clean/gzip_knn.csv -c conf/clean.yaml
    deps:
    - path: sms_spam/reports/gzip_knn.csv
      hash: md5
      md5: 4a17855f53d2f84e70a495d058b01899
      size: 646870
    params:
      conf/clean.yaml:
        drop_values:
          accuracy: 0.0
          predict_time: 1.0
        replace:
          model.init.metric:
            jaro: Jaro
            _winkler: -Winkler
            levenshtein: Levenshtein
            ncd: NCD
            ratio: Ratio
            seqRatio: SeqRatio
            hamming: Hamming
            gzip: GZIP
            pkl: Pickle
            bz2: BZ2
            zstd: ZSTD
            lzma: LZMA
          model_name:
            GzipSVC: k-SVC
            GzipLogisticRegressor: k-Logistic
            GzipKNN: k-KNN
          model.init.symmetric:
            true: Symmetric
            false: Asymmetric
          model.init.sampling_method:
            random: Random
            medoid: Medoid
            sum: Sum
            svc: SVC
            hardness: Hardness
            nearmiss: NearMiss
            knn: KNN
          dataset:
            ddos: DDoS
            sms_spam: SMS Spam
            kdd_nsl: KDD NSL
            truthseeker: Truthseeker
          model.init.m:
            -1: 1
        replace_cols:
          dataset: Dataset
          model.init.metric: Metric
          model.init.symmetric: Symmetric
          model.init.sampling_method: Condensing Method
          model.init.m: Condensing Ratio
          model_name: Model
    outs:
    - path: sms_spam/plots/clean/gzip_knn.csv
      hash: md5
      md5: 7fb07e1f2c79d4353326b37c8a591ed2
      size: 450012
  clean@sms_spam-gzip_svc:
    cmd: python -m deckard.layers.clean_data  -i sms_spam/reports/gzip_svc.csv -o
      sms_spam/plots/clean/gzip_svc.csv -c conf/clean.yaml
    deps:
    - path: sms_spam/reports/gzip_svc.csv
      hash: md5
      md5: c05548df9f102f92361afa9b7476fdff
      size: 1350809
    params:
      conf/clean.yaml:
        drop_values:
          accuracy: 0.0
          predict_time: 1.0
        replace:
          model.init.metric:
            jaro: Jaro
            _winkler: -Winkler
            levenshtein: Levenshtein
            ncd: NCD
            ratio: Ratio
            seqRatio: SeqRatio
            hamming: Hamming
            gzip: GZIP
            pkl: Pickle
            bz2: BZ2
            zstd: ZSTD
            lzma: LZMA
          model_name:
            GzipSVC: k-SVC
            GzipLogisticRegressor: k-Logistic
            GzipKNN: k-KNN
          model.init.symmetric:
            true: Symmetric
            false: Asymmetric
          model.init.sampling_method:
            random: Random
            medoid: Medoid
            sum: Sum
            svc: SVC
            hardness: Hardness
            nearmiss: NearMiss
            knn: KNN
          dataset:
            ddos: DDoS
            sms_spam: SMS Spam
            kdd_nsl: KDD NSL
            truthseeker: Truthseeker
          model.init.m:
            -1: 1
        replace_cols:
          dataset: Dataset
          model.init.metric: Metric
          model.init.symmetric: Symmetric
          model.init.sampling_method: Condensing Method
          model.init.m: Condensing Ratio
          model_name: Model
    outs:
    - path: sms_spam/plots/clean/gzip_svc.csv
      hash: md5
      md5: 125fbea3e6d8e7926e64c8bd5222bc9c
      size: 1100044
  clean@sms_spam-gzip_logistic:
    cmd: python -m deckard.layers.clean_data  -i sms_spam/reports/gzip_logistic.csv
      -o sms_spam/plots/clean/gzip_logistic.csv -c conf/clean.yaml
    deps:
    - path: sms_spam/reports/gzip_logistic.csv
      hash: md5
      md5: 6776a26690c4f3d00775f6e99eac99d0
      size: 1250342
    params:
      conf/clean.yaml:
        drop_values:
          accuracy: 0.0
          predict_time: 1.0
        replace:
          model.init.metric:
            jaro: Jaro
            _winkler: -Winkler
            levenshtein: Levenshtein
            ncd: NCD
            ratio: Ratio
            seqRatio: SeqRatio
            hamming: Hamming
            gzip: GZIP
            pkl: Pickle
            bz2: BZ2
            zstd: ZSTD
            lzma: LZMA
          model_name:
            GzipSVC: k-SVC
            GzipLogisticRegressor: k-Logistic
            GzipKNN: k-KNN
          model.init.symmetric:
            true: Symmetric
            false: Asymmetric
          model.init.sampling_method:
            random: Random
            medoid: Medoid
            sum: Sum
            svc: SVC
            hardness: Hardness
            nearmiss: NearMiss
            knn: KNN
          dataset:
            ddos: DDoS
            sms_spam: SMS Spam
            kdd_nsl: KDD NSL
            truthseeker: Truthseeker
          model.init.m:
            -1: 1
        replace_cols:
          dataset: Dataset
          model.init.metric: Metric
          model.init.symmetric: Symmetric
          model.init.sampling_method: Condensing Method
          model.init.m: Condensing Ratio
          model_name: Model
    outs:
    - path: sms_spam/plots/clean/gzip_logistic.csv
      hash: md5
      md5: f29eb4d1d0e58a00616bf2c73acd35cd
      size: 566135
  clean@sms_spam-condense/knn:
    cmd: python -m deckard.layers.clean_data  -i sms_spam/reports/condense/knn.csv
      -o sms_spam/plots/clean/condense/knn.csv -c conf/clean.yaml
    deps:
    - path: sms_spam/reports/condense/knn.csv
      hash: md5
      md5: 5e322d2d99e5491cd40efb76cb576d15
      size: 1141722
    params:
      conf/clean.yaml:
        drop_values:
          accuracy: 0.0
          predict_time: 1.0
        replace:
          model.init.metric:
            jaro: Jaro
            _winkler: -Winkler
            levenshtein: Levenshtein
            ncd: NCD
            ratio: Ratio
            seqRatio: SeqRatio
            hamming: Hamming
            gzip: GZIP
            pkl: Pickle
            bz2: BZ2
            zstd: ZSTD
            lzma: LZMA
          model_name:
            GzipSVC: k-SVC
            GzipLogisticRegressor: k-Logistic
            GzipKNN: k-KNN
          model.init.symmetric:
            true: Symmetric
            false: Asymmetric
          model.init.sampling_method:
            random: Random
            medoid: Medoid
            sum: Sum
            svc: SVC
            hardness: Hardness
            nearmiss: NearMiss
            knn: KNN
          dataset:
            ddos: DDoS
            sms_spam: SMS Spam
            kdd_nsl: KDD NSL
            truthseeker: Truthseeker
          model.init.m:
            -1: 1
        replace_cols:
          dataset: Dataset
          model.init.metric: Metric
          model.init.symmetric: Symmetric
          model.init.sampling_method: Condensing Method
          model.init.m: Condensing Ratio
          model_name: Model
    outs:
    - path: sms_spam/plots/clean/condense/knn.csv
      hash: md5
      md5: 7fe49a083334810ebee6fe42646ce8bb
      size: 841832
  clean@sms_spam-condense/svc:
    cmd: python -m deckard.layers.clean_data  -i sms_spam/reports/condense/svc.csv
      -o sms_spam/plots/clean/condense/svc.csv -c conf/clean.yaml
    deps:
    - path: sms_spam/reports/condense/svc.csv
      hash: md5
      md5: 5ead82ad572519728e9f571b7120ef21
      size: 1397197
    params:
      conf/clean.yaml:
        drop_values:
          accuracy: 0.0
          predict_time: 1.0
        replace:
          model.init.metric:
            jaro: Jaro
            _winkler: -Winkler
            levenshtein: Levenshtein
            ncd: NCD
            ratio: Ratio
            seqRatio: SeqRatio
            hamming: Hamming
            gzip: GZIP
            pkl: Pickle
            bz2: BZ2
            zstd: ZSTD
            lzma: LZMA
          model_name:
            GzipSVC: k-SVC
            GzipLogisticRegressor: k-Logistic
            GzipKNN: k-KNN
          model.init.symmetric:
            true: Symmetric
            false: Asymmetric
          model.init.sampling_method:
            random: Random
            medoid: Medoid
            sum: Sum
            svc: SVC
            hardness: Hardness
            nearmiss: NearMiss
            knn: KNN
          dataset:
            ddos: DDoS
            sms_spam: SMS Spam
            kdd_nsl: KDD NSL
            truthseeker: Truthseeker
          model.init.m:
            -1: 1
        replace_cols:
          dataset: Dataset
          model.init.metric: Metric
          model.init.symmetric: Symmetric
          model.init.sampling_method: Condensing Method
          model.init.m: Condensing Ratio
          model_name: Model
    outs:
    - path: sms_spam/plots/clean/condense/svc.csv
      hash: md5
      md5: d46389196ac13d9242c8cf1dc11cb574
      size: 1099972
  clean@sms_spam-condense/logistic:
    cmd: python -m deckard.layers.clean_data  -i sms_spam/reports/condense/logistic.csv
      -o sms_spam/plots/clean/condense/logistic.csv -c conf/clean.yaml
    deps:
    - path: sms_spam/reports/condense/logistic.csv
      hash: md5
      md5: 53489828bf0d55ab22d5dba310488dd8
      size: 1047981
    params:
      conf/clean.yaml:
        drop_values:
          accuracy: 0.0
          predict_time: 1.0
        replace:
          model.init.metric:
            jaro: Jaro
            _winkler: -Winkler
            levenshtein: Levenshtein
            ncd: NCD
            ratio: Ratio
            seqRatio: SeqRatio
            hamming: Hamming
            gzip: GZIP
            pkl: Pickle
            bz2: BZ2
            zstd: ZSTD
            lzma: LZMA
          model_name:
            GzipSVC: k-SVC
            GzipLogisticRegressor: k-Logistic
            GzipKNN: k-KNN
          model.init.symmetric:
            true: Symmetric
            false: Asymmetric
          model.init.sampling_method:
            random: Random
            medoid: Medoid
            sum: Sum
            svc: SVC
            hardness: Hardness
            nearmiss: NearMiss
            knn: KNN
          dataset:
            ddos: DDoS
            sms_spam: SMS Spam
            kdd_nsl: KDD NSL
            truthseeker: Truthseeker
          model.init.m:
            -1: 1
        replace_cols:
          dataset: Dataset
          model.init.metric: Metric
          model.init.symmetric: Symmetric
          model.init.sampling_method: Condensing Method
          model.init.m: Condensing Ratio
          model_name: Model
    outs:
    - path: sms_spam/plots/clean/condense/logistic.csv
      hash: md5
      md5: 2233af9bf8eaf5c2e21468c66a49faa2
      size: 345334
  merge@sms_spam:
    cmd: python merge.py --big_dir sms_spam/plots/ --data_file clean/gzip_knn.csv
      --little_dir_data_file clean/gzip_logistic.csv clean/gzip_svc.csv --output_folder
      sms_spam/plots --output_file merged.csv
    deps:
    - path: sms_spam/plots/clean/gzip_knn.csv
      hash: md5
      md5: 7fb07e1f2c79d4353326b37c8a591ed2
      size: 450012
    - path: sms_spam/plots/clean/gzip_logistic.csv
      hash: md5
      md5: f29eb4d1d0e58a00616bf2c73acd35cd
      size: 566135
    - path: sms_spam/plots/clean/gzip_svc.csv
      hash: md5
      md5: 125fbea3e6d8e7926e64c8bd5222bc9c
      size: 1100044
    outs:
    - path: sms_spam/plots/merged.csv
      hash: md5
      md5: dcfec316b2e65a718c817f7855047ce8
      size: 2136730
  merge_condense@sms_spam:
    cmd: python merge.py --big_dir sms_spam/plots/ --data_file clean/condense/knn.csv
      --little_dir_data_file  clean/condense/logistic.csv clean/condense/svc.csv --output_folder
      sms_spam/plots/ --output_file condensed_merged.csv
    deps:
    - path: sms_spam/plots/clean/condense/knn.csv
      hash: md5
      md5: 7fe49a083334810ebee6fe42646ce8bb
      size: 841832
    - path: sms_spam/plots/clean/condense/logistic.csv
      hash: md5
      md5: 2233af9bf8eaf5c2e21468c66a49faa2
      size: 345334
    - path: sms_spam/plots/clean/condense/svc.csv
      hash: md5
      md5: d46389196ac13d9242c8cf1dc11cb574
      size: 1099972
    outs:
    - path: sms_spam/plots/condensed_merged.csv
      hash: md5
      md5: 4d9c5958bce75ed7e10e913c4ceaf608
      size: 2310272
  plot@sms_spam:
    cmd: python -m deckard.layers.plots  --path sms_spam/plots/  --file sms_spam/plots/merged.csv  -c
      conf/plots.yaml
    deps:
    - path: conf/plots.yaml
      hash: md5
      md5: 43e3ec0876b55c83f231615f7a904e33
      size: 7386
    - path: sms_spam/plots/merged.csv
      hash: md5
      md5: dcfec316b2e65a718c817f7855047ce8
      size: 2136730
    params:
      conf/plots.yaml:
        cat_plot:
        - file: symmetric_vs_compressor_metric.pdf
          x: Metric
          y: accuracy
          hue: Symmetric
          errorbar: se
          kind: boxen
          titles: ' '
          xlabels: Compressor
          ylabels: Accuracy
          legend_title: Metrics
          order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          hue_order:
          - Asymmetric
          - Symmetric
          rotation: 90
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: symmetric_vs_string_metric.pdf
          x: Metric
          y: accuracy
          hue: Symmetric
          errorbar: se
          kind: boxen
          titles: ' '
          xlabels: Compressors
          ylabels: Accuracy
          legend_title: ' '
          order:
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          hue_order:
          - Asymmetric
          - Symmetric
          rotation: 90
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: symmetric_vs_metric.pdf
          x: Metric
          y: accuracy
          hue: Symmetric
          errorbar: se
          kind: boxen
          titles: ' '
          xlabels: Compressors
          ylabels: Accuracy
          legend_title: ' '
          order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          hue_order:
          - Asymmetric
          - Symmetric
          rotation: 90
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: symmetric_vs_metric_train_time.pdf
          x: Metric
          y: train_time
          hue: Symmetric
          errorbar: se
          kind: boxen
          titles:
          xlabels: Metrics
          ylabels: Training Time (s)
          legend_title: Metrics
          order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          hue_order:
          - Asymmetric
          - Symmetric
          rotation: 90
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
          y_scale: linear
        - file: symmetric_vs_string_metric_train_time.pdf
          x: Metric
          y: train_time
          hue: Symmetric
          errorbar: se
          kind: boxen
          titles:
          xlabels: Compressors
          ylabels: Training Time (s)
          legend_title: String Metrics
          order:
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          hue_order:
          - Asymmetric
          - Symmetric
          rotation: 90
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: symmetric_vs_compressor_metric_train_time.pdf
          x: Metric
          y: train_time
          hue: Symmetric
          errorbar: se
          kind: boxen
          titles:
          xlabels: Compressors
          ylabels: Training Time (s)
          legend_title: Metrics
          order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          hue_order:
          - Asymmetric
          - Symmetric
          rotation: 90
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        line_plot:
        - file: compressor_metric_vs_accuracy.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: accuracy
          ylabel: Accuracy
          hue_order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: metric_vs_accuracy.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: accuracy
          ylabel: Accuracy
          hue_order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: string_metric_vs_accuracy.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: accuracy
          ylabel: Accuracy
          hue_order:
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: metric_vs_train_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: train_time
          ylabel: Training Time (s)
          y_scale: linear
          hue_order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: compressor_metric_vs_train_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: train_time
          ylabel: Training Time (s)
          y_scale: linear
          hue_order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: string_metric_vs_train_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: train_time
          ylabel: Training Time (s)
          y_scale: linear
          hue_order:
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: compressor_metric_vs_predict_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: predict_time
          ylabel: Prediction Time (s)
          y_scale: linear
          hue_order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
        - file: metric_vs_predict_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: predict_time
          ylabel: Prediction Time (s)
          y_scale: linear
          hue_order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
        - file: string_metric_vs_predict_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: predict_time
          ylabel: Prediction Time (s)
          y_scale: linear
          hue_order:
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
    outs:
    - path: sms_spam/plots/compressor_metric_vs_accuracy.pdf
      hash: md5
      md5: cdcbf4878e7c3287c8694002c2f45fb5
      size: 20399
    - path: sms_spam/plots/metric_vs_accuracy.pdf
      hash: md5
      md5: 2795444576d0fbe8c54749dc01c114fd
      size: 24540
    - path: sms_spam/plots/string_metric_vs_accuracy.pdf
      hash: md5
      md5: ef6c5d875dda20fb447f7ec7a83b32cb
      size: 20903
    - path: sms_spam/plots/symmetric_vs_compressor_metric.pdf
      hash: md5
      md5: 6e576ec571263de0b286ffdf8878c32a
      size: 21174
    - path: sms_spam/plots/symmetric_vs_metric.pdf
      hash: md5
      md5: cff58cffce5c49f11beb3d341ceb2e31
      size: 31119
    - path: sms_spam/plots/symmetric_vs_metric_train_time.pdf
      hash: md5
      md5: 65288c7ff4a7fca4b27ff1c3bf358c3d
      size: 31438
    - path: sms_spam/plots/symmetric_vs_string_metric.pdf
      hash: md5
      md5: 76a3934d166d819433370276fa037aac
      size: 23660
    - path: sms_spam/plots/symmetric_vs_string_metric_train_time.pdf
      hash: md5
      md5: 9ca0bf59046f2af734d189799b7d3ab4
      size: 24698
  plot_condense@sms_spam:
    cmd: python -m deckard.layers.plots  --path sms_spam/plots/  --file sms_spam/plots/condensed_merged.csv  -c
      conf/condensed_plots.yaml
    deps:
    - path: conf/condensed_plots.yaml
      hash: md5
      md5: 662671583c33bcb6d99103ad6bf289d6
      size: 1916
    - path: sms_spam/plots/condensed_merged.csv
      hash: md5
      md5: 4d9c5958bce75ed7e10e913c4ceaf608
      size: 2310272
    params:
      conf/condensed_plots.yaml:
        cat_plot:
        - file: condensing_method_vs_accuracy.pdf
          digitize: Condensing Ratio
          x: Condensing Method
          hue: Condensing Ratio
          y: accuracy
          y_scale: linear
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
          kind: boxen
          col: Model
          rotation: 45
          order:
          - Random
          - Medoid
          - Sum
          - SVC
          - Hardness
          - NearMiss
          - KNN
          xticklabels:
          - Random
          - Medoid
          - Sum
          - SVC
          - Hardness
          - NearMiss
          - KNN
          xlabels: Condensing Method
          ylabels: Accuracy
          legend_title: Sample Ratio
        - file: condensing_method_vs_train_time.pdf
          x: Condensing Method
          hue: Condensing Ratio
          digitize: Condensing Ratio
          y: train_time
          y_scale: log
          kind: boxen
          col: Model
          rotation: 45
          order:
          - Random
          - Medoid
          - Sum
          - SVC
          - Hardness
          - NearMiss
          - KNN
          xticklabels:
          - Random
          - Medoid
          - Sum
          - SVC
          - Hardness
          - NearMiss
          - k-NN
          xlabels: Condensing Method
          ylabels: Training Time
          legend_title: Sample Ratio
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: condensing_method_vs_predict_time.pdf
          x: Condensing Method
          hue: Condensing Ratio
          digitize: Condensing Ratio
          y: predict_time
          y_scale: log
          col: Model
          rotation: 45
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
          kind: boxen
          order:
          - Random
          - Medoid
          - Sum
          - SVC
          - Hardness
          - NearMiss
          - KNN
          xticklabels:
          - Random
          - Medoid
          - Sum
          - SVC
          - Hardness
          - NearMiss
          - k-NN
          xlabels: Condensing Method
          ylabels: Prediction Time
          legend_title: Sample Ratio
    outs:
    - path: sms_spam/plots/condensing_method_vs_accuracy.pdf
      hash: md5
      md5: a8db8dd3da602a582ecb6ba3adebfa5b
      size: 58429
    - path: sms_spam/plots/condensing_method_vs_predict_time.pdf
      hash: md5
      md5: da23c88ab97c6e81a0e3a210cfff20e2
      size: 83215
    - path: sms_spam/plots/condensing_method_vs_train_time.pdf
      hash: md5
      md5: e1710cd23a7069fec3ab2bebb06713d6
      size: 82184
  copy@sms_spam:
    cmd: rm -rf ~/Gzip-KNN/figs/sms_spam/ && mkdir -p ~/Gzip-KNN/figs/sms_spam/ &&
      cp -r sms_spam/plots/* ~/Gzip-KNN/figs/sms_spam/ && rm -rf ~/Gzip-KNN/figs/sms_spam/.gitignore
    deps:
    - path: sms_spam/plots/
      hash: md5
      md5: 92684c2e59c10c76c9cd023c5f052e24.dir
      size: 9422913
      nfiles: 26
  clean@kdd_nsl-condense/knn:
    cmd: python -m deckard.layers.clean_data  -i kdd_nsl/reports/condense/knn.csv
      -o kdd_nsl/plots/clean/condense/knn.csv -c conf/clean.yaml
    deps:
    - path: kdd_nsl/reports/condense/knn.csv
      hash: md5
      md5: 7f02784208bceeff1eae81b1b9d18e83
      size: 1230527
    params:
      conf/clean.yaml:
        drop_values:
          accuracy: 0.0
          predict_time: 1.0
        replace:
          model.init.metric:
            jaro: Jaro
            _winkler: -Winkler
            levenshtein: Levenshtein
            ncd: NCD
            ratio: Ratio
            seqRatio: SeqRatio
            hamming: Hamming
            gzip: GZIP
            pkl: Pickle
            bz2: BZ2
            zstd: ZSTD
            lzma: LZMA
          model_name:
            GzipSVC: k-SVC
            GzipLogisticRegressor: k-Logistic
            GzipKNN: k-KNN
          model.init.symmetric:
            true: Symmetric
            false: Asymmetric
          model.init.sampling_method:
            random: Random
            medoid: Medoid
            sum: Sum
            svc: SVC
            hardness: Hardness
            nearmiss: NearMiss
            knn: KNN
          dataset:
            ddos: DDoS
            sms_spam: SMS Spam
            kdd_nsl: KDD NSL
            truthseeker: Truthseeker
          model.init.m:
            -1: 1
        replace_cols:
          dataset: Dataset
          model.init.metric: Metric
          model.init.symmetric: Symmetric
          model.init.sampling_method: Condensing Method
          model.init.m: Condensing Ratio
          model_name: Model
    outs:
    - path: kdd_nsl/plots/clean/condense/knn.csv
      hash: md5
      md5: 01c600e8486f3b42fb93a8ea426638fd
      size: 928491
  clean@kdd_nsl-condense/logistic:
    cmd: python -m deckard.layers.clean_data  -i kdd_nsl/reports/condense/logistic.csv
      -o kdd_nsl/plots/clean/condense/logistic.csv -c conf/clean.yaml
    deps:
    - path: kdd_nsl/reports/condense/logistic.csv
      hash: md5
      md5: 867e4962cfb9603f6eff4fdb7364fa27
      size: 1188336
    params:
      conf/clean.yaml:
        drop_values:
          accuracy: 0.0
          predict_time: 1.0
        replace:
          model.init.metric:
            jaro: Jaro
            _winkler: -Winkler
            levenshtein: Levenshtein
            ncd: NCD
            ratio: Ratio
            seqRatio: SeqRatio
            hamming: Hamming
            gzip: GZIP
            pkl: Pickle
            bz2: BZ2
            zstd: ZSTD
            lzma: LZMA
          model_name:
            GzipSVC: k-SVC
            GzipLogisticRegressor: k-Logistic
            GzipKNN: k-KNN
          model.init.symmetric:
            true: Symmetric
            false: Asymmetric
          model.init.sampling_method:
            random: Random
            medoid: Medoid
            sum: Sum
            svc: SVC
            hardness: Hardness
            nearmiss: NearMiss
            knn: KNN
          dataset:
            ddos: DDoS
            sms_spam: SMS Spam
            kdd_nsl: KDD NSL
            truthseeker: Truthseeker
          model.init.m:
            -1: 1
        replace_cols:
          dataset: Dataset
          model.init.metric: Metric
          model.init.symmetric: Symmetric
          model.init.sampling_method: Condensing Method
          model.init.m: Condensing Ratio
          model_name: Model
    outs:
    - path: kdd_nsl/plots/clean/condense/logistic.csv
      hash: md5
      md5: d762eb52e34427b787696523e6e84fd9
      size: 517320
  clean@kdd_nsl-condense/svc:
    cmd: python -m deckard.layers.clean_data  -i kdd_nsl/reports/condense/svc.csv
      -o kdd_nsl/plots/clean/condense/svc.csv -c conf/clean.yaml
    deps:
    - path: kdd_nsl/reports/condense/svc.csv
      hash: md5
      md5: fd4d2f89ec51b5b68589164bf0bf98a8
      size: 1495270
    params:
      conf/clean.yaml:
        drop_values:
          accuracy: 0.0
          predict_time: 1.0
        replace:
          model.init.metric:
            jaro: Jaro
            _winkler: -Winkler
            levenshtein: Levenshtein
            ncd: NCD
            ratio: Ratio
            seqRatio: SeqRatio
            hamming: Hamming
            gzip: GZIP
            pkl: Pickle
            bz2: BZ2
            zstd: ZSTD
            lzma: LZMA
          model_name:
            GzipSVC: k-SVC
            GzipLogisticRegressor: k-Logistic
            GzipKNN: k-KNN
          model.init.symmetric:
            true: Symmetric
            false: Asymmetric
          model.init.sampling_method:
            random: Random
            medoid: Medoid
            sum: Sum
            svc: SVC
            hardness: Hardness
            nearmiss: NearMiss
            knn: KNN
          dataset:
            ddos: DDoS
            sms_spam: SMS Spam
            kdd_nsl: KDD NSL
            truthseeker: Truthseeker
          model.init.m:
            -1: 1
        replace_cols:
          dataset: Dataset
          model.init.metric: Metric
          model.init.symmetric: Symmetric
          model.init.sampling_method: Condensing Method
          model.init.m: Condensing Ratio
          model_name: Model
    outs:
    - path: kdd_nsl/plots/clean/condense/svc.csv
      hash: md5
      md5: f38c5c2a9bd5e325c118000b006ea160
      size: 1176275
  merge_condense@kdd_nsl:
    cmd: python merge.py --big_dir kdd_nsl/plots/ --data_file clean/condense/knn.csv
      --little_dir_data_file  clean/condense/logistic.csv clean/condense/svc.csv --output_folder
      kdd_nsl/plots/ --output_file condensed_merged.csv
    deps:
    - path: kdd_nsl/plots/clean/condense/knn.csv
      hash: md5
      md5: 01c600e8486f3b42fb93a8ea426638fd
      size: 928491
    - path: kdd_nsl/plots/clean/condense/logistic.csv
      hash: md5
      md5: d762eb52e34427b787696523e6e84fd9
      size: 517320
    - path: kdd_nsl/plots/clean/condense/svc.csv
      hash: md5
      md5: f38c5c2a9bd5e325c118000b006ea160
      size: 1176275
    outs:
    - path: kdd_nsl/plots/condensed_merged.csv
      hash: md5
      md5: deca13c3508d89c9a2c6ee0dbdb94ae3
      size: 2646816
  clean@kdd_nsl-gzip_knn:
    cmd: python -m deckard.layers.clean_data  -i kdd_nsl/reports/gzip_knn.csv -o kdd_nsl/plots/clean/gzip_knn.csv
      -c conf/clean.yaml
    deps:
    - path: kdd_nsl/reports/gzip_knn.csv
      hash: md5
      md5: bd313900a4176a3f52bb687b1ed67685
      size: 712255
    params:
      conf/clean.yaml:
        drop_values:
          accuracy: 0.0
          predict_time: 1.0
        replace:
          model.init.metric:
            jaro: Jaro
            _winkler: -Winkler
            levenshtein: Levenshtein
            ncd: NCD
            ratio: Ratio
            seqRatio: SeqRatio
            hamming: Hamming
            gzip: GZIP
            pkl: Pickle
            bz2: BZ2
            zstd: ZSTD
            lzma: LZMA
          model_name:
            GzipSVC: k-SVC
            GzipLogisticRegressor: k-Logistic
            GzipKNN: k-KNN
          model.init.symmetric:
            true: Symmetric
            false: Asymmetric
          model.init.sampling_method:
            random: Random
            medoid: Medoid
            sum: Sum
            svc: SVC
            hardness: Hardness
            nearmiss: NearMiss
            knn: KNN
          dataset:
            ddos: DDoS
            sms_spam: SMS Spam
            kdd_nsl: KDD NSL
            truthseeker: Truthseeker
          model.init.m:
            -1: 1
        replace_cols:
          dataset: Dataset
          model.init.metric: Metric
          model.init.symmetric: Symmetric
          model.init.sampling_method: Condensing Method
          model.init.m: Condensing Ratio
          model_name: Model
    outs:
    - path: kdd_nsl/plots/clean/gzip_knn.csv
      hash: md5
      md5: 6f3721827ec59876187befe71917cca1
      size: 496184
  clean@kdd_nsl-gzip_logistic:
    cmd: python -m deckard.layers.clean_data  -i kdd_nsl/reports/gzip_logistic.csv
      -o kdd_nsl/plots/clean/gzip_logistic.csv -c conf/clean.yaml
    deps:
    - path: kdd_nsl/reports/gzip_logistic.csv
      hash: md5
      md5: 48b20e1f0c5bc8ed8a997f477e863f4a
      size: 1322010
    params:
      conf/clean.yaml:
        drop_values:
          accuracy: 0.0
          predict_time: 1.0
        replace:
          model.init.metric:
            jaro: Jaro
            _winkler: -Winkler
            levenshtein: Levenshtein
            ncd: NCD
            ratio: Ratio
            seqRatio: SeqRatio
            hamming: Hamming
            gzip: GZIP
            pkl: Pickle
            bz2: BZ2
            zstd: ZSTD
            lzma: LZMA
          model_name:
            GzipSVC: k-SVC
            GzipLogisticRegressor: k-Logistic
            GzipKNN: k-KNN
          model.init.symmetric:
            true: Symmetric
            false: Asymmetric
          model.init.sampling_method:
            random: Random
            medoid: Medoid
            sum: Sum
            svc: SVC
            hardness: Hardness
            nearmiss: NearMiss
            knn: KNN
          dataset:
            ddos: DDoS
            sms_spam: SMS Spam
            kdd_nsl: KDD NSL
            truthseeker: Truthseeker
          model.init.m:
            -1: 1
        replace_cols:
          dataset: Dataset
          model.init.metric: Metric
          model.init.symmetric: Symmetric
          model.init.sampling_method: Condensing Method
          model.init.m: Condensing Ratio
          model_name: Model
    outs:
    - path: kdd_nsl/plots/clean/gzip_logistic.csv
      hash: md5
      md5: fd48f9dcb3aaa86e4a6e6e8e8e327294
      size: 587585
  clean@kdd_nsl-gzip_svc:
    cmd: python -m deckard.layers.clean_data  -i kdd_nsl/reports/gzip_svc.csv -o kdd_nsl/plots/clean/gzip_svc.csv
      -c conf/clean.yaml
    deps:
    - path: kdd_nsl/reports/gzip_svc.csv
      hash: md5
      md5: 8cce447ffd02091345d09ae6950e3c10
      size: 1423691
    params:
      conf/clean.yaml:
        drop_values:
          accuracy: 0.0
          predict_time: 1.0
        replace:
          model.init.metric:
            jaro: Jaro
            _winkler: -Winkler
            levenshtein: Levenshtein
            ncd: NCD
            ratio: Ratio
            seqRatio: SeqRatio
            hamming: Hamming
            gzip: GZIP
            pkl: Pickle
            bz2: BZ2
            zstd: ZSTD
            lzma: LZMA
          model_name:
            GzipSVC: k-SVC
            GzipLogisticRegressor: k-Logistic
            GzipKNN: k-KNN
          model.init.symmetric:
            true: Symmetric
            false: Asymmetric
          model.init.sampling_method:
            random: Random
            medoid: Medoid
            sum: Sum
            svc: SVC
            hardness: Hardness
            nearmiss: NearMiss
            knn: KNN
          dataset:
            ddos: DDoS
            sms_spam: SMS Spam
            kdd_nsl: KDD NSL
            truthseeker: Truthseeker
          model.init.m:
            -1: 1
        replace_cols:
          dataset: Dataset
          model.init.metric: Metric
          model.init.symmetric: Symmetric
          model.init.sampling_method: Condensing Method
          model.init.m: Condensing Ratio
          model_name: Model
    outs:
    - path: kdd_nsl/plots/clean/gzip_svc.csv
      hash: md5
      md5: 40eec0bce9eda0100184c70214f7b257
      size: 1173266
  merge@kdd_nsl:
    cmd: python merge.py --big_dir kdd_nsl/plots/ --data_file clean/gzip_knn.csv --little_dir_data_file
      clean/gzip_logistic.csv clean/gzip_svc.csv --output_folder kdd_nsl/plots --output_file
      merged.csv
    deps:
    - path: kdd_nsl/plots/clean/gzip_knn.csv
      hash: md5
      md5: 6f3721827ec59876187befe71917cca1
      size: 496184
    - path: kdd_nsl/plots/clean/gzip_logistic.csv
      hash: md5
      md5: fd48f9dcb3aaa86e4a6e6e8e8e327294
      size: 587585
    - path: kdd_nsl/plots/clean/gzip_svc.csv
      hash: md5
      md5: 40eec0bce9eda0100184c70214f7b257
      size: 1173266
    outs:
    - path: kdd_nsl/plots/merged.csv
      hash: md5
      md5: 998c90211e201471c6bf914d715d095a
      size: 2277572
  plot@kdd_nsl:
    cmd: python -m deckard.layers.plots  --path kdd_nsl/plots/  --file kdd_nsl/plots/merged.csv  -c
      conf/plots.yaml
    deps:
    - path: conf/plots.yaml
      hash: md5
      md5: 43e3ec0876b55c83f231615f7a904e33
      size: 7386
    - path: kdd_nsl/plots/merged.csv
      hash: md5
      md5: 998c90211e201471c6bf914d715d095a
      size: 2277572
    params:
      conf/plots.yaml:
        cat_plot:
        - file: symmetric_vs_compressor_metric.pdf
          x: Metric
          y: accuracy
          hue: Symmetric
          errorbar: se
          kind: boxen
          titles: ' '
          xlabels: Compressor
          ylabels: Accuracy
          legend_title: Metrics
          order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          hue_order:
          - Asymmetric
          - Symmetric
          rotation: 90
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: symmetric_vs_string_metric.pdf
          x: Metric
          y: accuracy
          hue: Symmetric
          errorbar: se
          kind: boxen
          titles: ' '
          xlabels: Compressors
          ylabels: Accuracy
          legend_title: ' '
          order:
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          hue_order:
          - Asymmetric
          - Symmetric
          rotation: 90
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: symmetric_vs_metric.pdf
          x: Metric
          y: accuracy
          hue: Symmetric
          errorbar: se
          kind: boxen
          titles: ' '
          xlabels: Compressors
          ylabels: Accuracy
          legend_title: ' '
          order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          hue_order:
          - Asymmetric
          - Symmetric
          rotation: 90
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: symmetric_vs_metric_train_time.pdf
          x: Metric
          y: train_time
          hue: Symmetric
          errorbar: se
          kind: boxen
          titles:
          xlabels: Metrics
          ylabels: Training Time (s)
          legend_title: Metrics
          order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          hue_order:
          - Asymmetric
          - Symmetric
          rotation: 90
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
          y_scale: linear
        - file: symmetric_vs_string_metric_train_time.pdf
          x: Metric
          y: train_time
          hue: Symmetric
          errorbar: se
          kind: boxen
          titles:
          xlabels: Compressors
          ylabels: Training Time (s)
          legend_title: String Metrics
          order:
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          hue_order:
          - Asymmetric
          - Symmetric
          rotation: 90
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: symmetric_vs_compressor_metric_train_time.pdf
          x: Metric
          y: train_time
          hue: Symmetric
          errorbar: se
          kind: boxen
          titles:
          xlabels: Compressors
          ylabels: Training Time (s)
          legend_title: Metrics
          order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          hue_order:
          - Asymmetric
          - Symmetric
          rotation: 90
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        line_plot:
        - file: compressor_metric_vs_accuracy.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: accuracy
          ylabel: Accuracy
          hue_order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: metric_vs_accuracy.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: accuracy
          ylabel: Accuracy
          hue_order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: string_metric_vs_accuracy.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: accuracy
          ylabel: Accuracy
          hue_order:
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: metric_vs_train_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: train_time
          ylabel: Training Time (s)
          y_scale: linear
          hue_order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: compressor_metric_vs_train_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: train_time
          ylabel: Training Time (s)
          y_scale: linear
          hue_order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: string_metric_vs_train_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: train_time
          ylabel: Training Time (s)
          y_scale: linear
          hue_order:
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: compressor_metric_vs_predict_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: predict_time
          ylabel: Prediction Time (s)
          y_scale: linear
          hue_order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
        - file: metric_vs_predict_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: predict_time
          ylabel: Prediction Time (s)
          y_scale: linear
          hue_order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
        - file: string_metric_vs_predict_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: predict_time
          ylabel: Prediction Time (s)
          y_scale: linear
          hue_order:
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
    outs:
    - path: kdd_nsl/plots/compressor_metric_vs_accuracy.pdf
      hash: md5
      md5: edad9e683854a63d3b93ea9b6113fd58
      size: 20385
    - path: kdd_nsl/plots/metric_vs_accuracy.pdf
      hash: md5
      md5: 6e8105b0cbfc3e771e57340e349e33a9
      size: 24517
    - path: kdd_nsl/plots/string_metric_vs_accuracy.pdf
      hash: md5
      md5: 21474395a4719cc0564d0aaeb133bed8
      size: 20892
    - path: kdd_nsl/plots/symmetric_vs_compressor_metric.pdf
      hash: md5
      md5: c74aef319c993dc9ea8bbd6d361f265c
      size: 21314
    - path: kdd_nsl/plots/symmetric_vs_metric.pdf
      hash: md5
      md5: 52bfb1ced09558f003ca9b7b664aa755
      size: 31117
    - path: kdd_nsl/plots/symmetric_vs_metric_train_time.pdf
      hash: md5
      md5: 1c4ec319122eb8d907d987e37821d77b
      size: 32006
    - path: kdd_nsl/plots/symmetric_vs_string_metric.pdf
      hash: md5
      md5: 668aa5a457d3079525c9762b4168c15f
      size: 22883
    - path: kdd_nsl/plots/symmetric_vs_string_metric_train_time.pdf
      hash: md5
      md5: ddaf2ccaed464f4249b8bd80ad85cde4
      size: 24957
  clean@ddos-gzip_knn:
    cmd: python -m deckard.layers.clean_data  -i ddos/reports/gzip_knn.csv -o ddos/plots/clean/gzip_knn.csv
      -c conf/clean.yaml
    deps:
    - path: ddos/reports/gzip_knn.csv
      hash: md5
      md5: 5ea2e6e2263d3933ee3c290ad22d162b
      size: 870650
    params:
      conf/clean.yaml:
        drop_values:
          accuracy: 0.0
          predict_time: 1.0
        replace:
          model.init.metric:
            jaro: Jaro
            _winkler: -Winkler
            levenshtein: Levenshtein
            ncd: NCD
            ratio: Ratio
            seqRatio: SeqRatio
            hamming: Hamming
            gzip: GZIP
            pkl: Pickle
            bz2: BZ2
            zstd: ZSTD
            lzma: LZMA
          model_name:
            GzipSVC: k-SVC
            GzipLogisticRegressor: k-Logistic
            GzipKNN: k-KNN
          model.init.symmetric:
            true: Symmetric
            false: Asymmetric
          model.init.sampling_method:
            random: Random
            medoid: Medoid
            sum: Sum
            svc: SVC
            hardness: Hardness
            nearmiss: NearMiss
            knn: KNN
          dataset:
            ddos: DDoS
            sms_spam: SMS Spam
            kdd_nsl: KDD NSL
            truthseeker: Truthseeker
          model.init.m:
            -1: 1
        replace_cols:
          dataset: Dataset
          model.init.metric: Metric
          model.init.symmetric: Symmetric
          model.init.sampling_method: Condensing Method
          model.init.m: Condensing Ratio
          model_name: Model
    outs:
    - path: ddos/plots/clean/gzip_knn.csv
      hash: md5
      md5: 87b3b42c34d110a25f96483080db85fd
      size: 700942
  clean@ddos-gzip_logistic:
    cmd: python -m deckard.layers.clean_data  -i ddos/reports/gzip_logistic.csv -o
      ddos/plots/clean/gzip_logistic.csv -c conf/clean.yaml
    deps:
    - path: ddos/reports/gzip_logistic.csv
      hash: md5
      md5: 9afc2bc076a953a5187992fba51b64ba
      size: 1252312
    params:
      conf/clean.yaml:
        drop_values:
          accuracy: 0.0
          predict_time: 1.0
        replace:
          model.init.metric:
            jaro: Jaro
            _winkler: -Winkler
            levenshtein: Levenshtein
            ncd: NCD
            ratio: Ratio
            seqRatio: SeqRatio
            hamming: Hamming
            gzip: GZIP
            pkl: Pickle
            bz2: BZ2
            zstd: ZSTD
            lzma: LZMA
          model_name:
            GzipSVC: k-SVC
            GzipLogisticRegressor: k-Logistic
            GzipKNN: k-KNN
          model.init.symmetric:
            true: Symmetric
            false: Asymmetric
          model.init.sampling_method:
            random: Random
            medoid: Medoid
            sum: Sum
            svc: SVC
            hardness: Hardness
            nearmiss: NearMiss
            knn: KNN
          dataset:
            ddos: DDoS
            sms_spam: SMS Spam
            kdd_nsl: KDD NSL
            truthseeker: Truthseeker
          model.init.m:
            -1: 1
        replace_cols:
          dataset: Dataset
          model.init.metric: Metric
          model.init.symmetric: Symmetric
          model.init.sampling_method: Condensing Method
          model.init.m: Condensing Ratio
          model_name: Model
    outs:
    - path: ddos/plots/clean/gzip_logistic.csv
      hash: md5
      md5: f39910b350eec96d7a418a1db2982ec3
      size: 419910
  clean@ddos-gzip_svc:
    cmd: python -m deckard.layers.clean_data  -i ddos/reports/gzip_svc.csv -o ddos/plots/clean/gzip_svc.csv
      -c conf/clean.yaml
    deps:
    - path: ddos/reports/gzip_svc.csv
      hash: md5
      md5: e53c4b21a4c4bcbb4aa78008e21062c4
      size: 1396669
    params:
      conf/clean.yaml:
        drop_values:
          accuracy: 0.0
          predict_time: 1.0
        replace:
          model.init.metric:
            jaro: Jaro
            _winkler: -Winkler
            levenshtein: Levenshtein
            ncd: NCD
            ratio: Ratio
            seqRatio: SeqRatio
            hamming: Hamming
            gzip: GZIP
            pkl: Pickle
            bz2: BZ2
            zstd: ZSTD
            lzma: LZMA
          model_name:
            GzipSVC: k-SVC
            GzipLogisticRegressor: k-Logistic
            GzipKNN: k-KNN
          model.init.symmetric:
            true: Symmetric
            false: Asymmetric
          model.init.sampling_method:
            random: Random
            medoid: Medoid
            sum: Sum
            svc: SVC
            hardness: Hardness
            nearmiss: NearMiss
            knn: KNN
          dataset:
            ddos: DDoS
            sms_spam: SMS Spam
            kdd_nsl: KDD NSL
            truthseeker: Truthseeker
          model.init.m:
            -1: 1
        replace_cols:
          dataset: Dataset
          model.init.metric: Metric
          model.init.symmetric: Symmetric
          model.init.sampling_method: Condensing Method
          model.init.m: Condensing Ratio
          model_name: Model
    outs:
    - path: ddos/plots/clean/gzip_svc.csv
      hash: md5
      md5: 0e9c103702f8329f811932f085a8d473
      size: 1137604
  merge@ddos:
    cmd: python merge.py --big_dir ddos/plots/ --data_file clean/gzip_knn.csv --little_dir_data_file
      clean/gzip_logistic.csv clean/gzip_svc.csv --output_folder ddos/plots --output_file
      merged.csv
    deps:
    - path: ddos/plots/clean/gzip_knn.csv
      hash: md5
      md5: 87b3b42c34d110a25f96483080db85fd
      size: 700942
    - path: ddos/plots/clean/gzip_logistic.csv
      hash: md5
      md5: f39910b350eec96d7a418a1db2982ec3
      size: 419910
    - path: ddos/plots/clean/gzip_svc.csv
      hash: md5
      md5: 0e9c103702f8329f811932f085a8d473
      size: 1137604
    outs:
    - path: ddos/plots/merged.csv
      hash: md5
      md5: d176413946c2584e65ba0ca185fe74e5
      size: 2280519
  clean@truthseeker-gzip_knn:
    cmd: python -m deckard.layers.clean_data  -i truthseeker/reports/gzip_knn.csv
      -o truthseeker/plots/clean/gzip_knn.csv -c conf/clean.yaml
    deps:
    - path: truthseeker/reports/gzip_knn.csv
      hash: md5
      md5: b9bea03c06d3f4dc30282441e36c700a
      size: 793437
    params:
      conf/clean.yaml:
        drop_values:
          accuracy: 0.0
          predict_time: 1.0
        replace:
          model.init.metric:
            jaro: Jaro
            _winkler: -Winkler
            levenshtein: Levenshtein
            ncd: NCD
            ratio: Ratio
            seqRatio: SeqRatio
            hamming: Hamming
            gzip: GZIP
            pkl: Pickle
            bz2: BZ2
            zstd: ZSTD
            lzma: LZMA
          model_name:
            GzipSVC: k-SVC
            GzipLogisticRegressor: k-Logistic
            GzipKNN: k-KNN
          model.init.symmetric:
            true: Symmetric
            false: Asymmetric
          model.init.sampling_method:
            random: Random
            medoid: Medoid
            sum: Sum
            svc: SVC
            hardness: Hardness
            nearmiss: NearMiss
            knn: KNN
          dataset:
            ddos: DDoS
            sms_spam: SMS Spam
            kdd_nsl: KDD NSL
            truthseeker: Truthseeker
          model.init.m:
            -1: 1
        replace_cols:
          dataset: Dataset
          model.init.metric: Metric
          model.init.symmetric: Symmetric
          model.init.sampling_method: Condensing Method
          model.init.m: Condensing Ratio
          model_name: Model
    outs:
    - path: truthseeker/plots/clean/gzip_knn.csv
      hash: md5
      md5: 7f13a0d7c746135aeaca61efd5968f3c
      size: 557930
  clean@truthseeker-gzip_logistic:
    cmd: python -m deckard.layers.clean_data  -i truthseeker/reports/gzip_logistic.csv
      -o truthseeker/plots/clean/gzip_logistic.csv -c conf/clean.yaml
    deps:
    - path: truthseeker/reports/gzip_logistic.csv
      hash: md5
      md5: 06ba1ec0435fac93c0204286ee88ca26
      size: 1313525
    params:
      conf/clean.yaml:
        drop_values:
          accuracy: 0.0
          predict_time: 1.0
        replace:
          model.init.metric:
            jaro: Jaro
            _winkler: -Winkler
            levenshtein: Levenshtein
            ncd: NCD
            ratio: Ratio
            seqRatio: SeqRatio
            hamming: Hamming
            gzip: GZIP
            pkl: Pickle
            bz2: BZ2
            zstd: ZSTD
            lzma: LZMA
          model_name:
            GzipSVC: k-SVC
            GzipLogisticRegressor: k-Logistic
            GzipKNN: k-KNN
          model.init.symmetric:
            true: Symmetric
            false: Asymmetric
          model.init.sampling_method:
            random: Random
            medoid: Medoid
            sum: Sum
            svc: SVC
            hardness: Hardness
            nearmiss: NearMiss
            knn: KNN
          dataset:
            ddos: DDoS
            sms_spam: SMS Spam
            kdd_nsl: KDD NSL
            truthseeker: Truthseeker
          model.init.m:
            -1: 1
        replace_cols:
          dataset: Dataset
          model.init.metric: Metric
          model.init.symmetric: Symmetric
          model.init.sampling_method: Condensing Method
          model.init.m: Condensing Ratio
          model_name: Model
    outs:
    - path: truthseeker/plots/clean/gzip_logistic.csv
      hash: md5
      md5: a9cb7327389ac4d5353b78d2b518490d
      size: 697746
  clean@truthseeker-gzip_svc:
    cmd: python -m deckard.layers.clean_data  -i truthseeker/reports/gzip_svc.csv
      -o truthseeker/plots/clean/gzip_svc.csv -c conf/clean.yaml
    deps:
    - path: truthseeker/reports/gzip_svc.csv
      hash: md5
      md5: a6f40e3c4f1a2242a43632576013334c
      size: 1452411
    params:
      conf/clean.yaml:
        drop_values:
          accuracy: 0.0
          predict_time: 1.0
        replace:
          model.init.metric:
            jaro: Jaro
            _winkler: -Winkler
            levenshtein: Levenshtein
            ncd: NCD
            ratio: Ratio
            seqRatio: SeqRatio
            hamming: Hamming
            gzip: GZIP
            pkl: Pickle
            bz2: BZ2
            zstd: ZSTD
            lzma: LZMA
          model_name:
            GzipSVC: k-SVC
            GzipLogisticRegressor: k-Logistic
            GzipKNN: k-KNN
          model.init.symmetric:
            true: Symmetric
            false: Asymmetric
          model.init.sampling_method:
            random: Random
            medoid: Medoid
            sum: Sum
            svc: SVC
            hardness: Hardness
            nearmiss: NearMiss
            knn: KNN
          dataset:
            ddos: DDoS
            sms_spam: SMS Spam
            kdd_nsl: KDD NSL
            truthseeker: Truthseeker
          model.init.m:
            -1: 1
        replace_cols:
          dataset: Dataset
          model.init.metric: Metric
          model.init.symmetric: Symmetric
          model.init.sampling_method: Condensing Method
          model.init.m: Condensing Ratio
          model_name: Model
    outs:
    - path: truthseeker/plots/clean/gzip_svc.csv
      hash: md5
      md5: 0501df843b9f661d34581eaaaef58f70
      size: 1184672
  merge@truthseeker:
    cmd: python merge.py --big_dir truthseeker/plots/ --data_file clean/gzip_knn.csv
      --little_dir_data_file clean/gzip_logistic.csv clean/gzip_svc.csv --output_folder
      truthseeker/plots --output_file merged.csv
    deps:
    - path: truthseeker/plots/clean/gzip_knn.csv
      hash: md5
      md5: 7f13a0d7c746135aeaca61efd5968f3c
      size: 557930
    - path: truthseeker/plots/clean/gzip_logistic.csv
      hash: md5
      md5: a9cb7327389ac4d5353b78d2b518490d
      size: 697746
    - path: truthseeker/plots/clean/gzip_svc.csv
      hash: md5
      md5: 0501df843b9f661d34581eaaaef58f70
      size: 1184672
    outs:
    - path: truthseeker/plots/merged.csv
      hash: md5
      md5: e102b93c1bc4608bec15c920a7dd8052
      size: 2463761
  merge_datasets:
    cmd: python merge.py --big_dir . --little_dir . --data_file sms_spam/plots/merged.csv
      --little_dir_data_file  kdd_nsl/plots/merged.csv ddos/plots/merged.csv truthseeker/plots/merged.csv
      kdd_nsl/plots/condensed_merged.csv ddos/plots/condensed_merged.csv truthseeker/plots/condensed_merged.csv
      sms_spam/plots/condensed_merged.csv --output_folder combined/plots/ --output_file
      merged.csv
    deps:
    - path: ddos/plots/merged.csv
      hash: md5
      md5: d176413946c2584e65ba0ca185fe74e5
      size: 2280519
    - path: kdd_nsl/plots/merged.csv
      hash: md5
      md5: 998c90211e201471c6bf914d715d095a
      size: 2277572
    - path: sms_spam/plots/merged.csv
      hash: md5
      md5: dcfec316b2e65a718c817f7855047ce8
      size: 2136730
    - path: truthseeker/plots/merged.csv
      hash: md5
      md5: e102b93c1bc4608bec15c920a7dd8052
      size: 2463761
    outs:
    - path: combined/plots/merged.csv
      hash: md5
      md5: f113844c930e28200b28863f468ecb19
      size: 18484178
  clean@ddos-condense/svc:
    cmd: python -m deckard.layers.clean_data  -i ddos/reports/condense/svc.csv -o
      ddos/plots/clean/condense/svc.csv -c conf/clean.yaml
    deps:
    - path: ddos/reports/condense/svc.csv
      hash: md5
      md5: 603d872c7bc5d8ce3e2d087537f1171d
      size: 1247829
    params:
      conf/clean.yaml:
        drop_values:
          accuracy: 0.0
          predict_time: 1.0
        replace:
          model.init.metric:
            jaro: Jaro
            _winkler: -Winkler
            levenshtein: Levenshtein
            ncd: NCD
            ratio: Ratio
            seqRatio: SeqRatio
            hamming: Hamming
            gzip: GZIP
            pkl: Pickle
            bz2: BZ2
            zstd: ZSTD
            lzma: LZMA
          model_name:
            GzipSVC: k-SVC
            GzipLogisticRegressor: k-Logistic
            GzipKNN: k-KNN
          model.init.symmetric:
            true: Symmetric
            false: Asymmetric
          model.init.sampling_method:
            random: Random
            medoid: Medoid
            sum: Sum
            svc: SVC
            hardness: Hardness
            nearmiss: NearMiss
            knn: KNN
          dataset:
            ddos: DDoS
            sms_spam: SMS Spam
            kdd_nsl: KDD NSL
            truthseeker: Truthseeker
          model.init.m:
            -1: 1
        replace_cols:
          dataset: Dataset
          model.init.metric: Metric
          model.init.symmetric: Symmetric
          model.init.sampling_method: Condensing Method
          model.init.m: Condensing Ratio
          model_name: Model
    outs:
    - path: ddos/plots/clean/condense/svc.csv
      hash: md5
      md5: b9163109d30bffa0d092b45bc94e600a
      size: 958897
  clean@truthseeker-condense/svc:
    cmd: python -m deckard.layers.clean_data  -i truthseeker/reports/condense/svc.csv
      -o truthseeker/plots/clean/condense/svc.csv -c conf/clean.yaml
    deps:
    - path: truthseeker/reports/condense/svc.csv
      hash: md5
      md5: f1bf0ad1190078b036db2bc05f470ff5
      size: 825142
    params:
      conf/clean.yaml:
        drop_values:
          accuracy: 0.0
          predict_time: 1.0
        replace:
          model.init.metric:
            jaro: Jaro
            _winkler: -Winkler
            levenshtein: Levenshtein
            ncd: NCD
            ratio: Ratio
            seqRatio: SeqRatio
            hamming: Hamming
            gzip: GZIP
            pkl: Pickle
            bz2: BZ2
            zstd: ZSTD
            lzma: LZMA
          model_name:
            GzipSVC: k-SVC
            GzipLogisticRegressor: k-Logistic
            GzipKNN: k-KNN
          model.init.symmetric:
            true: Symmetric
            false: Asymmetric
          model.init.sampling_method:
            random: Random
            medoid: Medoid
            sum: Sum
            svc: SVC
            hardness: Hardness
            nearmiss: NearMiss
            knn: KNN
          dataset:
            ddos: DDoS
            sms_spam: SMS Spam
            kdd_nsl: KDD NSL
            truthseeker: Truthseeker
          model.init.m:
            -1: 1
        replace_cols:
          dataset: Dataset
          model.init.metric: Metric
          model.init.symmetric: Symmetric
          model.init.sampling_method: Condensing Method
          model.init.m: Condensing Ratio
          model_name: Model
    outs:
    - path: truthseeker/plots/clean/condense/svc.csv
      hash: md5
      md5: 78d6c744fe8b0f1577a604356e0ab29d
      size: 633673
  clean@truthseeker-condense/logistic:
    cmd: python -m deckard.layers.clean_data  -i truthseeker/reports/condense/logistic.csv
      -o truthseeker/plots/clean/condense/logistic.csv -c conf/clean.yaml
    deps:
    - path: truthseeker/reports/condense/logistic.csv
      hash: md5
      md5: 07bb4c331d67a498e8d88cb9521cc1f0
      size: 1192308
    params:
      conf/clean.yaml:
        drop_values:
          accuracy: 0.0
          predict_time: 1.0
        replace:
          model.init.metric:
            jaro: Jaro
            _winkler: -Winkler
            levenshtein: Levenshtein
            ncd: NCD
            ratio: Ratio
            seqRatio: SeqRatio
            hamming: Hamming
            gzip: GZIP
            pkl: Pickle
            bz2: BZ2
            zstd: ZSTD
            lzma: LZMA
          model_name:
            GzipSVC: k-SVC
            GzipLogisticRegressor: k-Logistic
            GzipKNN: k-KNN
          model.init.symmetric:
            true: Symmetric
            false: Asymmetric
          model.init.sampling_method:
            random: Random
            medoid: Medoid
            sum: Sum
            svc: SVC
            hardness: Hardness
            nearmiss: NearMiss
            knn: KNN
          dataset:
            ddos: DDoS
            sms_spam: SMS Spam
            kdd_nsl: KDD NSL
            truthseeker: Truthseeker
          model.init.m:
            -1: 1
        replace_cols:
          dataset: Dataset
          model.init.metric: Metric
          model.init.symmetric: Symmetric
          model.init.sampling_method: Condensing Method
          model.init.m: Condensing Ratio
          model_name: Model
    outs:
    - path: truthseeker/plots/clean/condense/logistic.csv
      hash: md5
      md5: a6a33b3cb3d7e3e10d4353cc781c460d
      size: 334757
  clean@truthseeker-condense/knn:
    cmd: python -m deckard.layers.clean_data  -i truthseeker/reports/condense/knn.csv
      -o truthseeker/plots/clean/condense/knn.csv -c conf/clean.yaml
    deps:
    - path: truthseeker/reports/condense/knn.csv
      hash: md5
      md5: e6033070a5d7a22c4f63820d16430dc2
      size: 1155179
    params:
      conf/clean.yaml:
        drop_values:
          accuracy: 0.0
          predict_time: 1.0
        replace:
          model.init.metric:
            jaro: Jaro
            _winkler: -Winkler
            levenshtein: Levenshtein
            ncd: NCD
            ratio: Ratio
            seqRatio: SeqRatio
            hamming: Hamming
            gzip: GZIP
            pkl: Pickle
            bz2: BZ2
            zstd: ZSTD
            lzma: LZMA
          model_name:
            GzipSVC: k-SVC
            GzipLogisticRegressor: k-Logistic
            GzipKNN: k-KNN
          model.init.symmetric:
            true: Symmetric
            false: Asymmetric
          model.init.sampling_method:
            random: Random
            medoid: Medoid
            sum: Sum
            svc: SVC
            hardness: Hardness
            nearmiss: NearMiss
            knn: KNN
          dataset:
            ddos: DDoS
            sms_spam: SMS Spam
            kdd_nsl: KDD NSL
            truthseeker: Truthseeker
          model.init.m:
            -1: 1
        replace_cols:
          dataset: Dataset
          model.init.metric: Metric
          model.init.symmetric: Symmetric
          model.init.sampling_method: Condensing Method
          model.init.m: Condensing Ratio
          model_name: Model
    outs:
    - path: truthseeker/plots/clean/condense/knn.csv
      hash: md5
      md5: b752d13d0c4172c8d361171fc214e777
      size: 850685
  plot@truthseeker:
    cmd: python -m deckard.layers.plots  --path truthseeker/plots/  --file truthseeker/plots/merged.csv  -c
      conf/plots.yaml
    deps:
    - path: conf/plots.yaml
      hash: md5
      md5: 43e3ec0876b55c83f231615f7a904e33
      size: 7386
    - path: truthseeker/plots/merged.csv
      hash: md5
      md5: e102b93c1bc4608bec15c920a7dd8052
      size: 2463761
    params:
      conf/plots.yaml:
        cat_plot:
        - file: symmetric_vs_compressor_metric.pdf
          x: Metric
          y: accuracy
          hue: Symmetric
          errorbar: se
          kind: boxen
          titles: ' '
          xlabels: Compressor
          ylabels: Accuracy
          legend_title: Metrics
          order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          hue_order:
          - Asymmetric
          - Symmetric
          rotation: 90
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: symmetric_vs_string_metric.pdf
          x: Metric
          y: accuracy
          hue: Symmetric
          errorbar: se
          kind: boxen
          titles: ' '
          xlabels: Compressors
          ylabels: Accuracy
          legend_title: ' '
          order:
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          hue_order:
          - Asymmetric
          - Symmetric
          rotation: 90
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: symmetric_vs_metric.pdf
          x: Metric
          y: accuracy
          hue: Symmetric
          errorbar: se
          kind: boxen
          titles: ' '
          xlabels: Compressors
          ylabels: Accuracy
          legend_title: ' '
          order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          hue_order:
          - Asymmetric
          - Symmetric
          rotation: 90
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: symmetric_vs_metric_train_time.pdf
          x: Metric
          y: train_time
          hue: Symmetric
          errorbar: se
          kind: boxen
          titles:
          xlabels: Metrics
          ylabels: Training Time (s)
          legend_title: Metrics
          order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          hue_order:
          - Asymmetric
          - Symmetric
          rotation: 90
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
          y_scale: linear
        - file: symmetric_vs_string_metric_train_time.pdf
          x: Metric
          y: train_time
          hue: Symmetric
          errorbar: se
          kind: boxen
          titles:
          xlabels: Compressors
          ylabels: Training Time (s)
          legend_title: String Metrics
          order:
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          hue_order:
          - Asymmetric
          - Symmetric
          rotation: 90
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: symmetric_vs_compressor_metric_train_time.pdf
          x: Metric
          y: train_time
          hue: Symmetric
          errorbar: se
          kind: boxen
          titles:
          xlabels: Compressors
          ylabels: Training Time (s)
          legend_title: Metrics
          order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          hue_order:
          - Asymmetric
          - Symmetric
          rotation: 90
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        line_plot:
        - file: compressor_metric_vs_accuracy.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: accuracy
          ylabel: Accuracy
          hue_order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: metric_vs_accuracy.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: accuracy
          ylabel: Accuracy
          hue_order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: string_metric_vs_accuracy.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: accuracy
          ylabel: Accuracy
          hue_order:
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: metric_vs_train_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: train_time
          ylabel: Training Time (s)
          y_scale: linear
          hue_order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: compressor_metric_vs_train_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: train_time
          ylabel: Training Time (s)
          y_scale: linear
          hue_order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: string_metric_vs_train_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: train_time
          ylabel: Training Time (s)
          y_scale: linear
          hue_order:
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: compressor_metric_vs_predict_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: predict_time
          ylabel: Prediction Time (s)
          y_scale: linear
          hue_order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
        - file: metric_vs_predict_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: predict_time
          ylabel: Prediction Time (s)
          y_scale: linear
          hue_order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
        - file: string_metric_vs_predict_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: predict_time
          ylabel: Prediction Time (s)
          y_scale: linear
          hue_order:
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
    outs:
    - path: truthseeker/plots/compressor_metric_vs_accuracy.pdf
      hash: md5
      md5: 93b9a9f2e8532123bedea07b2b13f991
      size: 19725
    - path: truthseeker/plots/metric_vs_accuracy.pdf
      hash: md5
      md5: fc58b7e4055dbe4ae950c493e039764b
      size: 23832
    - path: truthseeker/plots/string_metric_vs_accuracy.pdf
      hash: md5
      md5: f71e170253e7628ba99f632cfa193c9a
      size: 19649
    - path: truthseeker/plots/symmetric_vs_compressor_metric.pdf
      hash: md5
      md5: c2d3850fc3906f08dc248e9c42412925
      size: 21325
    - path: truthseeker/plots/symmetric_vs_metric.pdf
      hash: md5
      md5: a946740ea3b3875472f827cdc4f24c53
      size: 31503
    - path: truthseeker/plots/symmetric_vs_metric_train_time.pdf
      hash: md5
      md5: f55479ac428af8ad7ea6cf5bb12abe26
      size: 31944
    - path: truthseeker/plots/symmetric_vs_string_metric.pdf
      hash: md5
      md5: 2f7f92158ff43132b5f8d106aa9c5fbc
      size: 23375
    - path: truthseeker/plots/symmetric_vs_string_metric_train_time.pdf
      hash: md5
      md5: ce3daad656f56376ce563c09ee749de6
      size: 25236
  plot@ddos:
    cmd: python -m deckard.layers.plots  --path ddos/plots/  --file ddos/plots/merged.csv  -c
      conf/plots.yaml
    deps:
    - path: conf/plots.yaml
      hash: md5
      md5: 43e3ec0876b55c83f231615f7a904e33
      size: 7386
    - path: ddos/plots/merged.csv
      hash: md5
      md5: d176413946c2584e65ba0ca185fe74e5
      size: 2280519
    params:
      conf/plots.yaml:
        cat_plot:
        - file: symmetric_vs_compressor_metric.pdf
          x: Metric
          y: accuracy
          hue: Symmetric
          errorbar: se
          kind: boxen
          titles: ' '
          xlabels: Compressor
          ylabels: Accuracy
          legend_title: Metrics
          order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          hue_order:
          - Asymmetric
          - Symmetric
          rotation: 90
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: symmetric_vs_string_metric.pdf
          x: Metric
          y: accuracy
          hue: Symmetric
          errorbar: se
          kind: boxen
          titles: ' '
          xlabels: Compressors
          ylabels: Accuracy
          legend_title: ' '
          order:
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          hue_order:
          - Asymmetric
          - Symmetric
          rotation: 90
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: symmetric_vs_metric.pdf
          x: Metric
          y: accuracy
          hue: Symmetric
          errorbar: se
          kind: boxen
          titles: ' '
          xlabels: Compressors
          ylabels: Accuracy
          legend_title: ' '
          order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          hue_order:
          - Asymmetric
          - Symmetric
          rotation: 90
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: symmetric_vs_metric_train_time.pdf
          x: Metric
          y: train_time
          hue: Symmetric
          errorbar: se
          kind: boxen
          titles:
          xlabels: Metrics
          ylabels: Training Time (s)
          legend_title: Metrics
          order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          hue_order:
          - Asymmetric
          - Symmetric
          rotation: 90
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
          y_scale: linear
        - file: symmetric_vs_string_metric_train_time.pdf
          x: Metric
          y: train_time
          hue: Symmetric
          errorbar: se
          kind: boxen
          titles:
          xlabels: Compressors
          ylabels: Training Time (s)
          legend_title: String Metrics
          order:
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          hue_order:
          - Asymmetric
          - Symmetric
          rotation: 90
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: symmetric_vs_compressor_metric_train_time.pdf
          x: Metric
          y: train_time
          hue: Symmetric
          errorbar: se
          kind: boxen
          titles:
          xlabels: Compressors
          ylabels: Training Time (s)
          legend_title: Metrics
          order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          hue_order:
          - Asymmetric
          - Symmetric
          rotation: 90
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        line_plot:
        - file: compressor_metric_vs_accuracy.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: accuracy
          ylabel: Accuracy
          hue_order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: metric_vs_accuracy.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: accuracy
          ylabel: Accuracy
          hue_order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: string_metric_vs_accuracy.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: accuracy
          ylabel: Accuracy
          hue_order:
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: metric_vs_train_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: train_time
          ylabel: Training Time (s)
          y_scale: linear
          hue_order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: compressor_metric_vs_train_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: train_time
          ylabel: Training Time (s)
          y_scale: linear
          hue_order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: string_metric_vs_train_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: train_time
          ylabel: Training Time (s)
          y_scale: linear
          hue_order:
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: compressor_metric_vs_predict_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: predict_time
          ylabel: Prediction Time (s)
          y_scale: linear
          hue_order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
        - file: metric_vs_predict_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: predict_time
          ylabel: Prediction Time (s)
          y_scale: linear
          hue_order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
        - file: string_metric_vs_predict_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: predict_time
          ylabel: Prediction Time (s)
          y_scale: linear
          hue_order:
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          legend:
            title: Metrics
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
    outs:
    - path: ddos/plots/compressor_metric_vs_accuracy.pdf
      hash: md5
      md5: cd79fdc72d42189ffed94feeec05b5e8
      size: 20365
    - path: ddos/plots/metric_vs_accuracy.pdf
      hash: md5
      md5: fe668a87736885b135c034335af6106d
      size: 24491
    - path: ddos/plots/string_metric_vs_accuracy.pdf
      hash: md5
      md5: a70fbfc58675122ad983cb892134c946
      size: 21326
    - path: ddos/plots/symmetric_vs_compressor_metric.pdf
      hash: md5
      md5: 3c713dd693a601c9bb9a2d7e37f7150c
      size: 21079
    - path: ddos/plots/symmetric_vs_metric.pdf
      hash: md5
      md5: 2263eeced08e2e6856858db56dee0f7e
      size: 31219
    - path: ddos/plots/symmetric_vs_metric_train_time.pdf
      hash: md5
      md5: 842842ba71e38cbba9baec583835bb13
      size: 32216
    - path: ddos/plots/symmetric_vs_string_metric.pdf
      hash: md5
      md5: e98aaa91a81d49cef99cd1169752fe89
      size: 23138
    - path: ddos/plots/symmetric_vs_string_metric_train_time.pdf
      hash: md5
      md5: 6a1e302447bcb0c5ecc9b55aedbf547a
      size: 25087
  merge_condense@truthseeker:
    cmd: python merge.py --big_dir truthseeker/plots/ --data_file clean/condense/knn.csv
      --little_dir_data_file  clean/condense/logistic.csv clean/condense/svc.csv --output_folder
      truthseeker/plots/ --output_file condensed_merged.csv
    deps:
    - path: truthseeker/plots/clean/condense/knn.csv
      hash: md5
      md5: b752d13d0c4172c8d361171fc214e777
      size: 850685
    - path: truthseeker/plots/clean/condense/logistic.csv
      hash: md5
      md5: a6a33b3cb3d7e3e10d4353cc781c460d
      size: 334757
    - path: truthseeker/plots/clean/condense/svc.csv
      hash: md5
      md5: 78d6c744fe8b0f1577a604356e0ab29d
      size: 633673
    outs:
    - path: truthseeker/plots/condensed_merged.csv
      hash: md5
      md5: 063490f5338ec0ac80a2eb022ae273f2
      size: 1836572
  plot_condense@truthseeker:
    cmd: python -m deckard.layers.plots  --path truthseeker/plots/  --file truthseeker/plots/condensed_merged.csv  -c
      conf/condensed_plots.yaml
    deps:
    - path: conf/condensed_plots.yaml
      hash: md5
      md5: 662671583c33bcb6d99103ad6bf289d6
      size: 1916
    - path: truthseeker/plots/condensed_merged.csv
      hash: md5
      md5: 063490f5338ec0ac80a2eb022ae273f2
      size: 1836572
    params:
      conf/condensed_plots.yaml:
        cat_plot:
        - file: condensing_method_vs_accuracy.pdf
          digitize: Condensing Ratio
          x: Condensing Method
          hue: Condensing Ratio
          y: accuracy
          y_scale: linear
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
          kind: boxen
          col: Model
          rotation: 45
          order:
          - Random
          - Medoid
          - Sum
          - SVC
          - Hardness
          - NearMiss
          - KNN
          xticklabels:
          - Random
          - Medoid
          - Sum
          - SVC
          - Hardness
          - NearMiss
          - KNN
          xlabels: Condensing Method
          ylabels: Accuracy
          legend_title: Sample Ratio
        - file: condensing_method_vs_train_time.pdf
          x: Condensing Method
          hue: Condensing Ratio
          digitize: Condensing Ratio
          y: train_time
          y_scale: log
          kind: boxen
          col: Model
          rotation: 45
          order:
          - Random
          - Medoid
          - Sum
          - SVC
          - Hardness
          - NearMiss
          - KNN
          xticklabels:
          - Random
          - Medoid
          - Sum
          - SVC
          - Hardness
          - NearMiss
          - k-NN
          xlabels: Condensing Method
          ylabels: Training Time
          legend_title: Sample Ratio
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: condensing_method_vs_predict_time.pdf
          x: Condensing Method
          hue: Condensing Ratio
          digitize: Condensing Ratio
          y: predict_time
          y_scale: log
          col: Model
          rotation: 45
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
          kind: boxen
          order:
          - Random
          - Medoid
          - Sum
          - SVC
          - Hardness
          - NearMiss
          - KNN
          xticklabels:
          - Random
          - Medoid
          - Sum
          - SVC
          - Hardness
          - NearMiss
          - k-NN
          xlabels: Condensing Method
          ylabels: Prediction Time
          legend_title: Sample Ratio
    outs:
    - path: truthseeker/plots/condensing_method_vs_accuracy.pdf
      hash: md5
      md5: 8421bedad92bb668a906a3bec653099d
      size: 55860
    - path: truthseeker/plots/condensing_method_vs_predict_time.pdf
      hash: md5
      md5: af37fbf580ef16ef1a4c5c3db967d81a
      size: 78306
    - path: truthseeker/plots/condensing_method_vs_train_time.pdf
      hash: md5
      md5: 8dd58b8a48e86b63316cb5d535adbf76
      size: 77439
  copy@truthseeker:
    cmd: rm -rf ~/Gzip-KNN/figs/truthseeker/ && mkdir -p ~/Gzip-KNN/figs/truthseeker/
      && cp -r truthseeker/plots/* ~/Gzip-KNN/figs/truthseeker/ && rm -rf ~/Gzip-KNN/figs/truthseeker/.gitignore
    deps:
    - path: truthseeker/plots/
      hash: md5
      md5: e733b2de2d441ab93b766f930d43fdcd.dir
      size: 9118078
      nfiles: 26
  clean@ddos-condense/knn:
    cmd: python -m deckard.layers.clean_data  -i ddos/reports/condense/knn.csv -o
      ddos/plots/clean/condense/knn.csv -c conf/clean.yaml
    deps:
    - path: ddos/reports/condense/knn.csv
      hash: md5
      md5: 7a526d5c2cd6d10b1bdc6894f6c17217
      size: 1394408
    params:
      conf/clean.yaml:
        drop_values:
          accuracy: 0.0
          predict_time: 1.0
        replace:
          model.init.metric:
            jaro: Jaro
            _winkler: -Winkler
            levenshtein: Levenshtein
            ncd: NCD
            ratio: Ratio
            seqRatio: SeqRatio
            hamming: Hamming
            gzip: GZIP
            pkl: Pickle
            bz2: BZ2
            zstd: ZSTD
            lzma: LZMA
          model_name:
            GzipSVC: k-SVC
            GzipLogisticRegressor: k-Logistic
            GzipKNN: k-KNN
          model.init.symmetric:
            true: Symmetric
            false: Asymmetric
          model.init.sampling_method:
            random: Random
            medoid: Medoid
            sum: Sum
            svc: SVC
            hardness: Hardness
            nearmiss: NearMiss
            knn: KNN
          dataset:
            ddos: DDoS
            sms_spam: SMS Spam
            kdd_nsl: KDD NSL
            truthseeker: Truthseeker
          model.init.m:
            -1: 1
        replace_cols:
          dataset: Dataset
          model.init.metric: Metric
          model.init.symmetric: Symmetric
          model.init.sampling_method: Condensing Method
          model.init.m: Condensing Ratio
          model_name: Model
    outs:
    - path: ddos/plots/clean/condense/knn.csv
      hash: md5
      md5: a8ce24c3c2c77c7d2edef7bd031801e8
      size: 1051465
  clean@ddos-condense/logistic:
    cmd: python -m deckard.layers.clean_data  -i ddos/reports/condense/logistic.csv
      -o ddos/plots/clean/condense/logistic.csv -c conf/clean.yaml
    deps:
    - path: ddos/reports/condense/logistic.csv
      hash: md5
      md5: 6d9471c0d92c1df6a07fbcdb150496c7
      size: 1229006
    params:
      conf/clean.yaml:
        drop_values:
          accuracy: 0.0
          predict_time: 1.0
        replace:
          model.init.metric:
            jaro: Jaro
            _winkler: -Winkler
            levenshtein: Levenshtein
            ncd: NCD
            ratio: Ratio
            seqRatio: SeqRatio
            hamming: Hamming
            gzip: GZIP
            pkl: Pickle
            bz2: BZ2
            zstd: ZSTD
            lzma: LZMA
          model_name:
            GzipSVC: k-SVC
            GzipLogisticRegressor: k-Logistic
            GzipKNN: k-KNN
          model.init.symmetric:
            true: Symmetric
            false: Asymmetric
          model.init.sampling_method:
            random: Random
            medoid: Medoid
            sum: Sum
            svc: SVC
            hardness: Hardness
            nearmiss: NearMiss
            knn: KNN
          dataset:
            ddos: DDoS
            sms_spam: SMS Spam
            kdd_nsl: KDD NSL
            truthseeker: Truthseeker
          model.init.m:
            -1: 1
        replace_cols:
          dataset: Dataset
          model.init.metric: Metric
          model.init.symmetric: Symmetric
          model.init.sampling_method: Condensing Method
          model.init.m: Condensing Ratio
          model_name: Model
    outs:
    - path: ddos/plots/clean/condense/logistic.csv
      hash: md5
      md5: cbb8d6cd925852af2fc1882230cc52d6
      size: 412305
  merge_condense@ddos:
    cmd: python merge.py --big_dir ddos/plots/ --data_file clean/condense/knn.csv
      --little_dir_data_file  clean/condense/logistic.csv clean/condense/svc.csv --output_folder
      ddos/plots/ --output_file condensed_merged.csv
    deps:
    - path: ddos/plots/clean/condense/knn.csv
      hash: md5
      md5: a8ce24c3c2c77c7d2edef7bd031801e8
      size: 1051465
    - path: ddos/plots/clean/condense/logistic.csv
      hash: md5
      md5: cbb8d6cd925852af2fc1882230cc52d6
      size: 412305
    - path: ddos/plots/clean/condense/svc.csv
      hash: md5
      md5: b9163109d30bffa0d092b45bc94e600a
      size: 958897
    outs:
    - path: ddos/plots/condensed_merged.csv
      hash: md5
      md5: e068c0013b624033b64fba0e7879b74f
      size: 2446632
  plot_condense@ddos:
    cmd: python -m deckard.layers.plots  --path ddos/plots/  --file ddos/plots/condensed_merged.csv  -c
      conf/condensed_plots.yaml
    deps:
    - path: conf/condensed_plots.yaml
      hash: md5
      md5: 662671583c33bcb6d99103ad6bf289d6
      size: 1916
    - path: ddos/plots/condensed_merged.csv
      hash: md5
      md5: e068c0013b624033b64fba0e7879b74f
      size: 2446632
    params:
      conf/condensed_plots.yaml:
        cat_plot:
        - file: condensing_method_vs_accuracy.pdf
          digitize: Condensing Ratio
          x: Condensing Method
          hue: Condensing Ratio
          y: accuracy
          y_scale: linear
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
          kind: boxen
          col: Model
          rotation: 45
          order:
          - Random
          - Medoid
          - Sum
          - SVC
          - Hardness
          - NearMiss
          - KNN
          xticklabels:
          - Random
          - Medoid
          - Sum
          - SVC
          - Hardness
          - NearMiss
          - KNN
          xlabels: Condensing Method
          ylabels: Accuracy
          legend_title: Sample Ratio
        - file: condensing_method_vs_train_time.pdf
          x: Condensing Method
          hue: Condensing Ratio
          digitize: Condensing Ratio
          y: train_time
          y_scale: log
          kind: boxen
          col: Model
          rotation: 45
          order:
          - Random
          - Medoid
          - Sum
          - SVC
          - Hardness
          - NearMiss
          - KNN
          xticklabels:
          - Random
          - Medoid
          - Sum
          - SVC
          - Hardness
          - NearMiss
          - k-NN
          xlabels: Condensing Method
          ylabels: Training Time
          legend_title: Sample Ratio
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: condensing_method_vs_predict_time.pdf
          x: Condensing Method
          hue: Condensing Ratio
          digitize: Condensing Ratio
          y: predict_time
          y_scale: log
          col: Model
          rotation: 45
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
          kind: boxen
          order:
          - Random
          - Medoid
          - Sum
          - SVC
          - Hardness
          - NearMiss
          - KNN
          xticklabels:
          - Random
          - Medoid
          - Sum
          - SVC
          - Hardness
          - NearMiss
          - k-NN
          xlabels: Condensing Method
          ylabels: Prediction Time
          legend_title: Sample Ratio
    outs:
    - path: ddos/plots/condensing_method_vs_accuracy.pdf
      hash: md5
      md5: 5ef239d4f8e01ede2fbb5951c5f9284e
      size: 57600
    - path: ddos/plots/condensing_method_vs_predict_time.pdf
      hash: md5
      md5: 5ebef81c2de19d2d943041e2aa30417a
      size: 86093
    - path: ddos/plots/condensing_method_vs_train_time.pdf
      hash: md5
      md5: 730e30bad8b430abadbbb1dd4742e9e5
      size: 85052
  plot_condense@kdd_nsl:
    cmd: python -m deckard.layers.plots  --path kdd_nsl/plots/  --file kdd_nsl/plots/condensed_merged.csv  -c
      conf/condensed_plots.yaml
    deps:
    - path: conf/condensed_plots.yaml
      hash: md5
      md5: 662671583c33bcb6d99103ad6bf289d6
      size: 1916
    - path: kdd_nsl/plots/condensed_merged.csv
      hash: md5
      md5: deca13c3508d89c9a2c6ee0dbdb94ae3
      size: 2646816
    params:
      conf/condensed_plots.yaml:
        cat_plot:
        - file: condensing_method_vs_accuracy.pdf
          digitize: Condensing Ratio
          x: Condensing Method
          hue: Condensing Ratio
          y: accuracy
          y_scale: linear
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
          kind: boxen
          col: Model
          rotation: 45
          order:
          - Random
          - Medoid
          - Sum
          - SVC
          - Hardness
          - NearMiss
          - KNN
          xticklabels:
          - Random
          - Medoid
          - Sum
          - SVC
          - Hardness
          - NearMiss
          - KNN
          xlabels: Condensing Method
          ylabels: Accuracy
          legend_title: Sample Ratio
        - file: condensing_method_vs_train_time.pdf
          x: Condensing Method
          hue: Condensing Ratio
          digitize: Condensing Ratio
          y: train_time
          y_scale: log
          kind: boxen
          col: Model
          rotation: 45
          order:
          - Random
          - Medoid
          - Sum
          - SVC
          - Hardness
          - NearMiss
          - KNN
          xticklabels:
          - Random
          - Medoid
          - Sum
          - SVC
          - Hardness
          - NearMiss
          - k-NN
          xlabels: Condensing Method
          ylabels: Training Time
          legend_title: Sample Ratio
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
        - file: condensing_method_vs_predict_time.pdf
          x: Condensing Method
          hue: Condensing Ratio
          digitize: Condensing Ratio
          y: predict_time
          y_scale: log
          col: Model
          rotation: 45
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
          kind: boxen
          order:
          - Random
          - Medoid
          - Sum
          - SVC
          - Hardness
          - NearMiss
          - KNN
          xticklabels:
          - Random
          - Medoid
          - Sum
          - SVC
          - Hardness
          - NearMiss
          - k-NN
          xlabels: Condensing Method
          ylabels: Prediction Time
          legend_title: Sample Ratio
    outs:
    - path: kdd_nsl/plots/condensing_method_vs_accuracy.pdf
      hash: md5
      md5: e53e0d7b9118bf2b59407cc7a4f5837b
      size: 59251
    - path: kdd_nsl/plots/condensing_method_vs_predict_time.pdf
      hash: md5
      md5: e1ec3bc19fe7774e7ac4d0951c559a0c
      size: 87393
    - path: kdd_nsl/plots/condensing_method_vs_train_time.pdf
      hash: md5
      md5: ddfd6d614a9be076154b1f318466729b
      size: 86468
  plot_merged:
    cmd: python -m deckard.layers.plots  --path combined/plots/  --file combined/plots/merged.csv  -c
      conf/merged_plots.yaml
    deps:
    - path: combined/plots/merged.csv
      hash: md5
      md5: f113844c930e28200b28863f468ecb19
      size: 18484178
    - path: conf/merged_plots.yaml
      hash: md5
      md5: ccfd0355b120e57e17581c0f4b67e493
      size: 8297
    params:
      conf/merged_plots.yaml:
        cat_plot:
        - file: models_vs_accuracy.pdf
          x: Model
          y: accuracy
          hue: data.sample.train_size
          errorbar: se
          kind: boxen
          titles:
          xlabels: ' '
          ylabels: Accuracy
          legend_title: Samples
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
          rotation: 90
          col: Dataset
          order:
          - k-KNN
          - k-SVC
          - k-Logistic
          col_order:
          - DDoS
          - SMS Spam
          - KDD NSL
          - Truthseeker
        - file: models_vs_train_time.pdf
          x: Model
          y: train_time
          hue: data.sample.train_size
          errorbar: se
          kind: boxen
          titles:
          xlabels: ' '
          ylabels: $t_t$ (s)
          legend_title: Samples
          rotation: 90
          col: Dataset
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
          y_scale: log
          order:
          - k-KNN
          - k-SVC
          - k-Logistic
          col_order:
          - DDoS
          - SMS Spam
          - KDD NSL
          - Truthseeker
        - file: models_vs_predict_time.pdf
          x: Model
          y: predict_time_per_sample
          hue: data.sample.train_size
          errorbar: se
          kind: boxen
          titles:
          xlabels: ' '
          ylabels: $t_i$ (s)
          legend_title: Samples
          col: Dataset
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
          rotation: 90
          y_scale: log
          order:
          - k-KNN
          - k-SVC
          - k-Logistic
          col_order:
          - DDoS
          - SMS Spam
          - KDD NSL
          - Truthseeker
        - file: symmetric_models_vs_accuracy.pdf
          row: Model
          x: data.sample.train_size
          y: accuracy
          hue: Symmetric
          errorbar: se
          kind: boxen
          titles:
          xlabels: Samples
          ylabels: Accuracy
          legend_title: ' '
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
          rotation: 90
          col: Dataset
          col_order:
          - DDoS
          - SMS Spam
          - KDD NSL
          - Truthseeker
          row_order:
          - k-KNN
          - k-SVC
          - k-Logistic
        - file: symmetric_models_vs_train_time.pdf
          row: Model
          x: data.sample.train_size
          y: train_time_per_sample
          hue: Symmetric
          errorbar: se
          kind: boxen
          titles:
          xlabels: ' '
          ylabels: $t_t$ (s)
          legend_title: ' '
          rotation: 90
          col: Dataset
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
          y_scale: log
          col_order:
          - DDoS
          - SMS Spam
          - KDD NSL
          - Truthseeker
          row_order:
          - k-KNN
          - k-SVC
          - k-Logistic
        - file: symmetric_models_vs_predict_time.pdf
          x: data.sample.train_size
          row: Model
          y: predict_time_per_sample
          hue: Symmetric
          errorbar: se
          kind: boxen
          titles:
          xlabels: ' '
          ylabels: $t_i$ (s)
          legend_title: ' '
          col: Dataset
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
          rotation: 90
          y_scale: log
          col_order:
          - DDoS
          - SMS Spam
          - KDD NSL
          - Truthseeker
          row_order:
          - k-KNN
          - k-SVC
          - k-Logistic
        - file: condensing_methods_vs_accuracy.pdf
          x: Model
          y: accuracy
          hue: Condensing Method
          errorbar: se
          kind: boxen
          titles:
          xlabels: ' '
          ylabels: Accuracy
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
          rotation: 90
          col: Dataset
          col_order:
          - DDoS
          - SMS Spam
          - KDD NSL
          - Truthseeker
          order:
          - k-KNN
          - k-SVC
          - k-Logistic
          legend_title: Condensing Method
        - file: condensing_methods_vs_train_time.pdf
          x: Model
          y: train_time
          hue: Condensing Method
          errorbar: se
          kind: boxen
          titles:
          xlabels: ' '
          ylabels: $t_t$ (s)
          legend_title: Condensing Method
          rotation: 90
          col: Dataset
          y_scale: log
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
          col_order:
          - DDoS
          - SMS Spam
          - KDD NSL
          - Truthseeker
          order:
          - k-KNN
          - k-SVC
          - k-Logistic
        - file: condensing_methods_vs_predict_time.pdf
          x: Model
          y: predict_time_per_sample
          hue: Condensing Method
          errorbar: se
          kind: boxen
          titles:
          xlabels: ' '
          ylabels: $t_i$ (s)
          legend_title: Condensing Method
          col: Dataset
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 14
          rotation: 90
          y_scale: log
          col_order:
          - DDoS
          - SMS Spam
          - KDD NSL
          - Truthseeker
          order:
          - k-KNN
          - k-SVC
          - k-Logistic
        line_plot:
        - file: compressor_metric_vs_accuracy.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: accuracy
          ylabel: Accuracy
          hue_order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          style: Dataset
          style_order:
          - DDoS
          - SMS Spam
          - KDD NSL
          - Truthseeker
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 12
        - file: string_metric_vs_accuracy.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: accuracy
          ylabel: Accuracy
          hue_order:
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          style: Dataset
          style_order:
          - DDoS
          - SMS Spam
          - KDD NSL
          - Truthseeker
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 12
        - file: string_metric_vs_train_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: train_time
          ylabel: $t_t$ (s)
          hue_order:
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          style: Dataset
          style_order:
          - DDoS
          - SMS Spam
          - KDD NSL
          - Truthseeker
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 12
          y_scale: log
        - file: compressor_metric_vs_train_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: train_time
          ylabel: $t_t$ (s)
          hue_order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          style: Dataset
          style_order:
          - DDoS
          - SMS Spam
          - KDD NSL
          - Truthseeker
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 12
          y_scale: log
        - file: string_metric_vs_predict_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: predict_time_per_sample
          ylabel: $t_i$ (s)
          hue_order:
          - Levenshtein
          - Ratio
          - Hamming
          - Jaro
          - Jaro-Winkler
          - SeqRatio
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          style: Dataset
          style_order:
          - DDoS
          - SMS Spam
          - KDD NSL
          - Truthseeker
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 12
          y_scale: log
        - file: compressor_metric_vs_predict_time.pdf
          hue: Metric
          title:
          x: data.sample.train_size
          xlabel: Number of Training Samples
          y: predict_time_per_sample
          ylabel: $t_i$ (s)
          hue_order:
          - GZIP
          - Pickle
          - BZ2
          - ZSTD
          - LZMA
          errorbar: se
          err_style: bars
          xlim:
          - 10
          - 500
          style: Dataset
          style_order:
          - DDoS
          - SMS Spam
          - KDD NSL
          - Truthseeker
          legend:
            bbox_to_anchor:
            - 1.05
            - 0.5
            loc: center left
            prop:
              size: 12
          y_scale: log
    outs:
    - path: combined/plots/compressor_metric_vs_accuracy.pdf
      hash: md5
      md5: a34af68e5015e2a5000afbeb15c47738
      size: 23056
    - path: combined/plots/compressor_metric_vs_predict_time.pdf
      hash: md5
      md5: 510835d44da8c68f91e35382bc5d96a3
      size: 23742
    - path: combined/plots/compressor_metric_vs_train_time.pdf
      hash: md5
      md5: 6231293f7caa94317f1464e5f90cfc36
      size: 23784
    - path: combined/plots/condensing_methods_vs_accuracy.pdf
      hash: md5
      md5: 47c8b12d23c7a85f30bf1c1393268513
      size: 48138
    - path: combined/plots/condensing_methods_vs_predict_time.pdf
      hash: md5
      md5: 9ddad1954e308c047afe04f13e93c251
      size: 72945
    - path: combined/plots/condensing_methods_vs_train_time.pdf
      hash: md5
      md5: 8000647f3c71cbf9d5ad933d997bd9ce
      size: 69491
    - path: combined/plots/models_vs_accuracy.pdf
      hash: md5
      md5: 7cb4a6db4455b85d67cd2dd1c0655d48
      size: 41292
    - path: combined/plots/models_vs_predict_time.pdf
      hash: md5
      md5: 3ae42d80dcea06015ce7d4b3efbaad0e
      size: 51046
    - path: combined/plots/models_vs_train_time.pdf
      hash: md5
      md5: 159f3e30b0bd30ebd254578a6f43a25c
      size: 50441
    - path: combined/plots/string_metric_vs_accuracy.pdf
      hash: md5
      md5: 20b4f31de5a6730ba69f8fdd34c3d48c
      size: 24156
    - path: combined/plots/string_metric_vs_predict_time.pdf
      hash: md5
      md5: bcd9e857bc7f671956b3558e0ccc56b6
      size: 24457
    - path: combined/plots/string_metric_vs_train_time.pdf
      hash: md5
      md5: 91240f65ea01fa61e9c8cb70e74fed9d
      size: 24473
    - path: combined/plots/symmetric_models_vs_accuracy.pdf
      hash: md5
      md5: 62b904b0e337c59fcfc841a7843b71a6
      size: 59288
    - path: combined/plots/symmetric_models_vs_predict_time.pdf
      hash: md5
      md5: fd71bc62a26d9acc677ddc2445c1d473
      size: 77721
    - path: combined/plots/symmetric_models_vs_train_time.pdf
      hash: md5
      md5: 2e66c3579f4e7c9a87636b5768cc45d2
      size: 77838
  copy@combined:
    cmd: rm -rf ~/Gzip-KNN/figs/combined/ && mkdir -p ~/Gzip-KNN/figs/combined/ &&
      cp -r combined/plots/* ~/Gzip-KNN/figs/combined/ && rm -rf ~/Gzip-KNN/figs/combined/.gitignore
    deps:
    - path: combined/plots/
      hash: md5
      md5: 950785f3917e8f8c7e5373ddbaeab572.dir
      size: 19176046
      nfiles: 16
  copy@ddos:
    cmd: rm -rf ~/Gzip-KNN/figs/ddos/ && mkdir -p ~/Gzip-KNN/figs/ddos/ && cp -r ddos/plots/*
      ~/Gzip-KNN/figs/ddos/ && rm -rf ~/Gzip-KNN/figs/ddos/.gitignore
    deps:
    - path: ddos/plots/
      hash: md5
      md5: e670c73817649a73c131d09298575a27.dir
      size: 9984576
      nfiles: 26
  copy@kdd_nsl:
    cmd: rm -rf ~/Gzip-KNN/figs/kdd_nsl/ && mkdir -p ~/Gzip-KNN/figs/kdd_nsl/ && cp
      -r kdd_nsl/plots/* ~/Gzip-KNN/figs/kdd_nsl/ && rm -rf ~/Gzip-KNN/figs/kdd_nsl/.gitignore
    deps:
    - path: kdd_nsl/plots/
      hash: md5
      md5: 92bd801bcc6150d862492af1ae617eb4.dir
      size: 10383071
      nfiles: 26
  clean_merged:
    cmd: python -m deckard.layers.clean_data  -i combined/plots/merged.csv -o combined/plots/clean_merged.csv
      -c conf/clean.yaml
    deps:
    - path: combined/plots/merged.csv
      hash: md5
      md5: 14b7b6d947a96066ff2ad028680511d5
      size: 33462041
    - path: conf/clean.yaml
      hash: md5
      md5: 3fdcad8f5751398ace2b94aaa74e4e18
      size: 1023
    params:
      conf/clean.yaml:
        drop_values:
          accuracy: 0.0
          predict_time: 1.0
        replace:
          model.init.metric:
            jaro: Jaro
            _winkler: -Winkler
            levenshtein: Levenshtein
            ncd: NCD
            ratio: Ratio
            seqRatio: SeqRatio
            hamming: Hamming
            gzip: GZIP
            pkl: Pickle
            bz2: BZ2
            zstd: ZSTD
            lzma: LZMA
          model_name:
            GzipSVC: k-SVC
            GzipLogisticRegressor: k-Logistic
            GzipKNN: k-KNN
          model.init.symmetric:
            true: Symmetric
            false: Asymmetric
          model.init.sampling_method:
            random: Random
            medoid: Medoid
            sum: Sum
            svc: SVC
            hardness: Hardness
            nearmiss: NearMiss
            knn: KNN
          dataset:
            ddos: DDoS
            sms_spam: SMS Spam
            kdd_nsl: KDD NSL
            truthseeker: Truthseeker
          model.init.m:
            -1: 1
        replace_cols:
          dataset: Dataset
          model.init.metric: Metric
          model.init.symmetric: Symmetric
          model.init.sampling_method: Condensing Method
          model.init.m: Condensing Ratio
          model_name: Model
    outs:
    - path: combined/plots/clean_merged.csv
      hash: md5
      md5: c156f464018e66193d396f270be55786
      size: 33579589
  data:
    cmd: python data_prep.py
    deps:
    - path: data_prep.py
      hash: md5
      md5: 18244c921ed2d7cbf25b8362b3ca33aa
      size: 5146
    outs:
    - path: raw_data/
      hash: md5
      md5: 33d46673e0631bef98be9e8991ed1ed1.dir
      size: 50328647
      nfiles: 8
  parse_params:
    cmd: python -m deckard.layers.parse
    deps:
    - path: conf/data/default.yaml
      hash: md5
      md5: 86639d6672cfd9529dda3e2ae4036c01
      size: 22
    - path: conf/default.yaml
      hash: md5
      md5: a0a533f84a7ffce197e0db5439219faf
      size: 1504
    - path: conf/files/default.yaml
      hash: md5
      md5: 7a2df5f8b98699376c3fb4da05d70dea
      size: 306
    - path: conf/model/default.yaml
      hash: md5
      md5: 39dc7512b1d19fea54550b080d880153
      size: 27
    - path: conf/scorers/default.yaml
      hash: md5
      md5: d8d00e7d284ea68b1244743dfef8f00c
      size: 280
    outs:
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
  train:
    cmd: python -m deckard.layers.experiment train
    deps:
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    - path: raw_data/
      hash: md5
      md5: 33d46673e0631bef98be9e8991ed1ed1.dir
      size: 50328647
      nfiles: 8
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          drop:
          - id
          name: raw_data/kdd_nsl_undersampled_5000.csv
          sample:
            _target_: deckard.base.data.SklearnDataSampler
            random_state: 0
            stratify: true
            test_size: 100
            train_size: 100
          target: label
        dataset: kdd_nsl
        device_id: cpu
        files:
          _target_: deckard.base.files.FileConfig
          data_dir: data
          data_type: .csv
          directory: kdd_nsl
          model_dir: model
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          reports: reports
          score_dict_file: score_dict.json
        model:
          _target_: deckard.base.model.Model
          data:
            _target_: deckard.base.data.Data
            drop:
            - id
            name: raw_data/kdd_nsl_undersampled_5000.csv
            sample:
              _target_: deckard.base.data.SklearnDataSampler
              random_state: 0
              stratify: true
              test_size: 100
              train_size: 100
            target: label
          init:
            _target_: deckard.base.model.ModelInitializer
            distance_matrix: kdd_nsl/model/gzip/100-100/0.npz
            k: 1
            m: -1
            metric: gzip
            name: gzip_classifier.GzipKNN
            symmetric: false
          library: sklearn
        model_name: gzip_knn
        scorers:
          _target_: deckard.base.scorer.ScorerDict
          accuracy:
            _target_: deckard.base.scorer.ScorerConfig
            direction: maximize
            name: sklearn.metrics.accuracy_score
          log_loss:
            _target_: deckard.base.scorer.ScorerConfig
            direction: minimize
            name: sklearn.metrics.log_loss
    outs:
    - path: kdd_nsl/reports/train/default/predictions.json
      hash: md5
      md5: 986d2f0abe9b96253b196a222a550609
      size: 702
    - path: kdd_nsl/reports/train/default/score_dict.json
      hash: md5
      md5: 492e1219d803759a686caa2859c91d21
      size: 485
  test_each_model@gzip-gzip_logistic-sms_spam-20:
    cmd: 'python -m deckard.layers.optimise  stage=test_each_model  files.name=gzip_logistic/gzip/20
      files.directory=sms_spam data=sms_spam data.sample.train_size=20 dataset=sms_spam
      model=gzip_logistic model_name=gzip_knn model.init.metric=gzip  model.init.m=-1
      hydra.run.dir=sms_spam/logs/test_each_model/gzip_logistic/gzip/20 ++raise_exception=True '
    deps:
    - path: kdd_nsl/reports/train/default/score_dict.json
      hash: md5
      md5: ee4344da4a735fb0b6e6d2cf83ddef6e
      size: 484
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          drop:
          - id
          name: raw_data/kdd_nsl_undersampled_5000.csv
          sample:
            _target_: deckard.base.data.SklearnDataSampler
            random_state: 0
            stratify: true
            test_size: 100
            train_size: 100
          target: label
        dataset: kdd_nsl
        device_id: cpu
        files:
          _target_: deckard.base.files.FileConfig
          data_dir: data
          data_type: .csv
          directory: kdd_nsl
          model_dir: model
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          reports: reports
          score_dict_file: score_dict.json
        model:
          _target_: deckard.base.model.Model
          data:
            _target_: deckard.base.data.Data
            drop:
            - id
            name: raw_data/kdd_nsl_undersampled_5000.csv
            sample:
              _target_: deckard.base.data.SklearnDataSampler
              random_state: 0
              stratify: true
              test_size: 100
              train_size: 100
            target: label
          init:
            _target_: deckard.base.model.ModelInitializer
            distance_matrix: kdd_nsl/model/gzip/100-100/0.npz
            k: 1
            m: -1
            metric: gzip
            name: gzip_classifier.GzipKNN
            symmetric: false
          library: sklearn
        model_name: gzip_knn
        scorers:
          _target_: deckard.base.scorer.ScorerDict
          accuracy:
            _target_: deckard.base.scorer.ScorerConfig
            direction: maximize
            name: sklearn.metrics.accuracy_score
          log_loss:
            _target_: deckard.base.scorer.ScorerConfig
            direction: minimize
            name: sklearn.metrics.log_loss
    outs:
    - path: sms_spam/logs/test_each_model/gzip_logistic/gzip/20
      hash: md5
      md5: d121a07eb6c0e96c7cd18fe1f2d0fbd6.dir
      size: 7950
      nfiles: 4
    - path: sms_spam/reports/test_each_model/gzip_logistic/gzip/20/score_dict.json
      hash: md5
      md5: 5d8bf090bc8e34df8ed01766adfca5eb
      size: 26
  test_each_model@gzip-gzip_knn-ddos-20:
    cmd: 'python -m deckard.layers.optimise  stage=test_each_model  files.name=gzip_knn/gzip/20
      files.directory=ddos data=ddos data.sample.train_size=20 dataset=ddos model=gzip_knn
      model_name=gzip_knn model.init.metric=gzip  model.init.m=-1 hydra.run.dir=ddos/logs/test_each_model/gzip_knn/gzip/20
      ++raise_exception=True '
    deps:
    - path: kdd_nsl/reports/train/default/score_dict.json
      hash: md5
      md5: ee4344da4a735fb0b6e6d2cf83ddef6e
      size: 484
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          drop:
          - id
          name: raw_data/kdd_nsl_undersampled_5000.csv
          sample:
            _target_: deckard.base.data.SklearnDataSampler
            random_state: 0
            stratify: true
            test_size: 100
            train_size: 100
          target: label
        dataset: kdd_nsl
        device_id: cpu
        files:
          _target_: deckard.base.files.FileConfig
          data_dir: data
          data_type: .csv
          directory: kdd_nsl
          model_dir: model
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          reports: reports
          score_dict_file: score_dict.json
        model:
          _target_: deckard.base.model.Model
          data:
            _target_: deckard.base.data.Data
            drop:
            - id
            name: raw_data/kdd_nsl_undersampled_5000.csv
            sample:
              _target_: deckard.base.data.SklearnDataSampler
              random_state: 0
              stratify: true
              test_size: 100
              train_size: 100
            target: label
          init:
            _target_: deckard.base.model.ModelInitializer
            distance_matrix: kdd_nsl/model/gzip/100-100/0.npz
            k: 1
            m: -1
            metric: gzip
            name: gzip_classifier.GzipKNN
            symmetric: false
          library: sklearn
        model_name: gzip_knn
        scorers:
          _target_: deckard.base.scorer.ScorerDict
          accuracy:
            _target_: deckard.base.scorer.ScorerConfig
            direction: maximize
            name: sklearn.metrics.accuracy_score
          log_loss:
            _target_: deckard.base.scorer.ScorerConfig
            direction: minimize
            name: sklearn.metrics.log_loss
    outs:
    - path: ddos/logs/test_each_model/gzip_knn/gzip/20
      hash: md5
      md5: 3a4d1598b93a5a00ffd486b26a568475.dir
      size: 7826
      nfiles: 4
    - path: ddos/reports/test_each_model/gzip_knn/gzip/20/score_dict.json
      hash: md5
      md5: 5d8bf090bc8e34df8ed01766adfca5eb
      size: 26
  test_each_model@gzip-gzip_svc-sms_spam-20:
    cmd: 'python -m deckard.layers.optimise  stage=test_each_model  files.name=gzip_svc/gzip/20
      files.directory=sms_spam data=sms_spam data.sample.train_size=20 dataset=sms_spam
      model=gzip_svc model_name=gzip_knn model.init.metric=gzip  model.init.m=-1 hydra.run.dir=sms_spam/logs/test_each_model/gzip_svc/gzip/20
      ++raise_exception=True '
    deps:
    - path: kdd_nsl/reports/train/default/score_dict.json
      hash: md5
      md5: ee4344da4a735fb0b6e6d2cf83ddef6e
      size: 484
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          drop:
          - id
          name: raw_data/kdd_nsl_undersampled_5000.csv
          sample:
            _target_: deckard.base.data.SklearnDataSampler
            random_state: 0
            stratify: true
            test_size: 100
            train_size: 100
          target: label
        dataset: kdd_nsl
        device_id: cpu
        files:
          _target_: deckard.base.files.FileConfig
          data_dir: data
          data_type: .csv
          directory: kdd_nsl
          model_dir: model
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          reports: reports
          score_dict_file: score_dict.json
        model:
          _target_: deckard.base.model.Model
          data:
            _target_: deckard.base.data.Data
            drop:
            - id
            name: raw_data/kdd_nsl_undersampled_5000.csv
            sample:
              _target_: deckard.base.data.SklearnDataSampler
              random_state: 0
              stratify: true
              test_size: 100
              train_size: 100
            target: label
          init:
            _target_: deckard.base.model.ModelInitializer
            distance_matrix: kdd_nsl/model/gzip/100-100/0.npz
            k: 1
            m: -1
            metric: gzip
            name: gzip_classifier.GzipKNN
            symmetric: false
          library: sklearn
        model_name: gzip_knn
        scorers:
          _target_: deckard.base.scorer.ScorerDict
          accuracy:
            _target_: deckard.base.scorer.ScorerConfig
            direction: maximize
            name: sklearn.metrics.accuracy_score
          log_loss:
            _target_: deckard.base.scorer.ScorerConfig
            direction: minimize
            name: sklearn.metrics.log_loss
    outs:
    - path: sms_spam/logs/test_each_model/gzip_svc/gzip/20
      hash: md5
      md5: ac59a56d56834986ab013ff5cb6b4448.dir
      size: 7861
      nfiles: 4
    - path: sms_spam/reports/test_each_model/gzip_svc/gzip/20/score_dict.json
      hash: md5
      md5: 5d8bf090bc8e34df8ed01766adfca5eb
      size: 26
  test_each_model@gzip-gzip_knn-sms_spam-20:
    cmd: 'python -m deckard.layers.optimise  stage=test_each_model  files.name=gzip_knn/gzip/20
      files.directory=sms_spam data=sms_spam data.sample.train_size=20 dataset=sms_spam
      model=gzip_knn model_name=gzip_knn model.init.metric=gzip  model.init.m=-1 hydra.run.dir=sms_spam/logs/test_each_model/gzip_knn/gzip/20
      ++raise_exception=True '
    deps:
    - path: kdd_nsl/reports/train/default/score_dict.json
      hash: md5
      md5: ee4344da4a735fb0b6e6d2cf83ddef6e
      size: 484
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          drop:
          - id
          name: raw_data/kdd_nsl_undersampled_5000.csv
          sample:
            _target_: deckard.base.data.SklearnDataSampler
            random_state: 0
            stratify: true
            test_size: 100
            train_size: 100
          target: label
        dataset: kdd_nsl
        device_id: cpu
        files:
          _target_: deckard.base.files.FileConfig
          data_dir: data
          data_type: .csv
          directory: kdd_nsl
          model_dir: model
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          reports: reports
          score_dict_file: score_dict.json
        model:
          _target_: deckard.base.model.Model
          data:
            _target_: deckard.base.data.Data
            drop:
            - id
            name: raw_data/kdd_nsl_undersampled_5000.csv
            sample:
              _target_: deckard.base.data.SklearnDataSampler
              random_state: 0
              stratify: true
              test_size: 100
              train_size: 100
            target: label
          init:
            _target_: deckard.base.model.ModelInitializer
            distance_matrix: kdd_nsl/model/gzip/100-100/0.npz
            k: 1
            m: -1
            metric: gzip
            name: gzip_classifier.GzipKNN
            symmetric: false
          library: sklearn
        model_name: gzip_knn
        scorers:
          _target_: deckard.base.scorer.ScorerDict
          accuracy:
            _target_: deckard.base.scorer.ScorerConfig
            direction: maximize
            name: sklearn.metrics.accuracy_score
          log_loss:
            _target_: deckard.base.scorer.ScorerConfig
            direction: minimize
            name: sklearn.metrics.log_loss
    outs:
    - path: sms_spam/logs/test_each_model/gzip_knn/gzip/20
      hash: md5
      md5: 4eaee5c6d9a4ad7d474938026f330e8c.dir
      size: 7858
      nfiles: 4
    - path: sms_spam/reports/test_each_model/gzip_knn/gzip/20/score_dict.json
      hash: md5
      md5: 5d8bf090bc8e34df8ed01766adfca5eb
      size: 26
  test_each_model@gzip-gzip_svc-truthseeker-20:
    cmd: 'python -m deckard.layers.optimise  stage=test_each_model  files.name=gzip_svc/gzip/20
      files.directory=truthseeker data=truthseeker data.sample.train_size=20 dataset=truthseeker
      model=gzip_svc model_name=gzip_knn model.init.metric=gzip  model.init.m=-1 hydra.run.dir=truthseeker/logs/test_each_model/gzip_svc/gzip/20
      ++raise_exception=True '
    deps:
    - path: kdd_nsl/reports/train/default/score_dict.json
      hash: md5
      md5: ee4344da4a735fb0b6e6d2cf83ddef6e
      size: 484
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          drop:
          - id
          name: raw_data/kdd_nsl_undersampled_5000.csv
          sample:
            _target_: deckard.base.data.SklearnDataSampler
            random_state: 0
            stratify: true
            test_size: 100
            train_size: 100
          target: label
        dataset: kdd_nsl
        device_id: cpu
        files:
          _target_: deckard.base.files.FileConfig
          data_dir: data
          data_type: .csv
          directory: kdd_nsl
          model_dir: model
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          reports: reports
          score_dict_file: score_dict.json
        model:
          _target_: deckard.base.model.Model
          data:
            _target_: deckard.base.data.Data
            drop:
            - id
            name: raw_data/kdd_nsl_undersampled_5000.csv
            sample:
              _target_: deckard.base.data.SklearnDataSampler
              random_state: 0
              stratify: true
              test_size: 100
              train_size: 100
            target: label
          init:
            _target_: deckard.base.model.ModelInitializer
            distance_matrix: kdd_nsl/model/gzip/100-100/0.npz
            k: 1
            m: -1
            metric: gzip
            name: gzip_classifier.GzipKNN
            symmetric: false
          library: sklearn
        model_name: gzip_knn
        scorers:
          _target_: deckard.base.scorer.ScorerDict
          accuracy:
            _target_: deckard.base.scorer.ScorerConfig
            direction: maximize
            name: sklearn.metrics.accuracy_score
          log_loss:
            _target_: deckard.base.scorer.ScorerConfig
            direction: minimize
            name: sklearn.metrics.log_loss
    outs:
    - path: truthseeker/logs/test_each_model/gzip_svc/gzip/20
      hash: md5
      md5: 5fb0774e1c5387d988a28d68900d7d02.dir
      size: 7924
      nfiles: 4
    - path: truthseeker/reports/test_each_model/gzip_svc/gzip/20/score_dict.json
      hash: md5
      md5: 5d8bf090bc8e34df8ed01766adfca5eb
      size: 26
  test_each_model@gzip-gzip_logistic-kdd_nsl-20:
    cmd: 'python -m deckard.layers.optimise  stage=test_each_model  files.name=gzip_logistic/gzip/20
      files.directory=kdd_nsl data=kdd_nsl data.sample.train_size=20 dataset=kdd_nsl
      model=gzip_logistic model_name=gzip_knn model.init.metric=gzip  model.init.m=-1
      hydra.run.dir=kdd_nsl/logs/test_each_model/gzip_logistic/gzip/20 ++raise_exception=True '
    deps:
    - path: kdd_nsl/reports/train/default/score_dict.json
      hash: md5
      md5: ee4344da4a735fb0b6e6d2cf83ddef6e
      size: 484
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          drop:
          - id
          name: raw_data/kdd_nsl_undersampled_5000.csv
          sample:
            _target_: deckard.base.data.SklearnDataSampler
            random_state: 0
            stratify: true
            test_size: 100
            train_size: 100
          target: label
        dataset: kdd_nsl
        device_id: cpu
        files:
          _target_: deckard.base.files.FileConfig
          data_dir: data
          data_type: .csv
          directory: kdd_nsl
          model_dir: model
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          reports: reports
          score_dict_file: score_dict.json
        model:
          _target_: deckard.base.model.Model
          data:
            _target_: deckard.base.data.Data
            drop:
            - id
            name: raw_data/kdd_nsl_undersampled_5000.csv
            sample:
              _target_: deckard.base.data.SklearnDataSampler
              random_state: 0
              stratify: true
              test_size: 100
              train_size: 100
            target: label
          init:
            _target_: deckard.base.model.ModelInitializer
            distance_matrix: kdd_nsl/model/gzip/100-100/0.npz
            k: 1
            m: -1
            metric: gzip
            name: gzip_classifier.GzipKNN
            symmetric: false
          library: sklearn
        model_name: gzip_knn
        scorers:
          _target_: deckard.base.scorer.ScorerDict
          accuracy:
            _target_: deckard.base.scorer.ScorerConfig
            direction: maximize
            name: sklearn.metrics.accuracy_score
          log_loss:
            _target_: deckard.base.scorer.ScorerConfig
            direction: minimize
            name: sklearn.metrics.log_loss
    outs:
    - path: kdd_nsl/logs/test_each_model/gzip_logistic/gzip/20
      hash: md5
      md5: ec6c44a8421f7cb02994bafbb0ceb59d.dir
      size: 7980
      nfiles: 4
    - path: kdd_nsl/reports/test_each_model/gzip_logistic/gzip/20/score_dict.json
      hash: md5
      md5: 5d8bf090bc8e34df8ed01766adfca5eb
      size: 26
  test_each_model@gzip-gzip_logistic-truthseeker-20:
    cmd: 'python -m deckard.layers.optimise  stage=test_each_model  files.name=gzip_logistic/gzip/20
      files.directory=truthseeker data=truthseeker data.sample.train_size=20 dataset=truthseeker
      model=gzip_logistic model_name=gzip_knn model.init.metric=gzip  model.init.m=-1
      hydra.run.dir=truthseeker/logs/test_each_model/gzip_logistic/gzip/20 ++raise_exception=True '
    deps:
    - path: kdd_nsl/reports/train/default/score_dict.json
      hash: md5
      md5: ee4344da4a735fb0b6e6d2cf83ddef6e
      size: 484
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          drop:
          - id
          name: raw_data/kdd_nsl_undersampled_5000.csv
          sample:
            _target_: deckard.base.data.SklearnDataSampler
            random_state: 0
            stratify: true
            test_size: 100
            train_size: 100
          target: label
        dataset: kdd_nsl
        device_id: cpu
        files:
          _target_: deckard.base.files.FileConfig
          data_dir: data
          data_type: .csv
          directory: kdd_nsl
          model_dir: model
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          reports: reports
          score_dict_file: score_dict.json
        model:
          _target_: deckard.base.model.Model
          data:
            _target_: deckard.base.data.Data
            drop:
            - id
            name: raw_data/kdd_nsl_undersampled_5000.csv
            sample:
              _target_: deckard.base.data.SklearnDataSampler
              random_state: 0
              stratify: true
              test_size: 100
              train_size: 100
            target: label
          init:
            _target_: deckard.base.model.ModelInitializer
            distance_matrix: kdd_nsl/model/gzip/100-100/0.npz
            k: 1
            m: -1
            metric: gzip
            name: gzip_classifier.GzipKNN
            symmetric: false
          library: sklearn
        model_name: gzip_knn
        scorers:
          _target_: deckard.base.scorer.ScorerDict
          accuracy:
            _target_: deckard.base.scorer.ScorerConfig
            direction: maximize
            name: sklearn.metrics.accuracy_score
          log_loss:
            _target_: deckard.base.scorer.ScorerConfig
            direction: minimize
            name: sklearn.metrics.log_loss
    outs:
    - path: truthseeker/logs/test_each_model/gzip_logistic/gzip/20
      hash: md5
      md5: 2ade09315cc26a4d65dbc22a657bfdec.dir
      size: 8013
      nfiles: 4
    - path: truthseeker/reports/test_each_model/gzip_logistic/gzip/20/score_dict.json
      hash: md5
      md5: 5d8bf090bc8e34df8ed01766adfca5eb
      size: 26
  test_each_model@gzip-gzip_svc-kdd_nsl-20:
    cmd: 'python -m deckard.layers.optimise  stage=test_each_model  files.name=gzip_svc/gzip/20
      files.directory=kdd_nsl data=kdd_nsl data.sample.train_size=20 dataset=kdd_nsl
      model=gzip_svc model_name=gzip_knn model.init.metric=gzip  model.init.m=-1 hydra.run.dir=kdd_nsl/logs/test_each_model/gzip_svc/gzip/20
      ++raise_exception=True '
    deps:
    - path: kdd_nsl/reports/train/default/score_dict.json
      hash: md5
      md5: ee4344da4a735fb0b6e6d2cf83ddef6e
      size: 484
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          drop:
          - id
          name: raw_data/kdd_nsl_undersampled_5000.csv
          sample:
            _target_: deckard.base.data.SklearnDataSampler
            random_state: 0
            stratify: true
            test_size: 100
            train_size: 100
          target: label
        dataset: kdd_nsl
        device_id: cpu
        files:
          _target_: deckard.base.files.FileConfig
          data_dir: data
          data_type: .csv
          directory: kdd_nsl
          model_dir: model
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          reports: reports
          score_dict_file: score_dict.json
        model:
          _target_: deckard.base.model.Model
          data:
            _target_: deckard.base.data.Data
            drop:
            - id
            name: raw_data/kdd_nsl_undersampled_5000.csv
            sample:
              _target_: deckard.base.data.SklearnDataSampler
              random_state: 0
              stratify: true
              test_size: 100
              train_size: 100
            target: label
          init:
            _target_: deckard.base.model.ModelInitializer
            distance_matrix: kdd_nsl/model/gzip/100-100/0.npz
            k: 1
            m: -1
            metric: gzip
            name: gzip_classifier.GzipKNN
            symmetric: false
          library: sklearn
        model_name: gzip_knn
        scorers:
          _target_: deckard.base.scorer.ScorerDict
          accuracy:
            _target_: deckard.base.scorer.ScorerConfig
            direction: maximize
            name: sklearn.metrics.accuracy_score
          log_loss:
            _target_: deckard.base.scorer.ScorerConfig
            direction: minimize
            name: sklearn.metrics.log_loss
    outs:
    - path: kdd_nsl/logs/test_each_model/gzip_svc/gzip/20
      hash: md5
      md5: 80e1fe29c22203d01027107088979db9.dir
      size: 7891
      nfiles: 4
    - path: kdd_nsl/reports/test_each_model/gzip_svc/gzip/20/score_dict.json
      hash: md5
      md5: 5d8bf090bc8e34df8ed01766adfca5eb
      size: 26
  test_each_model@gzip-gzip_knn-truthseeker-20:
    cmd: 'python -m deckard.layers.optimise  stage=test_each_model  files.name=gzip_knn/gzip/20
      files.directory=truthseeker data=truthseeker data.sample.train_size=20 dataset=truthseeker
      model=gzip_knn model_name=gzip_knn model.init.metric=gzip  model.init.m=-1 hydra.run.dir=truthseeker/logs/test_each_model/gzip_knn/gzip/20
      ++raise_exception=True '
    deps:
    - path: kdd_nsl/reports/train/default/score_dict.json
      hash: md5
      md5: ee4344da4a735fb0b6e6d2cf83ddef6e
      size: 484
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      params.yaml:
        data:
          _target_: deckard.base.data.Data
          drop:
          - id
          name: raw_data/kdd_nsl_undersampled_5000.csv
          sample:
            _target_: deckard.base.data.SklearnDataSampler
            random_state: 0
            stratify: true
            test_size: 100
            train_size: 100
          target: label
        dataset: kdd_nsl
        device_id: cpu
        files:
          _target_: deckard.base.files.FileConfig
          data_dir: data
          data_type: .csv
          directory: kdd_nsl
          model_dir: model
          name: default
          params_file: params.yaml
          predictions_file: predictions.json
          reports: reports
          score_dict_file: score_dict.json
        model:
          _target_: deckard.base.model.Model
          data:
            _target_: deckard.base.data.Data
            drop:
            - id
            name: raw_data/kdd_nsl_undersampled_5000.csv
            sample:
              _target_: deckard.base.data.SklearnDataSampler
              random_state: 0
              stratify: true
              test_size: 100
              train_size: 100
            target: label
          init:
            _target_: deckard.base.model.ModelInitializer
            distance_matrix: kdd_nsl/model/gzip/100-100/0.npz
            k: 1
            m: -1
            metric: gzip
            name: gzip_classifier.GzipKNN
            symmetric: false
          library: sklearn
        model_name: gzip_knn
        scorers:
          _target_: deckard.base.scorer.ScorerDict
          accuracy:
            _target_: deckard.base.scorer.ScorerConfig
            direction: maximize
            name: sklearn.metrics.accuracy_score
          log_loss:
            _target_: deckard.base.scorer.ScorerConfig
            direction: minimize
            name: sklearn.metrics.log_loss
    outs:
    - path: truthseeker/logs/test_each_model/gzip_knn/gzip/20
      hash: md5
      md5: e1b4842686f73992f04e9104eab3e88f.dir
      size: 7921
      nfiles: 4
    - path: truthseeker/reports/test_each_model/gzip_knn/gzip/20/score_dict.json
      hash: md5
      md5: 5d8bf090bc8e34df8ed01766adfca5eb
      size: 26
  grid_search@20-ddos-gzip_knn-true:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=20
      data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_knn_ddos hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/gzip_knn/20/symmetry_true hydra.callbacks.study_dump.output_file=ddos/logs/gzip_knn/20/study.csv
      files.directory=ddos files.reports=reports/gzip_knn/20/symmetry_true hydra.launcher.n_jobs=-1
      ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/gzip_knn/20/symmetry_true
      hash: md5
      md5: 75a67061f3d261f90a32e2e342a26049.dir
      size: 1201059
      nfiles: 513
    - path: ddos/reports/gzip_knn/20/symmetry_true/train/
      hash: md5
      md5: 410d4dc9dc529c85056cea27da5fc34f.dir
      size: 328616
      nfiles: 369
  grid_search@20-ddos-gzip_knn-false:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=20
      data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_knn_ddos hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/gzip_knn/20/symmetry_false
      hydra.callbacks.study_dump.output_file=ddos/logs/gzip_knn/20/study.csv files.directory=ddos
      files.reports=reports/gzip_knn/20/symmetry_false hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/gzip_knn/20/symmetry_false
      hash: md5
      md5: 5511994182145eb3145fd3afc672d1a5.dir
      size: 1200638
      nfiles: 513
    - path: ddos/reports/gzip_knn/20/symmetry_false/train/
      hash: md5
      md5: b507e62340bddb44dd3e66467a23444a.dir
      size: 328838
      nfiles: 369
  grid_search@20-ddos-gzip_logistic-true:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=20
      data.sample.test_size=100 model_name=gzip_logistic model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_logistic_ddos hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/gzip_logistic/20/symmetry_true
      hydra.callbacks.study_dump.output_file=ddos/logs/gzip_logistic/20/study.csv
      files.directory=ddos files.reports=reports/gzip_logistic/20/symmetry_true hydra.launcher.n_jobs=-1
      ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/gzip_logistic/20/symmetry_true
      hash: md5
      md5: 7411fc1827bfc3df75c9106a4288ee8d.dir
      size: 1262132
      nfiles: 513
    - path: ddos/reports/gzip_logistic/20/symmetry_true/train/
      hash: md5
      md5: 72358a4a9191f8e02e2d9348e7bfa5be.dir
      size: 601313
      nfiles: 356
  grid_search@20-ddos-gzip_logistic-false:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=20
      data.sample.test_size=100 model_name=gzip_logistic model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_logistic_ddos hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/gzip_logistic/20/symmetry_false
      hydra.callbacks.study_dump.output_file=ddos/logs/gzip_logistic/20/study.csv
      files.directory=ddos files.reports=reports/gzip_logistic/20/symmetry_false hydra.launcher.n_jobs=-1
      ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/gzip_logistic/20/symmetry_false
      hash: md5
      md5: 49dbe43b3f37ddc7ac2ae83c9022067e.dir
      size: 1243003
      nfiles: 513
    - path: ddos/reports/gzip_logistic/20/symmetry_false/train/
      hash: md5
      md5: 311ef4395865656e00f5428c8f98b19a.dir
      size: 616599
      nfiles: 340
  grid_search@20-ddos-gzip_svc-true:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=20
      data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_svc_ddos hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/gzip_svc/20/symmetry_true hydra.callbacks.study_dump.output_file=ddos/logs/gzip_svc/20/study.csv
      files.directory=ddos files.reports=reports/gzip_svc/20/symmetry_true hydra.launcher.n_jobs=-1
      ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/gzip_svc/20/symmetry_true
      hash: md5
      md5: 51fb64b0b4069b3a551837dd9602b50c.dir
      size: 1235122
      nfiles: 513
    - path: ddos/reports/gzip_svc/20/symmetry_true/train/
      hash: md5
      md5: 22b4b6a8d2e3861aedf0e4f43917ba72.dir
      size: 551301
      nfiles: 384
  grid_search@20-ddos-gzip_svc-false:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=20
      data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_svc_ddos hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/gzip_svc/20/symmetry_false
      hydra.callbacks.study_dump.output_file=ddos/logs/gzip_svc/20/study.csv files.directory=ddos
      files.reports=reports/gzip_svc/20/symmetry_false hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/gzip_svc/20/symmetry_false
      hash: md5
      md5: 2440c70c069be012281ec7412d211422.dir
      size: 1234738
      nfiles: 513
    - path: ddos/reports/gzip_svc/20/symmetry_false/train/
      hash: md5
      md5: 83c44eacdc2b26fd6264cfb781ea7c54.dir
      size: 551571
      nfiles: 384
  grid_search@20-kdd_nsl-gzip_knn-true:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=20 data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_knn_kdd_nsl hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/gzip_knn/20/symmetry_true
      hydra.callbacks.study_dump.output_file=kdd_nsl/logs/gzip_knn/20/study.csv files.directory=kdd_nsl
      files.reports=reports/gzip_knn/20/symmetry_true hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/gzip_knn/20/symmetry_true
      hash: md5
      md5: 677d1cdd68cb84a67d83107fc6925c3c.dir
      size: 1196876
      nfiles: 513
    - path: kdd_nsl/reports/gzip_knn/20/symmetry_true/train/
      hash: md5
      md5: bb50d06bc8b2fd621dd0a417273884cc.dir
      size: 341291
      nfiles: 356
  grid_search@20-kdd_nsl-gzip_knn-false:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=20 data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_knn_kdd_nsl hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/gzip_knn/20/symmetry_false
      hydra.callbacks.study_dump.output_file=kdd_nsl/logs/gzip_knn/20/study.csv files.directory=kdd_nsl
      files.reports=reports/gzip_knn/20/symmetry_false hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/gzip_knn/20/symmetry_false
      hash: md5
      md5: 8876b4cdea08cacd9fabea8b7c7e339b.dir
      size: 1180969
      nfiles: 513
    - path: kdd_nsl/reports/gzip_knn/20/symmetry_false/train/
      hash: md5
      md5: 8635540eb47bb367dbac1b7d6d83afde.dir
      size: 371913
      nfiles: 345
  grid_search@20-kdd_nsl-gzip_logistic-true:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=20 data.sample.test_size=100 model_name=gzip_logistic
      model.init.distance_matrix=null model.init.symmetric=true hydra.sweeper.study_name=gzip_logistic_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/gzip_logistic/20/symmetry_true
      hydra.callbacks.study_dump.output_file=kdd_nsl/logs/gzip_logistic/20/study.csv
      files.directory=kdd_nsl files.reports=reports/gzip_logistic/20/symmetry_true
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/gzip_logistic/20/symmetry_true
      hash: md5
      md5: 4752da5c6f9e5b19ffa7b85fedaa864d.dir
      size: 1271405
      nfiles: 513
    - path: kdd_nsl/reports/gzip_logistic/20/symmetry_true/train/
      hash: md5
      md5: b2fc29717a0256771a595e81e77363c9.dir
      size: 604610
      nfiles: 356
  grid_search@20-kdd_nsl-gzip_logistic-false:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=20 data.sample.test_size=100 model_name=gzip_logistic
      model.init.distance_matrix=null model.init.symmetric=false hydra.sweeper.study_name=gzip_logistic_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/gzip_logistic/20/symmetry_false
      hydra.callbacks.study_dump.output_file=kdd_nsl/logs/gzip_logistic/20/study.csv
      files.directory=kdd_nsl files.reports=reports/gzip_logistic/20/symmetry_false
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/gzip_logistic/20/symmetry_false
      hash: md5
      md5: 24f796fd29b950df2c9d7eb53db47cd2.dir
      size: 1260414
      nfiles: 513
    - path: kdd_nsl/reports/gzip_logistic/20/symmetry_false/train/
      hash: md5
      md5: 6f0315fbb05852baa48643f06ed318ad.dir
      size: 611076
      nfiles: 347
  grid_search@20-kdd_nsl-gzip_svc-true:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=20 data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_svc_kdd_nsl hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/gzip_svc/20/symmetry_true
      hydra.callbacks.study_dump.output_file=kdd_nsl/logs/gzip_svc/20/study.csv files.directory=kdd_nsl
      files.reports=reports/gzip_svc/20/symmetry_true hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/gzip_svc/20/symmetry_true
      hash: md5
      md5: 0cbe34f36b1aacc6101ec1d3d6d878eb.dir
      size: 1244608
      nfiles: 513
    - path: kdd_nsl/reports/gzip_svc/20/symmetry_true/train/
      hash: md5
      md5: 0ea5d4be51518781035dd7e85b700732.dir
      size: 554635
      nfiles: 384
  grid_search@20-kdd_nsl-gzip_svc-false:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=20 data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_svc_kdd_nsl hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/gzip_svc/20/symmetry_false
      hydra.callbacks.study_dump.output_file=kdd_nsl/logs/gzip_svc/20/study.csv files.directory=kdd_nsl
      files.reports=reports/gzip_svc/20/symmetry_false hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/gzip_svc/20/symmetry_false
      hash: md5
      md5: 9eba5cbbd68553f794dec337e9606f52.dir
      size: 1244184
      nfiles: 513
    - path: kdd_nsl/reports/gzip_svc/20/symmetry_false/train/
      hash: md5
      md5: dc18ba1e036d9b6678d4b97070d84c3c.dir
      size: 554884
      nfiles: 384
  grid_search@20-sms_spam-gzip_knn-true:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=20 data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_knn_sms_spam hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/gzip_knn/20/symmetry_true
      hydra.callbacks.study_dump.output_file=sms_spam/logs/gzip_knn/20/study.csv files.directory=sms_spam
      files.reports=reports/gzip_knn/20/symmetry_true hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/gzip_knn/20/symmetry_true
      hash: md5
      md5: b900fa95011e3c9620f9a7103baa47a1.dir
      size: 1193555
      nfiles: 513
    - path: sms_spam/reports/gzip_knn/20/symmetry_true/train/
      hash: md5
      md5: 0c2256ed804059b75873b27f8963204e.dir
      size: 329514
      nfiles: 356
  grid_search@20-sms_spam-gzip_knn-false:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=20 data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_knn_sms_spam hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/gzip_knn/20/symmetry_false
      hydra.callbacks.study_dump.output_file=sms_spam/logs/gzip_knn/20/study.csv files.directory=sms_spam
      files.reports=reports/gzip_knn/20/symmetry_false hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/gzip_knn/20/symmetry_false
      hash: md5
      md5: 0554269057beb85cd3746813652ba9d5.dir
      size: 1191491
      nfiles: 513
    - path: sms_spam/reports/gzip_knn/20/symmetry_false/train/
      hash: md5
      md5: e25f72d029f72432d5c9a5ffacec0208.dir
      size: 341814
      nfiles: 356
  grid_search@20-sms_spam-gzip_logistic-true:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=20 data.sample.test_size=100 model_name=gzip_logistic
      model.init.distance_matrix=null model.init.symmetric=true hydra.sweeper.study_name=gzip_logistic_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/gzip_logistic/20/symmetry_true
      hydra.callbacks.study_dump.output_file=sms_spam/logs/gzip_logistic/20/study.csv
      files.directory=sms_spam files.reports=reports/gzip_logistic/20/symmetry_true
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/gzip_logistic/20/symmetry_true
      hash: md5
      md5: b95404e2e4b0a957a788e82f65a49a10.dir
      size: 1268014
      nfiles: 513
    - path: sms_spam/reports/gzip_logistic/20/symmetry_true/train/
      hash: md5
      md5: b2333589409b837e4233aa2fb7cded97.dir
      size: 592315
      nfiles: 356
  grid_search@20-sms_spam-gzip_logistic-false:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=20 data.sample.test_size=100 model_name=gzip_logistic
      model.init.distance_matrix=null model.init.symmetric=false hydra.sweeper.study_name=gzip_logistic_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/gzip_logistic/20/symmetry_false
      hydra.callbacks.study_dump.output_file=sms_spam/logs/gzip_logistic/20/study.csv
      files.directory=sms_spam files.reports=reports/gzip_logistic/20/symmetry_false
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/gzip_logistic/20/symmetry_false
      hash: md5
      md5: 9d4569ebac94dccb57a6d50c04fd2b1c.dir
      size: 1252292
      nfiles: 513
    - path: sms_spam/reports/gzip_logistic/20/symmetry_false/train/
      hash: md5
      md5: a4a3af08dfca0a0ba5b94bb0a9ea735a.dir
      size: 603823
      nfiles: 343
  grid_search@20-sms_spam-gzip_svc-true:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=20 data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_svc_sms_spam hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/gzip_svc/20/symmetry_true
      hydra.callbacks.study_dump.output_file=sms_spam/logs/gzip_svc/20/study.csv files.directory=sms_spam
      files.reports=reports/gzip_svc/20/symmetry_true hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/gzip_svc/20/symmetry_true
      hash: md5
      md5: 97f387456af594e96fe70ae39cfe8018.dir
      size: 1241267
      nfiles: 513
    - path: sms_spam/reports/gzip_svc/20/symmetry_true/train/
      hash: md5
      md5: aa3a7443b115c46ce08aa7a70a7fb77c.dir
      size: 542327
      nfiles: 384
  grid_search@20-sms_spam-gzip_svc-false:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=20 data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_svc_sms_spam hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/gzip_svc/20/symmetry_false
      hydra.callbacks.study_dump.output_file=sms_spam/logs/gzip_svc/20/study.csv files.directory=sms_spam
      files.reports=reports/gzip_svc/20/symmetry_false hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/gzip_svc/20/symmetry_false
      hash: md5
      md5: dccf212ddba8d745daa30ce1c9efd0b1.dir
      size: 1240872
      nfiles: 513
    - path: sms_spam/reports/gzip_svc/20/symmetry_false/train/
      hash: md5
      md5: 923ea8186f9d9630e26fa0da18e03508.dir
      size: 542578
      nfiles: 384
  grid_search@20-truthseeker-gzip_knn-true:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=20 data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_knn_truthseeker hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/gzip_knn/20/symmetry_true
      hydra.callbacks.study_dump.output_file=truthseeker/logs/gzip_knn/20/study.csv
      files.directory=truthseeker files.reports=reports/gzip_knn/20/symmetry_true
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/gzip_knn/20/symmetry_true
      hash: md5
      md5: a98ed7354eb47190c6301eb889704388.dir
      size: 1206224
      nfiles: 513
    - path: truthseeker/reports/gzip_knn/20/symmetry_true/train/
      hash: md5
      md5: ad20e69c6454627f1483726b0cc91365.dir
      size: 331035
      nfiles: 359
  grid_search@20-truthseeker-gzip_knn-false:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=20 data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_knn_truthseeker hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/gzip_knn/20/symmetry_false
      hydra.callbacks.study_dump.output_file=truthseeker/logs/gzip_knn/20/study.csv
      files.directory=truthseeker files.reports=reports/gzip_knn/20/symmetry_false
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/gzip_knn/20/symmetry_false
      hash: md5
      md5: 2617ca5cb1d8ff3905d50915269c6e9f.dir
      size: 1203425
      nfiles: 513
    - path: truthseeker/reports/gzip_knn/20/symmetry_false/train/
      hash: md5
      md5: 4a06f23a3f742c65df6594ee04759bf8.dir
      size: 342243
      nfiles: 358
  grid_search@20-truthseeker-gzip_logistic-true:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=20 data.sample.test_size=100 model_name=gzip_logistic
      model.init.distance_matrix=null model.init.symmetric=true hydra.sweeper.study_name=gzip_logistic_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/gzip_logistic/20/symmetry_true
      hydra.callbacks.study_dump.output_file=truthseeker/logs/gzip_logistic/20/study.csv
      files.directory=truthseeker files.reports=reports/gzip_logistic/20/symmetry_true
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/gzip_logistic/20/symmetry_true
      hash: md5
      md5: ff829c546214f8c48b65d65886826fa3.dir
      size: 1277433
      nfiles: 513
    - path: truthseeker/reports/gzip_logistic/20/symmetry_true/train/
      hash: md5
      md5: 9fa0a99c495e46db650c6a7a5b520119.dir
      size: 596142
      nfiles: 356
  grid_search@20-truthseeker-gzip_logistic-false:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=20 data.sample.test_size=100 model_name=gzip_logistic
      model.init.distance_matrix=null model.init.symmetric=false hydra.sweeper.study_name=gzip_logistic_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/gzip_logistic/20/symmetry_false
      hydra.callbacks.study_dump.output_file=truthseeker/logs/gzip_logistic/20/study.csv
      files.directory=truthseeker files.reports=reports/gzip_logistic/20/symmetry_false
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/gzip_logistic/20/symmetry_false
      hash: md5
      md5: 3236c08228d49f414fb9276f63fd854e.dir
      size: 1265237
      nfiles: 513
    - path: truthseeker/reports/gzip_logistic/20/symmetry_false/train/
      hash: md5
      md5: 61c25a8988641a6780633c71c79af7b1.dir
      size: 603920
      nfiles: 346
  grid_search@20-truthseeker-gzip_svc-true:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=20 data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_svc_truthseeker hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/gzip_svc/20/symmetry_true
      hydra.callbacks.study_dump.output_file=truthseeker/logs/gzip_svc/20/study.csv
      files.directory=truthseeker files.reports=reports/gzip_svc/20/symmetry_true
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/gzip_svc/20/symmetry_true
      hash: md5
      md5: 80d0c1ade291bb4dbc9af47eddab6d27.dir
      size: 1250879
      nfiles: 513
    - path: truthseeker/reports/gzip_svc/20/symmetry_true/train/
      hash: md5
      md5: 913d1664491e029cb3e45e5fa1d9c2b1.dir
      size: 546189
      nfiles: 384
  grid_search@20-truthseeker-gzip_svc-false:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=20 data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_svc_truthseeker hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/gzip_svc/20/symmetry_false
      hydra.callbacks.study_dump.output_file=truthseeker/logs/gzip_svc/20/study.csv
      files.directory=truthseeker files.reports=reports/gzip_svc/20/symmetry_false
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/gzip_svc/20/symmetry_false
      hash: md5
      md5: cd321e0e8ed96e2dc914d3f061139e1b.dir
      size: 1250531
      nfiles: 513
    - path: truthseeker/reports/gzip_svc/20/symmetry_false/train/
      hash: md5
      md5: 7fd5bb25a3688c3470e30aeee85674ff.dir
      size: 546474
      nfiles: 384
  grid_search@100-ddos-gzip_knn-true:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_knn_ddos hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/gzip_knn/100/symmetry_true
      hydra.callbacks.study_dump.output_file=ddos/logs/gzip_knn/100/study.csv files.directory=ddos
      files.reports=reports/gzip_knn/100/symmetry_true hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/gzip_knn/100/symmetry_true
      hash: md5
      md5: ce684eab73c010891cc6eb844e066134.dir
      size: 1190708
      nfiles: 513
    - path: ddos/reports/gzip_knn/100/symmetry_true/train/
      hash: md5
      md5: 60e9b4f5171f22fb8144383380218108.dir
      size: 81468
      nfiles: 91
  grid_search@100-ddos-gzip_knn-false:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_knn_ddos hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/gzip_knn/100/symmetry_false
      hydra.callbacks.study_dump.output_file=ddos/logs/gzip_knn/100/study.csv files.directory=ddos
      files.reports=reports/gzip_knn/100/symmetry_false hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/gzip_knn/100/symmetry_false
      hash: md5
      md5: 307edd5cacb6d130cdca319d74e42152.dir
      size: 1200449
      nfiles: 513
    - path: ddos/reports/gzip_knn/100/symmetry_false/train/
      hash: md5
      md5: 9eb4c5ed862761d977cbec997e27a109.dir
      size: 286576
      nfiles: 321
  grid_search@100-ddos-gzip_logistic-true:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=gzip_logistic model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_logistic_ddos hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/gzip_logistic/100/symmetry_true
      hydra.callbacks.study_dump.output_file=ddos/logs/gzip_logistic/100/study.csv
      files.directory=ddos files.reports=reports/gzip_logistic/100/symmetry_true hydra.launcher.n_jobs=-1
      ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/gzip_logistic/100/symmetry_true
      hash: md5
      md5: d0b4bd67c2297fcf7cd87b5bb49830ce.dir
      size: 1236038
      nfiles: 513
    - path: ddos/reports/gzip_logistic/100/symmetry_true/train/
      hash: md5
      md5: 3f4bc5d4c66937cccc23ae865cd69762.dir
      size: 636279
      nfiles: 332
  grid_search@100-ddos-gzip_logistic-false:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=gzip_logistic model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_logistic_ddos hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/gzip_logistic/100/symmetry_false
      hydra.callbacks.study_dump.output_file=ddos/logs/gzip_logistic/100/study.csv
      files.directory=ddos files.reports=reports/gzip_logistic/100/symmetry_false
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/gzip_logistic/100/symmetry_false
      hash: md5
      md5: 54987f50efd1f9833711c4bce8ad266b.dir
      size: 1204334
      nfiles: 513
    - path: ddos/reports/gzip_logistic/100/symmetry_false/train/
      hash: md5
      md5: 4237b3f9a08decdbf109a54fce741a4e.dir
      size: 659696
      nfiles: 306
  grid_search@100-ddos-gzip_svc-true:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_svc_ddos hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/gzip_svc/100/symmetry_true
      hydra.callbacks.study_dump.output_file=ddos/logs/gzip_svc/100/study.csv files.directory=ddos
      files.reports=reports/gzip_svc/100/symmetry_true hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/gzip_svc/100/symmetry_true
      hash: md5
      md5: 8f54e554e59aa39da2cc6a545a2b2a84.dir
      size: 1238692
      nfiles: 513
    - path: ddos/reports/gzip_svc/100/symmetry_true/train/
      hash: md5
      md5: 1d55a1ad04addb2611ea268d0d5c037c.dir
      size: 552051
      nfiles: 384
  grid_search@100-ddos-gzip_svc-false:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_svc_ddos hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/gzip_svc/100/symmetry_false
      hydra.callbacks.study_dump.output_file=ddos/logs/gzip_svc/100/study.csv files.directory=ddos
      files.reports=reports/gzip_svc/100/symmetry_false hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/gzip_svc/100/symmetry_false
      hash: md5
      md5: 20385e7fa159098729a46a9ec8ad3e2f.dir
      size: 1240441
      nfiles: 513
    - path: ddos/reports/gzip_svc/100/symmetry_false/train/
      hash: md5
      md5: 006736d48dc878223021e6c5cc721e21.dir
      size: 552730
      nfiles: 384
  grid_search@100-kdd_nsl-gzip_knn-true:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_knn_kdd_nsl hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/gzip_knn/100/symmetry_true
      hydra.callbacks.study_dump.output_file=kdd_nsl/logs/gzip_knn/100/study.csv files.directory=kdd_nsl
      files.reports=reports/gzip_knn/100/symmetry_true hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/gzip_knn/100/symmetry_true
      hash: md5
      md5: 549fe2e753e0bcf601fd788dec7aeb1e.dir
      size: 1188776
      nfiles: 513
    - path: kdd_nsl/reports/gzip_knn/100/symmetry_true/train/
      hash: md5
      md5: c98bd9dce2feec89f7aec764a2c6d1e7.dir
      size: 179210
      nfiles: 190
  grid_search@100-kdd_nsl-gzip_knn-false:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_knn_kdd_nsl hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/gzip_knn/100/symmetry_false
      hydra.callbacks.study_dump.output_file=kdd_nsl/logs/gzip_knn/100/study.csv files.directory=kdd_nsl
      files.reports=reports/gzip_knn/100/symmetry_false hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/gzip_knn/100/symmetry_false
      hash: md5
      md5: 0a1d8131642b28351971a5294828d0d7.dir
      size: 1127001
      nfiles: 513
    - path: kdd_nsl/reports/gzip_knn/100/symmetry_false/train/
      hash: md5
      md5: abf88a5a4a306ec284320cf3aa409135.dir
      size: 155023
      nfiles: 138
  grid_search@100-kdd_nsl-gzip_logistic-true:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=gzip_logistic
      model.init.distance_matrix=null model.init.symmetric=true hydra.sweeper.study_name=gzip_logistic_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/gzip_logistic/100/symmetry_true
      hydra.callbacks.study_dump.output_file=kdd_nsl/logs/gzip_logistic/100/study.csv
      files.directory=kdd_nsl files.reports=reports/gzip_logistic/100/symmetry_true
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/gzip_logistic/100/symmetry_true
      hash: md5
      md5: e57d0862551308c0ec0cabd6542a55e5.dir
      size: 1239394
      nfiles: 513
    - path: kdd_nsl/reports/gzip_logistic/100/symmetry_true/train/
      hash: md5
      md5: af7ccccb3c94a39edbbd239e9cc2a6ae.dir
      size: 646824
      nfiles: 327
  grid_search@100-kdd_nsl-gzip_logistic-false:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=gzip_logistic
      model.init.distance_matrix=null model.init.symmetric=false hydra.sweeper.study_name=gzip_logistic_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/gzip_logistic/100/symmetry_false
      hydra.callbacks.study_dump.output_file=kdd_nsl/logs/gzip_logistic/100/study.csv
      files.directory=kdd_nsl files.reports=reports/gzip_logistic/100/symmetry_false
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/gzip_logistic/100/symmetry_false
      hash: md5
      md5: 3ee2c47866f4ce98afa41e1d10dc99c8.dir
      size: 1285300
      nfiles: 513
    - path: kdd_nsl/reports/gzip_logistic/100/symmetry_false/train/
      hash: md5
      md5: c7034228ec933542633506b363bdd18a.dir
      size: 586323
      nfiles: 367
  grid_search@100-kdd_nsl-gzip_svc-true:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_svc_kdd_nsl hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/gzip_svc/100/symmetry_true
      hydra.callbacks.study_dump.output_file=kdd_nsl/logs/gzip_svc/100/study.csv files.directory=kdd_nsl
      files.reports=reports/gzip_svc/100/symmetry_true hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/gzip_svc/100/symmetry_true
      hash: md5
      md5: 66d83844ef05adb0a121fce7b252b683.dir
      size: 1250230
      nfiles: 513
    - path: kdd_nsl/reports/gzip_svc/100/symmetry_true/train/
      hash: md5
      md5: 9de34dd6d2fb5ad4ebb92c7dfcf05629.dir
      size: 555703
      nfiles: 384
  grid_search@100-kdd_nsl-gzip_svc-false:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_svc_kdd_nsl hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/gzip_svc/100/symmetry_false
      hydra.callbacks.study_dump.output_file=kdd_nsl/logs/gzip_svc/100/study.csv files.directory=kdd_nsl
      files.reports=reports/gzip_svc/100/symmetry_false hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/gzip_svc/100/symmetry_false
      hash: md5
      md5: 977a69c4aa921c8559e687b1ca7fb3b6.dir
      size: 1244242
      nfiles: 513
    - path: kdd_nsl/reports/gzip_svc/100/symmetry_false/train/
      hash: md5
      md5: 4dafa970272be8aa5c954ef2c8883ce1.dir
      size: 555022
      nfiles: 384
  grid_search@100-sms_spam-gzip_knn-true:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_knn_sms_spam hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/gzip_knn/100/symmetry_true
      hydra.callbacks.study_dump.output_file=sms_spam/logs/gzip_knn/100/study.csv
      files.directory=sms_spam files.reports=reports/gzip_knn/100/symmetry_true hydra.launcher.n_jobs=-1
      ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/gzip_knn/100/symmetry_true
      hash: md5
      md5: 65acd2e653dbc019055530750df56494.dir
      size: 1102103
      nfiles: 513
    - path: sms_spam/reports/gzip_knn/100/symmetry_true/train/
      hash: md5
      md5: c22e9ad796b6cc03d2ad47c2bb4bcd4e.dir
      size: 240245
      nfiles: 238
  grid_search@100-sms_spam-gzip_knn-false:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_knn_sms_spam hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/gzip_knn/100/symmetry_false
      hydra.callbacks.study_dump.output_file=sms_spam/logs/gzip_knn/100/study.csv
      files.directory=sms_spam files.reports=reports/gzip_knn/100/symmetry_false hydra.launcher.n_jobs=-1
      ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/gzip_knn/100/symmetry_false
      hash: md5
      md5: b77d9d0576d484d42fa24401a1d81509.dir
      size: 1142222
      nfiles: 513
    - path: sms_spam/reports/gzip_knn/100/symmetry_false/train/
      hash: md5
      md5: 663f10d7b2a3647caecaa978b7b7d983.dir
      size: 119667
      nfiles: 117
  grid_search@100-sms_spam-gzip_logistic-true:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=gzip_logistic
      model.init.distance_matrix=null model.init.symmetric=true hydra.sweeper.study_name=gzip_logistic_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/gzip_logistic/100/symmetry_true
      hydra.callbacks.study_dump.output_file=sms_spam/logs/gzip_logistic/100/study.csv
      files.directory=sms_spam files.reports=reports/gzip_logistic/100/symmetry_true
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/gzip_logistic/100/symmetry_true
      hash: md5
      md5: 517eb16a845fa795e775ef9a68e0a0c6.dir
      size: 1234485
      nfiles: 513
    - path: sms_spam/reports/gzip_logistic/100/symmetry_true/train/
      hash: md5
      md5: 80878d8c169e37e8110005c63a1ee5d0.dir
      size: 635861
      nfiles: 326
  grid_search@100-sms_spam-gzip_logistic-false:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=gzip_logistic
      model.init.distance_matrix=null model.init.symmetric=false hydra.sweeper.study_name=gzip_logistic_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/gzip_logistic/100/symmetry_false
      hydra.callbacks.study_dump.output_file=sms_spam/logs/gzip_logistic/100/study.csv
      files.directory=sms_spam files.reports=reports/gzip_logistic/100/symmetry_false
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/gzip_logistic/100/symmetry_false
      hash: md5
      md5: 394ed9398208455dae29046d35774913.dir
      size: 1229002
      nfiles: 513
    - path: sms_spam/reports/gzip_logistic/100/symmetry_false/train/
      hash: md5
      md5: 1bd2509e914115c6a834f630872fe406.dir
      size: 628941
      nfiles: 323
  grid_search@100-sms_spam-gzip_svc-true:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_svc_sms_spam hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/gzip_svc/100/symmetry_true
      hydra.callbacks.study_dump.output_file=sms_spam/logs/gzip_svc/100/study.csv
      files.directory=sms_spam files.reports=reports/gzip_svc/100/symmetry_true hydra.launcher.n_jobs=-1
      ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/gzip_svc/100/symmetry_true
      hash: md5
      md5: c0931c4a2af0f0b39b4fb699e5ff8850.dir
      size: 1246641
      nfiles: 513
    - path: sms_spam/reports/gzip_svc/100/symmetry_true/train/
      hash: md5
      md5: 903ac9307687b483ee7f60f5c5a9e068.dir
      size: 543384
      nfiles: 384
  grid_search@100-sms_spam-gzip_svc-false:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_svc_sms_spam hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/gzip_svc/100/symmetry_false
      hydra.callbacks.study_dump.output_file=sms_spam/logs/gzip_svc/100/study.csv
      files.directory=sms_spam files.reports=reports/gzip_svc/100/symmetry_false hydra.launcher.n_jobs=-1
      ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/gzip_svc/100/symmetry_false
      hash: md5
      md5: f37630902004d80cb73ff229905ca426.dir
      size: 1247648
      nfiles: 513
    - path: sms_spam/reports/gzip_svc/100/symmetry_false/train/
      hash: md5
      md5: 58dc217409a236b747a999da2ef4cee1.dir
      size: 543731
      nfiles: 384
  grid_search@100-truthseeker-gzip_knn-true:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_knn_truthseeker hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/gzip_knn/100/symmetry_true
      hydra.callbacks.study_dump.output_file=truthseeker/logs/gzip_knn/100/study.csv
      files.directory=truthseeker files.reports=reports/gzip_knn/100/symmetry_true
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/gzip_knn/100/symmetry_true
      hash: md5
      md5: 3bb5017fdd0b61fd7b5be594c4dd0b9c.dir
      size: 1193938
      nfiles: 513
    - path: truthseeker/reports/gzip_knn/100/symmetry_true/train/
      hash: md5
      md5: c0ef5fa56bc9c65e6b6abe943f424be6.dir
      size: 227250
      nfiles: 244
  grid_search@100-truthseeker-gzip_knn-false:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_knn_truthseeker hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/gzip_knn/100/symmetry_false
      hydra.callbacks.study_dump.output_file=truthseeker/logs/gzip_knn/100/study.csv
      files.directory=truthseeker files.reports=reports/gzip_knn/100/symmetry_false
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/gzip_knn/100/symmetry_false
      hash: md5
      md5: 77709b1d2f5973a004742328fa7ccf46.dir
      size: 1173316
      nfiles: 513
    - path: truthseeker/reports/gzip_knn/100/symmetry_false/train/
      hash: md5
      md5: 0a3609651300c7e4d773fdce2af08984.dir
      size: 171434
      nfiles: 160
  grid_search@100-truthseeker-gzip_logistic-true:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=gzip_logistic
      model.init.distance_matrix=null model.init.symmetric=true hydra.sweeper.study_name=gzip_logistic_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/gzip_logistic/100/symmetry_true
      hydra.callbacks.study_dump.output_file=truthseeker/logs/gzip_logistic/100/study.csv
      files.directory=truthseeker files.reports=reports/gzip_logistic/100/symmetry_true
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/gzip_logistic/100/symmetry_true
      hash: md5
      md5: d6d4b0b157b08346ad1b518d2edfe1f8.dir
      size: 1243931
      nfiles: 513
    - path: truthseeker/reports/gzip_logistic/100/symmetry_true/train/
      hash: md5
      md5: 8f94e7db8385fb9f3973eb19b328397a.dir
      size: 639777
      nfiles: 326
  grid_search@100-truthseeker-gzip_logistic-false:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=gzip_logistic
      model.init.distance_matrix=null model.init.symmetric=false hydra.sweeper.study_name=gzip_logistic_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/gzip_logistic/100/symmetry_false
      hydra.callbacks.study_dump.output_file=truthseeker/logs/gzip_logistic/100/study.csv
      files.directory=truthseeker files.reports=reports/gzip_logistic/100/symmetry_false
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/gzip_logistic/100/symmetry_false
      hash: md5
      md5: e00ee47514e58ea5f4d39063d194ca52.dir
      size: 1288351
      nfiles: 513
    - path: truthseeker/reports/gzip_logistic/100/symmetry_false/train/
      hash: md5
      md5: 6eaa1b0799b99345f36c3649419ed12f.dir
      size: 581607
      nfiles: 364
  grid_search@100-truthseeker-gzip_svc-true:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_svc_truthseeker hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/gzip_svc/100/symmetry_true
      hydra.callbacks.study_dump.output_file=truthseeker/logs/gzip_svc/100/study.csv
      files.directory=truthseeker files.reports=reports/gzip_svc/100/symmetry_true
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/gzip_svc/100/symmetry_true
      hash: md5
      md5: 4d85a297bae6c4437d8775268b8f09aa.dir
      size: 1252991
      nfiles: 513
    - path: truthseeker/reports/gzip_svc/100/symmetry_true/train/
      hash: md5
      md5: e5dbcf02229d9973d0d948ab7291138c.dir
      size: 546664
      nfiles: 384
  grid_search@100-truthseeker-gzip_svc-false:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_svc_truthseeker hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/gzip_svc/100/symmetry_false
      hydra.callbacks.study_dump.output_file=truthseeker/logs/gzip_svc/100/study.csv
      files.directory=truthseeker files.reports=reports/gzip_svc/100/symmetry_false
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/gzip_svc/100/symmetry_false
      hash: md5
      md5: b33c39d320d25d5bfbd81006713e3d62.dir
      size: 1254591
      nfiles: 513
    - path: truthseeker/reports/gzip_svc/100/symmetry_false/train/
      hash: md5
      md5: 13ac657603b4c71f4a17d78cbdc69083.dir
      size: 547239
      nfiles: 384
  grid_search@300-ddos-gzip_knn-true:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=300
      data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_knn_ddos hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/gzip_knn/300/symmetry_true
      hydra.callbacks.study_dump.output_file=ddos/logs/gzip_knn/300/study.csv files.directory=ddos
      files.reports=reports/gzip_knn/300/symmetry_true hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/gzip_knn/300/symmetry_true
      hash: md5
      md5: af17db0ff3fb3bd25ffb0ac494ca602a.dir
      size: 1346717
      nfiles: 513
    - path: ddos/reports/gzip_knn/300/symmetry_true/train/
      hash: md5
      md5: 71a4924b35787ce8f819598c167de201.dir
      size: 373408
      nfiles: 408
  grid_search@300-ddos-gzip_knn-false:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=300
      data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_knn_ddos hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/gzip_knn/300/symmetry_false
      hydra.callbacks.study_dump.output_file=ddos/logs/gzip_knn/300/study.csv files.directory=ddos
      files.reports=reports/gzip_knn/300/symmetry_false hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/gzip_knn/300/symmetry_false
      hash: md5
      md5: 0319cb4c3e9d36acd9c85ddb314dfa6b.dir
      size: 1069243
      nfiles: 513
    - path: ddos/reports/gzip_knn/300/symmetry_false/train/
      hash: md5
      md5: 05266bb5e611efb233329446241a29fa.dir
      size: 181246
      nfiles: 174
  grid_search@300-ddos-gzip_logistic-true:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=300
      data.sample.test_size=100 model_name=gzip_logistic model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_logistic_ddos hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/gzip_logistic/300/symmetry_true
      hydra.callbacks.study_dump.output_file=ddos/logs/gzip_logistic/300/study.csv
      files.directory=ddos files.reports=reports/gzip_logistic/300/symmetry_true hydra.launcher.n_jobs=-1
      ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/gzip_logistic/300/symmetry_true
      hash: md5
      md5: d42114f2f4815d8f889f50a0938b831e.dir
      size: 1146194
      nfiles: 513
    - path: ddos/reports/gzip_logistic/300/symmetry_true/train/
      hash: md5
      md5: ca38e444a9aa31f6e7a96665bb38007d.dir
      size: 745603
      nfiles: 256
  grid_search@300-ddos-gzip_logistic-false:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=300
      data.sample.test_size=100 model_name=gzip_logistic model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_logistic_ddos hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/gzip_logistic/300/symmetry_false
      hydra.callbacks.study_dump.output_file=ddos/logs/gzip_logistic/300/study.csv
      files.directory=ddos files.reports=reports/gzip_logistic/300/symmetry_false
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/gzip_logistic/300/symmetry_false
      hash: md5
      md5: a8fa3547385310b5dbb522a330e91347.dir
      size: 1169526
      nfiles: 513
    - path: ddos/reports/gzip_logistic/300/symmetry_false/train/
      hash: md5
      md5: a9f1abeb97be445f44d5e7b5337d88f5.dir
      size: 697507
      nfiles: 276
  grid_search@300-ddos-gzip_svc-true:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=300
      data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_svc_ddos hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/gzip_svc/300/symmetry_true
      hydra.callbacks.study_dump.output_file=ddos/logs/gzip_svc/300/study.csv files.directory=ddos
      files.reports=reports/gzip_svc/300/symmetry_true hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/gzip_svc/300/symmetry_true
      hash: md5
      md5: 1a8948de743e0cdaa44d628f239e1e3c.dir
      size: 1240344
      nfiles: 513
    - path: ddos/reports/gzip_svc/300/symmetry_true/train/
      hash: md5
      md5: 291aedbbcb5dc632e66c2fdecdc69bb6.dir
      size: 552911
      nfiles: 384
  grid_search@300-ddos-gzip_svc-false:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=300
      data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_svc_ddos hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/gzip_svc/300/symmetry_false
      hydra.callbacks.study_dump.output_file=ddos/logs/gzip_svc/300/study.csv files.directory=ddos
      files.reports=reports/gzip_svc/300/symmetry_false hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/gzip_svc/300/symmetry_false
      hash: md5
      md5: 0649372351397fecccf61f57c2321add.dir
      size: 1240408
      nfiles: 513
    - path: ddos/reports/gzip_svc/300/symmetry_false/train/
      hash: md5
      md5: c12d40ef6548ebb8928f50aa2428e545.dir
      size: 553396
      nfiles: 384
  grid_search@300-kdd_nsl-gzip_knn-true:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=300 data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_knn_kdd_nsl hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/gzip_knn/300/symmetry_true
      hydra.callbacks.study_dump.output_file=kdd_nsl/logs/gzip_knn/300/study.csv files.directory=kdd_nsl
      files.reports=reports/gzip_knn/300/symmetry_true hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/gzip_knn/300/symmetry_true
      hash: md5
      md5: 6518b61cd3febf7b0a057e5186265bf8.dir
      size: 1175328
      nfiles: 513
    - path: kdd_nsl/reports/gzip_knn/300/symmetry_true/train/
      hash: md5
      md5: 4a1e268ece858c6e3e63908557957828.dir
      size: 92710
      nfiles: 93
  grid_search@300-kdd_nsl-gzip_knn-false:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=300 data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_knn_kdd_nsl hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/gzip_knn/300/symmetry_false
      hydra.callbacks.study_dump.output_file=kdd_nsl/logs/gzip_knn/300/study.csv files.directory=kdd_nsl
      files.reports=reports/gzip_knn/300/symmetry_false hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/gzip_knn/300/symmetry_false
      hash: md5
      md5: f09fc35ef1ba57f71a732f71ef4f4f93.dir
      size: 1099226
      nfiles: 513
    - path: kdd_nsl/reports/gzip_knn/300/symmetry_false/train/
      hash: md5
      md5: bc61b9e720b0857a9cb31282bd2a33ef.dir
      size: 110298
      nfiles: 91
  grid_search@300-kdd_nsl-gzip_logistic-true:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=300 data.sample.test_size=100 model_name=gzip_logistic
      model.init.distance_matrix=null model.init.symmetric=true hydra.sweeper.study_name=gzip_logistic_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/gzip_logistic/300/symmetry_true
      hydra.callbacks.study_dump.output_file=kdd_nsl/logs/gzip_logistic/300/study.csv
      files.directory=kdd_nsl files.reports=reports/gzip_logistic/300/symmetry_true
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/gzip_logistic/300/symmetry_true
      hash: md5
      md5: 591754e33808499461adf569eeff62f6.dir
      size: 1218882
      nfiles: 513
    - path: kdd_nsl/reports/gzip_logistic/300/symmetry_true/train/
      hash: md5
      md5: 8e8196245a8ccb61907d6b75bf0545b3.dir
      size: 671452
      nfiles: 310
  grid_search@300-kdd_nsl-gzip_logistic-false:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=300 data.sample.test_size=100 model_name=gzip_logistic
      model.init.distance_matrix=null model.init.symmetric=false hydra.sweeper.study_name=gzip_logistic_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/gzip_logistic/300/symmetry_false
      hydra.callbacks.study_dump.output_file=kdd_nsl/logs/gzip_logistic/300/study.csv
      files.directory=kdd_nsl files.reports=reports/gzip_logistic/300/symmetry_false
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/gzip_logistic/300/symmetry_false
      hash: md5
      md5: 2177259c53892537b69c753547243fbd.dir
      size: 1212739
      nfiles: 513
    - path: kdd_nsl/reports/gzip_logistic/300/symmetry_false/train/
      hash: md5
      md5: 80a3b8775f151e79b22ab6abc9adc19c.dir
      size: 664521
      nfiles: 305
  grid_search@300-kdd_nsl-gzip_svc-true:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=300 data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_svc_kdd_nsl hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/gzip_svc/300/symmetry_true
      hydra.callbacks.study_dump.output_file=kdd_nsl/logs/gzip_svc/300/study.csv files.directory=kdd_nsl
      files.reports=reports/gzip_svc/300/symmetry_true hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/gzip_svc/300/symmetry_true
      hash: md5
      md5: 9a09394fe4e7bdca36ed9d84acf7e18d.dir
      size: 1245638
      nfiles: 513
    - path: kdd_nsl/reports/gzip_svc/300/symmetry_true/train/
      hash: md5
      md5: 64a934d596bced654c98a1c6d21a6c58.dir
      size: 555648
      nfiles: 384
  grid_search@300-kdd_nsl-gzip_svc-false:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=300 data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_svc_kdd_nsl hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/gzip_svc/300/symmetry_false
      hydra.callbacks.study_dump.output_file=kdd_nsl/logs/gzip_svc/300/study.csv files.directory=kdd_nsl
      files.reports=reports/gzip_svc/300/symmetry_false hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/gzip_svc/300/symmetry_false
      hash: md5
      md5: 1be8fcbb302d5eed0d793b6a49892742.dir
      size: 1244276
      nfiles: 513
    - path: kdd_nsl/reports/gzip_svc/300/symmetry_false/train/
      hash: md5
      md5: adc40b356cae8e3d283d866bcfedacee.dir
      size: 555831
      nfiles: 384
  grid_search@300-sms_spam-gzip_knn-true:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=300 data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_knn_sms_spam hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/gzip_knn/300/symmetry_true
      hydra.callbacks.study_dump.output_file=sms_spam/logs/gzip_knn/300/study.csv
      files.directory=sms_spam files.reports=reports/gzip_knn/300/symmetry_true hydra.launcher.n_jobs=-1
      ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/gzip_knn/300/symmetry_true
      hash: md5
      md5: 3efd9a7fd75868b6da787adca58411d5.dir
      size: 1179292
      nfiles: 513
    - path: sms_spam/reports/gzip_knn/300/symmetry_true/train/
      hash: md5
      md5: f01e809c36fa5b1939201324f5f5576f.dir
      size: 94963
      nfiles: 100
  grid_search@300-sms_spam-gzip_knn-false:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=300 data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_knn_sms_spam hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/gzip_knn/300/symmetry_false
      hydra.callbacks.study_dump.output_file=sms_spam/logs/gzip_knn/300/study.csv
      files.directory=sms_spam files.reports=reports/gzip_knn/300/symmetry_false hydra.launcher.n_jobs=-1
      ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/gzip_knn/300/symmetry_false
      hash: md5
      md5: eef9eec5aceaef53ecfc282c9569951d.dir
      size: 1119172
      nfiles: 513
    - path: sms_spam/reports/gzip_knn/300/symmetry_false/train/
      hash: md5
      md5: 301e436d9d56acc0245cc52f6c9197f2.dir
      size: 159041
      nfiles: 142
  grid_search@300-sms_spam-gzip_logistic-true:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=300 data.sample.test_size=100 model_name=gzip_logistic
      model.init.distance_matrix=null model.init.symmetric=true hydra.sweeper.study_name=gzip_logistic_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/gzip_logistic/300/symmetry_true
      hydra.callbacks.study_dump.output_file=sms_spam/logs/gzip_logistic/300/study.csv
      files.directory=sms_spam files.reports=reports/gzip_logistic/300/symmetry_true
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/gzip_logistic/300/symmetry_true
      hash: md5
      md5: 6cea0d2d85946c164337c20e270f4b19.dir
      size: 1220145
      nfiles: 513
    - path: sms_spam/reports/gzip_logistic/300/symmetry_true/train/
      hash: md5
      md5: ea62a22364b79f3f3ba21f68b600d249.dir
      size: 651705
      nfiles: 315
  grid_search@300-sms_spam-gzip_logistic-false:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=300 data.sample.test_size=100 model_name=gzip_logistic
      model.init.distance_matrix=null model.init.symmetric=false hydra.sweeper.study_name=gzip_logistic_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/gzip_logistic/300/symmetry_false
      hydra.callbacks.study_dump.output_file=sms_spam/logs/gzip_logistic/300/study.csv
      files.directory=sms_spam files.reports=reports/gzip_logistic/300/symmetry_false
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/gzip_logistic/300/symmetry_false
      hash: md5
      md5: f7680aac11aa2547e7b2aab9a8b06f04.dir
      size: 1215592
      nfiles: 513
    - path: sms_spam/reports/gzip_logistic/300/symmetry_false/train/
      hash: md5
      md5: 1bcbd2967b2310999e24f065d54dea73.dir
      size: 645945
      nfiles: 310
  grid_search@300-sms_spam-gzip_svc-true:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=300 data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_svc_sms_spam hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/gzip_svc/300/symmetry_true
      hydra.callbacks.study_dump.output_file=sms_spam/logs/gzip_svc/300/study.csv
      files.directory=sms_spam files.reports=reports/gzip_svc/300/symmetry_true hydra.launcher.n_jobs=-1
      ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/gzip_svc/300/symmetry_true
      hash: md5
      md5: 13b0ac194d618584a2c1e6b5f4f7364e.dir
      size: 1246587
      nfiles: 513
    - path: sms_spam/reports/gzip_svc/300/symmetry_true/train/
      hash: md5
      md5: 5ab79b52bdf98185cd0e6d5d4ffbcb23.dir
      size: 543841
      nfiles: 384
  grid_search@300-sms_spam-gzip_svc-false:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=300 data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_svc_sms_spam hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/gzip_svc/300/symmetry_false
      hydra.callbacks.study_dump.output_file=sms_spam/logs/gzip_svc/300/study.csv
      files.directory=sms_spam files.reports=reports/gzip_svc/300/symmetry_false hydra.launcher.n_jobs=-1
      ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/gzip_svc/300/symmetry_false
      hash: md5
      md5: a96d9e38c066bb48ea1a53bd26b078e1.dir
      size: 1246912
      nfiles: 513
    - path: sms_spam/reports/gzip_svc/300/symmetry_false/train/
      hash: md5
      md5: f56837dd359816d29469f564dff45d59.dir
      size: 544233
      nfiles: 384
  grid_search@300-truthseeker-gzip_knn-true:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=300 data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_knn_truthseeker hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/gzip_knn/300/symmetry_true
      hydra.callbacks.study_dump.output_file=truthseeker/logs/gzip_knn/300/study.csv
      files.directory=truthseeker files.reports=reports/gzip_knn/300/symmetry_true
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/gzip_knn/300/symmetry_true
      hash: md5
      md5: 89c0a0b3be23c5b095af0d46314dcac7.dir
      size: 1179132
      nfiles: 513
    - path: truthseeker/reports/gzip_knn/300/symmetry_true/train/
      hash: md5
      md5: b9091b99a671c2218760784928823e4b.dir
      size: 251497
      nfiles: 264
  grid_search@300-truthseeker-gzip_knn-false:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=300 data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_knn_truthseeker hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/gzip_knn/300/symmetry_false
      hydra.callbacks.study_dump.output_file=truthseeker/logs/gzip_knn/300/study.csv
      files.directory=truthseeker files.reports=reports/gzip_knn/300/symmetry_false
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/gzip_knn/300/symmetry_false
      hash: md5
      md5: bc042e0a0a7c8969cb82aa2c94f9b23c.dir
      size: 1077732
      nfiles: 513
    - path: truthseeker/reports/gzip_knn/300/symmetry_false/train/
      hash: md5
      md5: 2e59a5fc5b485c2486f9a9693dbc3fe0.dir
      size: 118351
      nfiles: 71
  grid_search@300-truthseeker-gzip_logistic-true:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=300 data.sample.test_size=100 model_name=gzip_logistic
      model.init.distance_matrix=null model.init.symmetric=true hydra.sweeper.study_name=gzip_logistic_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/gzip_logistic/300/symmetry_true
      hydra.callbacks.study_dump.output_file=truthseeker/logs/gzip_logistic/300/study.csv
      files.directory=truthseeker files.reports=reports/gzip_logistic/300/symmetry_true
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/gzip_logistic/300/symmetry_true
      hash: md5
      md5: 4d82439f2deed1d6a618ce1ad799c824.dir
      size: 1191857
      nfiles: 513
    - path: truthseeker/reports/gzip_logistic/300/symmetry_true/train/
      hash: md5
      md5: 7e1ae0bca26f73f55cc6758f3e337b58.dir
      size: 703332
      nfiles: 282
  grid_search@300-truthseeker-gzip_logistic-false:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=300 data.sample.test_size=100 model_name=gzip_logistic
      model.init.distance_matrix=null model.init.symmetric=false hydra.sweeper.study_name=gzip_logistic_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/gzip_logistic/300/symmetry_false
      hydra.callbacks.study_dump.output_file=truthseeker/logs/gzip_logistic/300/study.csv
      files.directory=truthseeker files.reports=reports/gzip_logistic/300/symmetry_false
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/gzip_logistic/300/symmetry_false
      hash: md5
      md5: f58c3ed43982784d173ef7c51f40131a.dir
      size: 1267771
      nfiles: 513
    - path: truthseeker/reports/gzip_logistic/300/symmetry_false/train/
      hash: md5
      md5: a8c3ec6c80ab63035f004319d738b5b5.dir
      size: 604826
      nfiles: 346
  grid_search@300-truthseeker-gzip_svc-true:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=300 data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_svc_truthseeker hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/gzip_svc/300/symmetry_true
      hydra.callbacks.study_dump.output_file=truthseeker/logs/gzip_svc/300/study.csv
      files.directory=truthseeker files.reports=reports/gzip_svc/300/symmetry_true
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/gzip_svc/300/symmetry_true
      hash: md5
      md5: bd92286eeb4d84076ea5722f4c2f4840.dir
      size: 1258534
      nfiles: 513
    - path: truthseeker/reports/gzip_svc/300/symmetry_true/train/
      hash: md5
      md5: cd3382d0a44badb183dbddd10fd5886b.dir
      size: 548227
      nfiles: 384
  grid_search@300-truthseeker-gzip_svc-false:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=300 data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_svc_truthseeker hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/gzip_svc/300/symmetry_false
      hydra.callbacks.study_dump.output_file=truthseeker/logs/gzip_svc/300/study.csv
      files.directory=truthseeker files.reports=reports/gzip_svc/300/symmetry_false
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/gzip_svc/300/symmetry_false
      hash: md5
      md5: 599f141d242c8324a73ff4b984da1367.dir
      size: 1257388
      nfiles: 513
    - path: truthseeker/reports/gzip_svc/300/symmetry_false/train/
      hash: md5
      md5: cf52def2a122bfcea0e11cd16faaf620.dir
      size: 548355
      nfiles: 384
  grid_search@500-ddos-gzip_knn-true:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=500
      data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_knn_ddos hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/gzip_knn/500/symmetry_true
      hydra.callbacks.study_dump.output_file=ddos/logs/gzip_knn/500/study.csv files.directory=ddos
      files.reports=reports/gzip_knn/500/symmetry_true hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/gzip_knn/500/symmetry_true
      hash: md5
      md5: 7fa8a0b98279250f76080e06752df605.dir
      size: 1187614
      nfiles: 513
    - path: ddos/reports/gzip_knn/500/symmetry_true/train/
      hash: md5
      md5: a51352b11c98e628b18505c3cf0bd52b.dir
      size: 137980
      nfiles: 147
  grid_search@500-ddos-gzip_knn-false:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=500
      data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_knn_ddos hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/gzip_knn/500/symmetry_false
      hydra.callbacks.study_dump.output_file=ddos/logs/gzip_knn/500/study.csv files.directory=ddos
      files.reports=reports/gzip_knn/500/symmetry_false hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/gzip_knn/500/symmetry_false
      hash: md5
      md5: 6a8be8893367cfde8c13e5beda8f2334.dir
      size: 1214992
      nfiles: 513
    - path: ddos/reports/gzip_knn/500/symmetry_false/train/
      hash: md5
      md5: b92c0adcfc79c6a43ff5a5f1640e4619.dir
      size: 151618
      nfiles: 155
  grid_search@500-ddos-gzip_logistic-true:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=500
      data.sample.test_size=100 model_name=gzip_logistic model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_logistic_ddos hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/gzip_logistic/500/symmetry_true
      hydra.callbacks.study_dump.output_file=ddos/logs/gzip_logistic/500/study.csv
      files.directory=ddos files.reports=reports/gzip_logistic/500/symmetry_true hydra.launcher.n_jobs=-1
      ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/gzip_logistic/500/symmetry_true
      hash: md5
      md5: 32179c3265ebb97ae238b17a6e73c458.dir
      size: 1095426
      nfiles: 513
    - path: ddos/reports/gzip_logistic/500/symmetry_true/train/
      hash: md5
      md5: fa66bf49e7cf4aec00b22023355749ae.dir
      size: 741406
      nfiles: 259
  grid_search@500-ddos-gzip_logistic-false:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=500
      data.sample.test_size=100 model_name=gzip_logistic model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_logistic_ddos hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/gzip_logistic/500/symmetry_false
      hydra.callbacks.study_dump.output_file=ddos/logs/gzip_logistic/500/study.csv
      files.directory=ddos files.reports=reports/gzip_logistic/500/symmetry_false
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/gzip_logistic/500/symmetry_false
      hash: md5
      md5: 024872d256aa9362914fbcbdeb53da05.dir
      size: 1096493
      nfiles: 513
    - path: ddos/reports/gzip_logistic/500/symmetry_false/train/
      hash: md5
      md5: ea11d1da4e9d5badf58c0cf216ca4f96.dir
      size: 692473
      nfiles: 280
  grid_search@500-ddos-gzip_svc-true:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=500
      data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_svc_ddos hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/gzip_svc/500/symmetry_true
      hydra.callbacks.study_dump.output_file=ddos/logs/gzip_svc/500/study.csv files.directory=ddos
      files.reports=reports/gzip_svc/500/symmetry_true hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/gzip_svc/500/symmetry_true
      hash: md5
      md5: 374489560e10b4454ddf063c8624fe93.dir
      size: 1054250
      nfiles: 513
    - path: ddos/reports/gzip_svc/500/symmetry_true/train/
      hash: md5
      md5: 2be49a426b10674485217ab7fd0274ac.dir
      size: 552354
      nfiles: 384
  grid_search@500-ddos-gzip_svc-false:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=500
      data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_svc_ddos hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/gzip_svc/500/symmetry_false
      hydra.callbacks.study_dump.output_file=ddos/logs/gzip_svc/500/study.csv files.directory=ddos
      files.reports=reports/gzip_svc/500/symmetry_false hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/gzip_svc/500/symmetry_false
      hash: md5
      md5: 2e12d99734aa58387648c95f613d2d71.dir
      size: 1055864
      nfiles: 513
    - path: ddos/reports/gzip_svc/500/symmetry_false/train/
      hash: md5
      md5: fe782876988363bbf4ca6aaf7731b1c8.dir
      size: 552989
      nfiles: 384
  grid_search@500-kdd_nsl-gzip_knn-true:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=500 data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_knn_kdd_nsl hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/gzip_knn/500/symmetry_true
      hydra.callbacks.study_dump.output_file=kdd_nsl/logs/gzip_knn/500/study.csv files.directory=kdd_nsl
      files.reports=reports/gzip_knn/500/symmetry_true hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/gzip_knn/500/symmetry_true
      hash: md5
      md5: 870e3881cf532c9a5b92d4558668cf2f.dir
      size: 1027059
      nfiles: 513
    - path: kdd_nsl/reports/gzip_knn/500/symmetry_true/train/
      hash: md5
      md5: 8ba770a7c36bef7775700dba3888153d.dir
      size: 172277
      nfiles: 173
  grid_search@500-kdd_nsl-gzip_knn-false:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=500 data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_knn_kdd_nsl hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/gzip_knn/500/symmetry_false
      hydra.callbacks.study_dump.output_file=kdd_nsl/logs/gzip_knn/500/study.csv files.directory=kdd_nsl
      files.reports=reports/gzip_knn/500/symmetry_false hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/gzip_knn/500/symmetry_false
      hash: md5
      md5: 993b2bdb4e4c280b8ee620189da67025.dir
      size: 1018254
      nfiles: 513
    - path: kdd_nsl/reports/gzip_knn/500/symmetry_false/train/
      hash: md5
      md5: c312efd750558409341a8ce8a7f4973a.dir
      size: 180885
      nfiles: 141
  grid_search@500-kdd_nsl-gzip_logistic-true:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=500 data.sample.test_size=100 model_name=gzip_logistic
      model.init.distance_matrix=null model.init.symmetric=true hydra.sweeper.study_name=gzip_logistic_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/gzip_logistic/500/symmetry_true
      hydra.callbacks.study_dump.output_file=kdd_nsl/logs/gzip_logistic/500/study.csv
      files.directory=kdd_nsl files.reports=reports/gzip_logistic/500/symmetry_true
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/gzip_logistic/500/symmetry_true
      hash: md5
      md5: 8e068a0a85d8b5cc11451f7bcfd5a407.dir
      size: 1101123
      nfiles: 513
    - path: kdd_nsl/reports/gzip_logistic/500/symmetry_true/train/
      hash: md5
      md5: dacffb3908638915d17d4eba974f9cf8.dir
      size: 743302
      nfiles: 260
  grid_search@500-kdd_nsl-gzip_logistic-false:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=500 data.sample.test_size=100 model_name=gzip_logistic
      model.init.distance_matrix=null model.init.symmetric=false hydra.sweeper.study_name=gzip_logistic_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/gzip_logistic/500/symmetry_false
      hydra.callbacks.study_dump.output_file=kdd_nsl/logs/gzip_logistic/500/study.csv
      files.directory=kdd_nsl files.reports=reports/gzip_logistic/500/symmetry_false
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/gzip_logistic/500/symmetry_false
      hash: md5
      md5: c3b5a0ee2dd94ab3c64fd0a2cd89587f.dir
      size: 1103141
      nfiles: 513
    - path: kdd_nsl/reports/gzip_logistic/500/symmetry_false/train/
      hash: md5
      md5: a7781264939a0bfeb9e0392b1dcf2db1.dir
      size: 715883
      nfiles: 264
  grid_search@500-kdd_nsl-gzip_svc-true:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=500 data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_svc_kdd_nsl hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/gzip_svc/500/symmetry_true
      hydra.callbacks.study_dump.output_file=kdd_nsl/logs/gzip_svc/500/study.csv files.directory=kdd_nsl
      files.reports=reports/gzip_svc/500/symmetry_true hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/gzip_svc/500/symmetry_true
      hash: md5
      md5: d609b9b853cbc51c87bf9f3e1bddc101.dir
      size: 1060092
      nfiles: 513
    - path: kdd_nsl/reports/gzip_svc/500/symmetry_true/train/
      hash: md5
      md5: 326bc76a141d1a53cdd7fde5aff7f2d5.dir
      size: 555006
      nfiles: 384
  grid_search@500-kdd_nsl-gzip_svc-false:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=500 data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_svc_kdd_nsl hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/gzip_svc/500/symmetry_false
      hydra.callbacks.study_dump.output_file=kdd_nsl/logs/gzip_svc/500/study.csv files.directory=kdd_nsl
      files.reports=reports/gzip_svc/500/symmetry_false hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/gzip_svc/500/symmetry_false
      hash: md5
      md5: b46c949a5aaf7426147abaa4c491caca.dir
      size: 1061973
      nfiles: 513
    - path: kdd_nsl/reports/gzip_svc/500/symmetry_false/train/
      hash: md5
      md5: 25647cb3ad18137b912a4718948b3a42.dir
      size: 555376
      nfiles: 384
  grid_search@500-sms_spam-gzip_knn-true:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=500 data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_knn_sms_spam hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/gzip_knn/500/symmetry_true
      hydra.callbacks.study_dump.output_file=sms_spam/logs/gzip_knn/500/study.csv
      files.directory=sms_spam files.reports=reports/gzip_knn/500/symmetry_true hydra.launcher.n_jobs=-1
      ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/gzip_knn/500/symmetry_true
      hash: md5
      md5: 24e581f99c292ad3b940ace0d5598fa3.dir
      size: 1023783
      nfiles: 513
    - path: sms_spam/reports/gzip_knn/500/symmetry_true/train/
      hash: md5
      md5: d3e2b9311551817cf8a8cb67a8ca72f5.dir
      size: 164672
      nfiles: 162
  grid_search@500-sms_spam-gzip_knn-false:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=500 data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_knn_sms_spam hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/gzip_knn/500/symmetry_false
      hydra.callbacks.study_dump.output_file=sms_spam/logs/gzip_knn/500/study.csv
      files.directory=sms_spam files.reports=reports/gzip_knn/500/symmetry_false hydra.launcher.n_jobs=-1
      ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/gzip_knn/500/symmetry_false
      hash: md5
      md5: e72562066a1aea9ca80d3483e2ca8642.dir
      size: 1013149
      nfiles: 513
    - path: sms_spam/reports/gzip_knn/500/symmetry_false/train/
      hash: md5
      md5: c228e503b8fe9b585dd1a484d8ebd081.dir
      size: 142048
      nfiles: 111
  grid_search@500-sms_spam-gzip_logistic-true:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=500 data.sample.test_size=100 model_name=gzip_logistic
      model.init.distance_matrix=null model.init.symmetric=true hydra.sweeper.study_name=gzip_logistic_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/gzip_logistic/500/symmetry_true
      hydra.callbacks.study_dump.output_file=sms_spam/logs/gzip_logistic/500/study.csv
      files.directory=sms_spam files.reports=reports/gzip_logistic/500/symmetry_true
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/gzip_logistic/500/symmetry_true
      hash: md5
      md5: 6c400add9a8ec85ccba4cacf1b3bd08a.dir
      size: 1101988
      nfiles: 513
    - path: sms_spam/reports/gzip_logistic/500/symmetry_true/train/
      hash: md5
      md5: 3cbead4df7612dc93d99f5b127696084.dir
      size: 692359
      nfiles: 287
  grid_search@500-sms_spam-gzip_logistic-false:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=500 data.sample.test_size=100 model_name=gzip_logistic
      model.init.distance_matrix=null model.init.symmetric=false hydra.sweeper.study_name=gzip_logistic_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/gzip_logistic/500/symmetry_false
      hydra.callbacks.study_dump.output_file=sms_spam/logs/gzip_logistic/500/study.csv
      files.directory=sms_spam files.reports=reports/gzip_logistic/500/symmetry_false
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/gzip_logistic/500/symmetry_false
      hash: md5
      md5: 09a0bc7b3cdff9ad4487489a8e988a0e.dir
      size: 1102727
      nfiles: 513
    - path: sms_spam/reports/gzip_logistic/500/symmetry_false/train/
      hash: md5
      md5: 4e9621b0318f247def21885b160885f7.dir
      size: 670854
      nfiles: 290
  grid_search@500-sms_spam-gzip_svc-true:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=500 data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_svc_sms_spam hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/gzip_svc/500/symmetry_true
      hydra.callbacks.study_dump.output_file=sms_spam/logs/gzip_svc/500/study.csv
      files.directory=sms_spam files.reports=reports/gzip_svc/500/symmetry_true hydra.launcher.n_jobs=-1
      ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/gzip_svc/500/symmetry_true
      hash: md5
      md5: b8dcb2c63cc21475ff4f1923713831e2.dir
      size: 1059728
      nfiles: 513
    - path: sms_spam/reports/gzip_svc/500/symmetry_true/train/
      hash: md5
      md5: f1b05b2ebabe638bca487f30391b2690.dir
      size: 543415
      nfiles: 384
  grid_search@500-sms_spam-gzip_svc-false:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=500 data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_svc_sms_spam hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/gzip_svc/500/symmetry_false
      hydra.callbacks.study_dump.output_file=sms_spam/logs/gzip_svc/500/study.csv
      files.directory=sms_spam files.reports=reports/gzip_svc/500/symmetry_false hydra.launcher.n_jobs=-1
      ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/gzip_svc/500/symmetry_false
      hash: md5
      md5: ff00b6e6ee6018edfa3a91a9cc5408b4.dir
      size: 1056172
      nfiles: 513
    - path: sms_spam/reports/gzip_svc/500/symmetry_false/train/
      hash: md5
      md5: c196e66231a6e2724ac3581d303b81f2.dir
      size: 542594
      nfiles: 384
  grid_search@500-truthseeker-gzip_knn-true:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=500 data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_knn_truthseeker hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/gzip_knn/500/symmetry_true
      hydra.callbacks.study_dump.output_file=truthseeker/logs/gzip_knn/500/study.csv
      files.directory=truthseeker files.reports=reports/gzip_knn/500/symmetry_true
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/gzip_knn/500/symmetry_true
      hash: md5
      md5: 5c896e4b5b94b618c88f6fde91553f87.dir
      size: 1032521
      nfiles: 513
    - path: truthseeker/reports/gzip_knn/500/symmetry_true/train/
      hash: md5
      md5: 31a47d06a9126a05630ca553c04972ee.dir
      size: 132062
      nfiles: 123
  grid_search@500-truthseeker-gzip_knn-false:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=500 data.sample.test_size=100 model_name=gzip_knn model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_knn_truthseeker hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/gzip_knn/500/symmetry_false
      hydra.callbacks.study_dump.output_file=truthseeker/logs/gzip_knn/500/study.csv
      files.directory=truthseeker files.reports=reports/gzip_knn/500/symmetry_false
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_knn --multirun
    deps:
    - path: conf/gzip_knn.yaml
      hash: md5
      md5: 2d0f54d62dcdc05d21ea1730899de0bb
      size: 1827
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_knn.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            direction: ${direction}
            storage: sqlite:///optuna.db
            study_name: ${dataset}_${model_name}_${stage}
            n_trials: 128
            n_jobs: 8
            max_failure_rate: 1.0
            params:
              model.init.k: 1,3,5,7,11
              +model.init.weights: uniform,distance
              +model.init.algorithm: brute
              model_name: ${model_name}
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/gzip_knn/500/symmetry_false
      hash: md5
      md5: eb869a15a1f191a8535ed643d4edc49e.dir
      size: 1032194
      nfiles: 513
    - path: truthseeker/reports/gzip_knn/500/symmetry_false/train/
      hash: md5
      md5: bd08610afec81330e21cbd2acdc593cf.dir
      size: 259439
      nfiles: 240
  grid_search@500-truthseeker-gzip_logistic-true:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=500 data.sample.test_size=100 model_name=gzip_logistic
      model.init.distance_matrix=null model.init.symmetric=true hydra.sweeper.study_name=gzip_logistic_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/gzip_logistic/500/symmetry_true
      hydra.callbacks.study_dump.output_file=truthseeker/logs/gzip_logistic/500/study.csv
      files.directory=truthseeker files.reports=reports/gzip_logistic/500/symmetry_true
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/gzip_logistic/500/symmetry_true
      hash: md5
      md5: 933cd92ea61aaa05c8263d8e32111994.dir
      size: 1109798
      nfiles: 513
    - path: truthseeker/reports/gzip_logistic/500/symmetry_true/train/
      hash: md5
      md5: 827484f2bda7cfc6fa29d8948c530c04.dir
      size: 694506
      nfiles: 288
  grid_search@500-truthseeker-gzip_logistic-false:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=500 data.sample.test_size=100 model_name=gzip_logistic
      model.init.distance_matrix=null model.init.symmetric=false hydra.sweeper.study_name=gzip_logistic_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/gzip_logistic/500/symmetry_false
      hydra.callbacks.study_dump.output_file=truthseeker/logs/gzip_logistic/500/study.csv
      files.directory=truthseeker files.reports=reports/gzip_logistic/500/symmetry_false
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_logistic --multirun
    deps:
    - path: conf/gzip_logistic.yaml
      hash: md5
      md5: da7adfd9b59783b6cd34f750dfcfb1b5
      size: 1993
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_logistic.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.solver: saga
              +model.init.penalty: l2,l1
              +model.init.tol: tag(log, interval(1e-5, 1e-1))
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.fit_intercept: True,False
              +model.init.class_weight: balanced,None
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/gzip_logistic/500/symmetry_false
      hash: md5
      md5: d73d5159418041db6a04e3b2e28eb098.dir
      size: 1118714
      nfiles: 513
    - path: truthseeker/reports/gzip_logistic/500/symmetry_false/train/
      hash: md5
      md5: 9660dec7dadbe748a21dc47e69643b22.dir
      size: 610771
      nfiles: 341
  grid_search@500-truthseeker-gzip_svc-true:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=500 data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=true hydra.sweeper.study_name=gzip_svc_truthseeker hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/gzip_svc/500/symmetry_true
      hydra.callbacks.study_dump.output_file=truthseeker/logs/gzip_svc/500/study.csv
      files.directory=truthseeker files.reports=reports/gzip_svc/500/symmetry_true
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/gzip_svc/500/symmetry_true
      hash: md5
      md5: d7797b07b709fc08fcddabffecc95715.dir
      size: 1069472
      nfiles: 513
    - path: truthseeker/reports/gzip_svc/500/symmetry_true/train/
      hash: md5
      md5: bf48b74c530fed43c500ebd372118313.dir
      size: 547534
      nfiles: 384
  grid_search@500-truthseeker-gzip_svc-false:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=500 data.sample.test_size=100 model_name=gzip_svc model.init.distance_matrix=null
      model.init.symmetric=false hydra.sweeper.study_name=gzip_svc_truthseeker hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/gzip_svc/500/symmetry_false
      hydra.callbacks.study_dump.output_file=truthseeker/logs/gzip_svc/500/study.csv
      files.directory=truthseeker files.reports=reports/gzip_svc/500/symmetry_false
      hydra.launcher.n_jobs=-1 ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10 
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True                --config-name gzip_svc --multirun
    deps:
    - path: conf/gzip_svc.yaml
      hash: md5
      md5: ef6089c75166b6acb57ce97a89157ad9
      size: 1905
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/gzip_svc.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/${stage}/
          sweep:
            dir: ???
            subdir: ${hydra.job.id}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions:
              - maximize
              metric_names:
              - accuracy
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              consider_prior: true
              seed: 123
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: true
              n_startup_trials: 256
              n_ei_candidates: 32
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}_${stage}
            storage: sqlite:///optuna.db
            n_trials: 128
            n_jobs: 8
            params:
              +model.init.kernel: rbf,precomputed
              +model.init.C: tag(log, interval(1e-3, 1e3))
              +model.init.gamma: scale,auto
              +model.init.class_weight: balanced,null
              model_name: ${model_name}
            direction: ${direction}
            max_failure_rate: 1.0
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/gzip_svc/500/symmetry_false
      hash: md5
      md5: 5d3c0127195e4fb8c4cb65feb003ad80.dir
      size: 1040683
      nfiles: 513
    - path: truthseeker/reports/gzip_svc/500/symmetry_false/train/
      hash: md5
      md5: 57c31d6310b68e4f1ab72a73cd963b54.dir
      size: 754764
      nfiles: 529
  condense@ddos-knn-1-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_knn model=gzip_knn ++model.init.m=1
      ++model.init.distance_matrix=ddos/models/knn/gzip/1/distance_matrix.npz files.directory=ddos
      files.reports=reports/condense/knn/gzip/1/ hydra.sweeper.study_name=condense_knn_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/knn/gzip/1/
      hydra.callbacks.study_dump.output_file=ddos/knn/gzip/1/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/knn/gzip/1
      hash: md5
      md5: e2530b3f5106d0132be96f27642d0ae6.dir
      size: 1030100
      nfiles: 513
    - path: ddos/models/knn/gzip/1/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: ddos/reports/condense/knn/gzip/1
      hash: md5
      md5: cad182899ec15d21bd60b6a01c9a6301.dir
      size: 274309
      nfiles: 194
  condense@ddos-knn-0.9-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=1000
      data.sample.test_size=400 model_name=condensed_knn model=gzip_knn ++model.init.m=0.9
      ++model.init.distance_matrix=null files.directory=ddos files.reports=reports/condense/knn/gzip/0.9/
      hydra.sweeper.study_name=condense_knn_ddos hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8
      hydra.sweep.dir=ddos/logs/condense/knn/gzip/0.9/ hydra.callbacks.study_dump.output_file=ddos/knn/gzip/0.9/study.csv
      hydra.launcher.n_jobs=-1 --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 656748d0afcf960f44886e5272318833
      size: 2056
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/knn/gzip/0.9
      hash: md5
      md5: 25711fcae4fd6e8f990800955c973213.dir
      size: 996013
      nfiles: 513
  condense@ddos-knn-0.8-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_knn model=gzip_knn ++model.init.m=0.8
      ++model.init.distance_matrix=ddos/models/knn/gzip/0.8/distance_matrix.npz files.directory=ddos
      files.reports=reports/condense/knn/gzip/0.8/ hydra.sweeper.study_name=condense_knn_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/knn/gzip/0.8/
      hydra.callbacks.study_dump.output_file=ddos/knn/gzip/0.8/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/knn/gzip/0.8
      hash: md5
      md5: a33a7c1beb949b1b919525c31c416669.dir
      size: 1034615
      nfiles: 513
    - path: ddos/models/knn/gzip/0.8/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: ddos/reports/condense/knn/gzip/0.8
      hash: md5
      md5: 054a70f0b4b95c11d0129df7c2b92790.dir
      size: 176709
      nfiles: 193
  condense@ddos-knn-0.7-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_knn model=gzip_knn ++model.init.m=0.7
      ++model.init.distance_matrix=ddos/models/knn/gzip/0.7/distance_matrix.npz files.directory=ddos
      files.reports=reports/condense/knn/gzip/0.7/ hydra.sweeper.study_name=condense_knn_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/knn/gzip/0.7/
      hydra.callbacks.study_dump.output_file=ddos/knn/gzip/0.7/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/knn/gzip/0.7
      hash: md5
      md5: 010613a05537cec37591d79073a75a62.dir
      size: 1035175
      nfiles: 513
    - path: ddos/models/knn/gzip/0.7/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: ddos/reports/condense/knn/gzip/0.7
      hash: md5
      md5: 8974f2230e551c8f7e767f11d9929c7b.dir
      size: 260520
      nfiles: 285
  condense@ddos-knn-0.6-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_knn model=gzip_knn ++model.init.m=0.6
      ++model.init.distance_matrix=ddos/models/knn/gzip/0.6/distance_matrix.npz files.directory=ddos
      files.reports=reports/condense/knn/gzip/0.6/ hydra.sweeper.study_name=condense_knn_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/knn/gzip/0.6/
      hydra.callbacks.study_dump.output_file=ddos/knn/gzip/0.6/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/knn/gzip/0.6
      hash: md5
      md5: a2472f4a0dedd42bcee93009cc9fa5ca.dir
      size: 1035136
      nfiles: 513
    - path: ddos/models/knn/gzip/0.6/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: ddos/reports/condense/knn/gzip/0.6
      hash: md5
      md5: 2bb80facfa3d726065ba7757b153c945.dir
      size: 301659
      nfiles: 330
  condense@ddos-knn-0.5-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_knn model=gzip_knn ++model.init.m=0.5
      ++model.init.distance_matrix=ddos/models/knn/gzip/0.5/distance_matrix.npz files.directory=ddos
      files.reports=reports/condense/knn/gzip/0.5/ hydra.sweeper.study_name=condense_knn_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/knn/gzip/0.5/
      hydra.callbacks.study_dump.output_file=ddos/knn/gzip/0.5/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/knn/gzip/0.5
      hash: md5
      md5: 7499ff9ff275a26ceb7e8e58602176ae.dir
      size: 1035233
      nfiles: 513
    - path: ddos/models/knn/gzip/0.5/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: ddos/reports/condense/knn/gzip/0.5
      hash: md5
      md5: dd2a634e57b951027420f3c26f9c2c88.dir
      size: 309907
      nfiles: 339
  condense@ddos-knn-0.4-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_knn model=gzip_knn ++model.init.m=0.4
      ++model.init.distance_matrix=ddos/models/knn/gzip/0.4/distance_matrix.npz files.directory=ddos
      files.reports=reports/condense/knn/gzip/0.4/ hydra.sweeper.study_name=condense_knn_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/knn/gzip/0.4/
      hydra.callbacks.study_dump.output_file=ddos/knn/gzip/0.4/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/knn/gzip/0.4
      hash: md5
      md5: d2dd00a1d7d9ca4d8e565b8f3cbe2e4f.dir
      size: 1035184
      nfiles: 513
    - path: ddos/models/knn/gzip/0.4/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: ddos/reports/condense/knn/gzip/0.4
      hash: md5
      md5: 97f63f7128a388b4a621705796a1d3c0.dir
      size: 304365
      nfiles: 333
  condense@ddos-knn-0.3-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_knn model=gzip_knn ++model.init.m=0.3
      ++model.init.distance_matrix=ddos/models/knn/gzip/0.3/distance_matrix.npz files.directory=ddos
      files.reports=reports/condense/knn/gzip/0.3/ hydra.sweeper.study_name=condense_knn_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/knn/gzip/0.3/
      hydra.callbacks.study_dump.output_file=ddos/knn/gzip/0.3/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/knn/gzip/0.3
      hash: md5
      md5: 7f67b0fac72677f3a93f8b7dcc854e96.dir
      size: 1035263
      nfiles: 513
    - path: ddos/models/knn/gzip/0.3/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: ddos/reports/condense/knn/gzip/0.3
      hash: md5
      md5: a77f59346e085b8be390968e9e7c4a80.dir
      size: 304361
      nfiles: 333
  condense@ddos-knn-0.2-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_knn model=gzip_knn ++model.init.m=0.2
      ++model.init.distance_matrix=ddos/models/knn/gzip/0.2/distance_matrix.npz files.directory=ddos
      files.reports=reports/condense/knn/gzip/0.2/ hydra.sweeper.study_name=condense_knn_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/knn/gzip/0.2/
      hydra.callbacks.study_dump.output_file=ddos/knn/gzip/0.2/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/knn/gzip/0.2
      hash: md5
      md5: 11863b3089688d59fe5edcbef2bc7c56.dir
      size: 1043170
      nfiles: 513
    - path: ddos/models/knn/gzip/0.2/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: ddos/reports/condense/knn/gzip/0.2
      hash: md5
      md5: e5bb1a5c8c9a0199bb382cde927ceeea.dir
      size: 422205
      nfiles: 462
  condense@ddos-knn-0.1-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_knn model=gzip_knn ++model.init.m=0.1
      ++model.init.distance_matrix=ddos/models/knn/gzip/0.1/distance_matrix.npz files.directory=ddos
      files.reports=reports/condense/knn/gzip/0.1/ hydra.sweeper.study_name=condense_knn_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/knn/gzip/0.1/
      hydra.callbacks.study_dump.output_file=ddos/knn/gzip/0.1/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/knn/gzip/0.1
      hash: md5
      md5: 8ab58e37bd8a9afa0808b6e1c34fcb4e.dir
      size: 1035229
      nfiles: 513
    - path: ddos/models/knn/gzip/0.1/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: ddos/reports/condense/knn/gzip/0.1
      hash: md5
      md5: 31a19981cf6be710abfcdcf4564cd1be.dir
      size: 291591
      nfiles: 292
  condense@ddos-svc-1-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=1000
      data.sample.test_size=400 model_name=svc model=gzip_svc ++model.init.m=1 files.directory=ddos
      hydra.sweeper.study_name=gzip_svc_ddos files.reports=reports/condense/svc/gzip/1/
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/svc/gzip/1/
      hydra.callbacks.study_dump.output_file=ddos/svc/gzip/1/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: d75c54fc33a8fb1b9c9103b6159890d0
      size: 1948
    - path: ddos/models/svc/gzip/
      hash: md5
      md5: 4b1b97143c61ce9b640261fa71705d7c.dir
      size: 2962257
      nfiles: 2
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/svc/gzip/1
      hash: md5
      md5: 8936260acd264c3ea5c051b9efddd29a.dir
      size: 1003336
      nfiles: 513
  condense@ddos-svc-0.9-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_svc model=gzip_svc ++model.init.m=0.9
      ++model.init.distance_matrix=ddos/models/svc/gzip/0.9/distance_matrix.npz files.directory=ddos
      files.reports=reports/condense/svc/gzip/0.9/ hydra.sweeper.study_name=condense_svc_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/svc/gzip/0.9/
      hydra.callbacks.study_dump.output_file=ddos/svc/gzip/0.9/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/svc/gzip/0.9
      hash: md5
      md5: d46a5af8498ad5c9e5360a34ea92d011.dir
      size: 1052531
      nfiles: 513
    - path: ddos/models/svc/gzip/0.9/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: ddos/reports/condense/svc/gzip/0.9
      hash: md5
      md5: 4a29d993a15db72f4d0948c1132d52a6.dir
      size: 201673
      nfiles: 139
  condense@ddos-svc-0.8-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_svc model=gzip_svc ++model.init.m=0.8
      ++model.init.distance_matrix=ddos/models/svc/gzip/0.8/distance_matrix.npz files.directory=ddos
      files.reports=reports/condense/svc/gzip/0.8/ hydra.sweeper.study_name=condense_svc_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/svc/gzip/0.8/
      hydra.callbacks.study_dump.output_file=ddos/svc/gzip/0.8/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/svc/gzip/0.8
      hash: md5
      md5: 8a6c5f68a7f548509edc2b4996b27ca4.dir
      size: 1058719
      nfiles: 513
    - path: ddos/models/svc/gzip/0.8/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: ddos/reports/condense/svc/gzip/0.8
      hash: md5
      md5: 688da0c0e02ef76f5732e917185b0cd8.dir
      size: 219360
      nfiles: 151
  condense@ddos-svc-0.7-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_svc model=gzip_svc ++model.init.m=0.7
      ++model.init.distance_matrix=ddos/models/svc/gzip/0.7/distance_matrix.npz files.directory=ddos
      files.reports=reports/condense/svc/gzip/0.7/ hydra.sweeper.study_name=condense_svc_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/svc/gzip/0.7/
      hydra.callbacks.study_dump.output_file=ddos/svc/gzip/0.7/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/svc/gzip/0.7
      hash: md5
      md5: 6e5abeb4dbb7b7c88d89ba37d9f28195.dir
      size: 1056543
      nfiles: 513
    - path: ddos/models/svc/gzip/0.7/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: ddos/reports/condense/svc/gzip/0.7
      hash: md5
      md5: dfb03f2660d915bcc66f8a6b46fe795b.dir
      size: 288900
      nfiles: 199
  condense@ddos-svc-0.6-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_svc model=gzip_svc ++model.init.m=0.6
      ++model.init.distance_matrix=ddos/models/svc/gzip/0.6/distance_matrix.npz files.directory=ddos
      files.reports=reports/condense/svc/gzip/0.6/ hydra.sweeper.study_name=condense_svc_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/svc/gzip/0.6/
      hydra.callbacks.study_dump.output_file=ddos/svc/gzip/0.6/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/svc/gzip/0.6
      hash: md5
      md5: 0c757196ff3e6c41fef82ff63b2b203d.dir
      size: 1056549
      nfiles: 513
    - path: ddos/models/svc/gzip/0.6/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: ddos/reports/condense/svc/gzip/0.6
      hash: md5
      md5: 7479bae9e4d10b9b5b2fc94f3fb841d6.dir
      size: 393531
      nfiles: 271
  condense@ddos-svc-0.5-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_svc model=gzip_svc ++model.init.m=0.5
      ++model.init.distance_matrix=ddos/models/svc/gzip/0.5/distance_matrix.npz files.directory=ddos
      files.reports=reports/condense/svc/gzip/0.5/ hydra.sweeper.study_name=condense_svc_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/svc/gzip/0.5/
      hydra.callbacks.study_dump.output_file=ddos/svc/gzip/0.5/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/svc/gzip/0.5
      hash: md5
      md5: a28ab251fd3dffe0b4ab43620f933bde.dir
      size: 1057160
      nfiles: 513
    - path: ddos/models/svc/gzip/0.5/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: ddos/reports/condense/svc/gzip/0.5
      hash: md5
      md5: d9d25c555a858dd8cd4c41059eb007c2.dir
      size: 492639
      nfiles: 339
  condense@ddos-svc-0.4-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_svc model=gzip_svc ++model.init.m=0.4
      ++model.init.distance_matrix=ddos/models/svc/gzip/0.4/distance_matrix.npz files.directory=ddos
      files.reports=reports/condense/svc/gzip/0.4/ hydra.sweeper.study_name=condense_svc_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/svc/gzip/0.4/
      hydra.callbacks.study_dump.output_file=ddos/svc/gzip/0.4/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/svc/gzip/0.4
      hash: md5
      md5: 56aa3293cd2e67e1150dd3aea2ccba9f.dir
      size: 1057925
      nfiles: 513
    - path: ddos/models/svc/gzip/0.4/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: ddos/reports/condense/svc/gzip/0.4
      hash: md5
      md5: 2f63f4d5ec084459522eda16f17bdfd3.dir
      size: 505986
      nfiles: 348
  condense@ddos-svc-0.3-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_svc model=gzip_svc ++model.init.m=0.3
      ++model.init.distance_matrix=ddos/models/svc/gzip/0.3/distance_matrix.npz files.directory=ddos
      files.reports=reports/condense/svc/gzip/0.3/ hydra.sweeper.study_name=condense_svc_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/svc/gzip/0.3/
      hydra.callbacks.study_dump.output_file=ddos/svc/gzip/0.3/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/svc/gzip/0.3
      hash: md5
      md5: d61ef86495502d0df5269279d57c4612.dir
      size: 1058376
      nfiles: 513
    - path: ddos/models/svc/gzip/0.3/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: ddos/reports/condense/svc/gzip/0.3
      hash: md5
      md5: 7ace38e24c8e1bae5ef38c4bf1ee809f.dir
      size: 519132
      nfiles: 357
  condense@ddos-svc-0.2-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_svc model=gzip_svc ++model.init.m=0.2
      ++model.init.distance_matrix=ddos/models/svc/gzip/0.2/distance_matrix.npz files.directory=ddos
      files.reports=reports/condense/svc/gzip/0.2/ hydra.sweeper.study_name=condense_svc_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/svc/gzip/0.2/
      hydra.callbacks.study_dump.output_file=ddos/svc/gzip/0.2/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/svc/gzip/0.2
      hash: md5
      md5: f115372f5e02db19a84a8303adf085bd.dir
      size: 1058346
      nfiles: 513
    - path: ddos/models/svc/gzip/0.2/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: ddos/reports/condense/svc/gzip/0.2
      hash: md5
      md5: 7b7b89d99a39eee872dd0a53fa0bc656.dir
      size: 510431
      nfiles: 351
  condense@ddos-svc-0.1-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_svc model=gzip_svc ++model.init.m=0.1
      ++model.init.distance_matrix=ddos/models/svc/gzip/0.1/distance_matrix.npz files.directory=ddos
      files.reports=reports/condense/svc/gzip/0.1/ hydra.sweeper.study_name=condense_svc_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/svc/gzip/0.1/
      hydra.callbacks.study_dump.output_file=ddos/svc/gzip/0.1/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/svc/gzip/0.1
      hash: md5
      md5: 5b52170edada651272ee1d698fd1f54f.dir
      size: 1057384
      nfiles: 513
    - path: ddos/models/svc/gzip/0.1/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: ddos/reports/condense/svc/gzip/0.1
      hash: md5
      md5: dd5782e68590fd14b111ec6d09c5d1d6.dir
      size: 464246
      nfiles: 317
  condense@ddos-logistic-1-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_logistic model=gzip_logistic
      ++model.init.m=1 ++model.init.distance_matrix=ddos/models/logistic/gzip/1/distance_matrix.npz
      files.directory=ddos files.reports=reports/condense/logistic/gzip/1/ hydra.sweeper.study_name=condense_logistic_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/logistic/gzip/1/
      hydra.callbacks.study_dump.output_file=ddos/logistic/gzip/1/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: b52399ed877cfdd5fea482ac5ec149dc
      size: 2186
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/logistic/gzip/1
      hash: md5
      md5: f6bdf83aac179d1a6fda10847b1ece04.dir
      size: 1102183
      nfiles: 513
    - path: ddos/models/logistic/gzip/1/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
  condense@ddos-logistic-0.9-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_logistic model=gzip_logistic
      ++model.init.m=0.9 ++model.init.distance_matrix=ddos/models/logistic/gzip/0.9/distance_matrix.npz
      files.directory=ddos files.reports=reports/condense/logistic/gzip/0.9/ hydra.sweeper.study_name=condense_logistic_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/logistic/gzip/0.9/
      hydra.callbacks.study_dump.output_file=ddos/logistic/gzip/0.9/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: b52399ed877cfdd5fea482ac5ec149dc
      size: 2186
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/logistic/gzip/0.9
      hash: md5
      md5: aaf110f40fb850f3161782d3c3b6ce8b.dir
      size: 1119208
      nfiles: 513
    - path: ddos/models/logistic/gzip/0.9/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
  condense@ddos-logistic-0.8-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_logistic model=gzip_logistic
      ++model.init.m=0.8 ++model.init.distance_matrix=ddos/models/logistic/gzip/0.8/distance_matrix.npz
      files.directory=ddos files.reports=reports/condense/logistic/gzip/0.8/ hydra.sweeper.study_name=condense_logistic_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/logistic/gzip/0.8/
      hydra.callbacks.study_dump.output_file=ddos/logistic/gzip/0.8/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: b52399ed877cfdd5fea482ac5ec149dc
      size: 2186
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/logistic/gzip/0.8
      hash: md5
      md5: 59b163295c791530e2b91431228a189d.dir
      size: 1106188
      nfiles: 513
    - path: ddos/models/logistic/gzip/0.8/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
  condense@ddos-logistic-0.7-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_logistic model=gzip_logistic
      ++model.init.m=0.7 ++model.init.distance_matrix=ddos/models/logistic/gzip/0.7/distance_matrix.npz
      files.directory=ddos files.reports=reports/condense/logistic/gzip/0.7/ hydra.sweeper.study_name=condense_logistic_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/logistic/gzip/0.7/
      hydra.callbacks.study_dump.output_file=ddos/logistic/gzip/0.7/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: b52399ed877cfdd5fea482ac5ec149dc
      size: 2186
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/logistic/gzip/0.7
      hash: md5
      md5: 7b911e30ae93b3370d819cc772a2dac4.dir
      size: 1104218
      nfiles: 513
    - path: ddos/models/logistic/gzip/0.7/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
  condense@ddos-logistic-0.6-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_logistic model=gzip_logistic
      ++model.init.m=0.6 ++model.init.distance_matrix=ddos/models/logistic/gzip/0.6/distance_matrix.npz
      files.directory=ddos files.reports=reports/condense/logistic/gzip/0.6/ hydra.sweeper.study_name=condense_logistic_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/logistic/gzip/0.6/
      hydra.callbacks.study_dump.output_file=ddos/logistic/gzip/0.6/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: b52399ed877cfdd5fea482ac5ec149dc
      size: 2186
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/logistic/gzip/0.6
      hash: md5
      md5: a90e22b3cb302abae5747abf85643e80.dir
      size: 1101555
      nfiles: 513
    - path: ddos/models/logistic/gzip/0.6/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
  condense@ddos-logistic-0.5-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_logistic model=gzip_logistic
      ++model.init.m=0.5 ++model.init.distance_matrix=ddos/models/logistic/gzip/0.5/distance_matrix.npz
      files.directory=ddos files.reports=reports/condense/logistic/gzip/0.5/ hydra.sweeper.study_name=condense_logistic_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/logistic/gzip/0.5/
      hydra.callbacks.study_dump.output_file=ddos/logistic/gzip/0.5/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: b52399ed877cfdd5fea482ac5ec149dc
      size: 2186
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/logistic/gzip/0.5
      hash: md5
      md5: 669139d571377fcfad1d51e8cdc417bc.dir
      size: 1100844
      nfiles: 513
    - path: ddos/models/logistic/gzip/0.5/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
  condense@ddos-logistic-0.4-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_logistic model=gzip_logistic
      ++model.init.m=0.4 ++model.init.distance_matrix=ddos/models/logistic/gzip/0.4/distance_matrix.npz
      files.directory=ddos files.reports=reports/condense/logistic/gzip/0.4/ hydra.sweeper.study_name=condense_logistic_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/logistic/gzip/0.4/
      hydra.callbacks.study_dump.output_file=ddos/logistic/gzip/0.4/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: b52399ed877cfdd5fea482ac5ec149dc
      size: 2186
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/logistic/gzip/0.4
      hash: md5
      md5: 483c282e0c7c7961edbc2fbf91d342ac.dir
      size: 1098979
      nfiles: 513
    - path: ddos/models/logistic/gzip/0.4/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
  condense@ddos-logistic-0.3-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_logistic model=gzip_logistic
      ++model.init.m=0.3 ++model.init.distance_matrix=ddos/models/logistic/gzip/0.3/distance_matrix.npz
      files.directory=ddos files.reports=reports/condense/logistic/gzip/0.3/ hydra.sweeper.study_name=condense_logistic_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/logistic/gzip/0.3/
      hydra.callbacks.study_dump.output_file=ddos/logistic/gzip/0.3/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: b52399ed877cfdd5fea482ac5ec149dc
      size: 2186
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/logistic/gzip/0.3
      hash: md5
      md5: 564673989645ece01737b7ac16e44583.dir
      size: 1098947
      nfiles: 513
    - path: ddos/models/logistic/gzip/0.3/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
  condense@ddos-logistic-0.2-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_logistic model=gzip_logistic
      ++model.init.m=0.2 ++model.init.distance_matrix=ddos/models/logistic/gzip/0.2/distance_matrix.npz
      files.directory=ddos files.reports=reports/condense/logistic/gzip/0.2/ hydra.sweeper.study_name=condense_logistic_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/logistic/gzip/0.2/
      hydra.callbacks.study_dump.output_file=ddos/logistic/gzip/0.2/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: b52399ed877cfdd5fea482ac5ec149dc
      size: 2186
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/logistic/gzip/0.2
      hash: md5
      md5: afc0b9461c0cf473c2afe0b1766897dd.dir
      size: 1097203
      nfiles: 513
    - path: ddos/models/logistic/gzip/0.2/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
  condense@ddos-logistic-0.1-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=100
      data.sample.test_size=100 model_name=condensed_logistic model=gzip_logistic
      ++model.init.m=0.1 ++model.init.distance_matrix=ddos/models/logistic/gzip/0.1/distance_matrix.npz
      files.directory=ddos files.reports=reports/condense/logistic/gzip/0.1/ hydra.sweeper.study_name=condense_logistic_ddos
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=ddos/logs/condense/logistic/gzip/0.1/
      hydra.callbacks.study_dump.output_file=ddos/logistic/gzip/0.1/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: b52399ed877cfdd5fea482ac5ec149dc
      size: 2186
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/condense/logistic/gzip/0.1
      hash: md5
      md5: 256cc55eb1e80ff6159b171f7820b7a6.dir
      size: 1096453
      nfiles: 513
    - path: ddos/models/logistic/gzip/0.1/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
  condense@kdd_nsl-knn-1-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=1000 data.sample.test_size=400 model_name=knn model=gzip_knn
      ++model.init.m=1 files.directory=kdd_nsl hydra.sweeper.study_name=gzip_knn_kdd_nsl
      files.reports=reports/condense/knn/gzip/1/ hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8
      hydra.sweep.dir=kdd_nsl/logs/condense/knn/gzip/1/ hydra.callbacks.study_dump.output_file=kdd_nsl/knn/gzip/1/study.csv
      hydra.launcher.n_jobs=-1 --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 18662f67a2a6744e2079f98759ca96b6
      size: 1933
    - path: kdd_nsl/models/knn/gzip/
      hash: md5
      md5: ced919c462f9086785c6bee960820562.dir
      size: 1713651
      nfiles: 2
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/knn/gzip/1
      hash: md5
      md5: a7b1806d80ad898ff03f69b013631602.dir
      size: 967772
      nfiles: 513
  condense@kdd_nsl-knn-0.9-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.9 ++model.init.distance_matrix=kdd_nsl/models/knn/gzip/0.9/distance_matrix.npz
      files.directory=kdd_nsl files.reports=reports/condense/knn/gzip/0.9/ hydra.sweeper.study_name=condense_knn_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/knn/gzip/0.9/
      hydra.callbacks.study_dump.output_file=kdd_nsl/knn/gzip/0.9/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/knn/gzip/0.9
      hash: md5
      md5: ce82f6ede2bcd8e2d067bcdae4497612.dir
      size: 1045384
      nfiles: 513
    - path: kdd_nsl/models/knn/gzip/0.9/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: kdd_nsl/reports/condense/knn/gzip/0.9
      hash: md5
      md5: d3616710236e46170b70de37843d6fac.dir
      size: 135429
      nfiles: 146
  condense@kdd_nsl-knn-0.8-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.8 ++model.init.distance_matrix=kdd_nsl/models/knn/gzip/0.8/distance_matrix.npz
      files.directory=kdd_nsl files.reports=reports/condense/knn/gzip/0.8/ hydra.sweeper.study_name=condense_knn_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/knn/gzip/0.8/
      hydra.callbacks.study_dump.output_file=kdd_nsl/knn/gzip/0.8/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/knn/gzip/0.8
      hash: md5
      md5: a9e7ce9bf88134292855cbfe96ebd979.dir
      size: 1044685
      nfiles: 513
    - path: kdd_nsl/models/knn/gzip/0.8/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: kdd_nsl/reports/condense/knn/gzip/0.8
      hash: md5
      md5: 6a1acb9ed16d73147a752d5cf500d3b3.dir
      size: 149243
      nfiles: 161
  condense@kdd_nsl-knn-0.7-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.7 ++model.init.distance_matrix=kdd_nsl/models/knn/gzip/0.7/distance_matrix.npz
      files.directory=kdd_nsl files.reports=reports/condense/knn/gzip/0.7/ hydra.sweeper.study_name=condense_knn_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/knn/gzip/0.7/
      hydra.callbacks.study_dump.output_file=kdd_nsl/knn/gzip/0.7/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/knn/gzip/0.7
      hash: md5
      md5: 92819a281f6b49b276da739611f8fd24.dir
      size: 1045182
      nfiles: 513
    - path: kdd_nsl/models/knn/gzip/0.7/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: kdd_nsl/reports/condense/knn/gzip/0.7
      hash: md5
      md5: 75e6ff9a870b0152a6344408e5d1f68d.dir
      size: 236720
      nfiles: 256
  condense@kdd_nsl-knn-0.6-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.6 ++model.init.distance_matrix=kdd_nsl/models/knn/gzip/0.6/distance_matrix.npz
      files.directory=kdd_nsl files.reports=reports/condense/knn/gzip/0.6/ hydra.sweeper.study_name=condense_knn_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/knn/gzip/0.6/
      hydra.callbacks.study_dump.output_file=kdd_nsl/knn/gzip/0.6/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/knn/gzip/0.6
      hash: md5
      md5: f868cafc8a9ca828c8b25140c092993e.dir
      size: 1045616
      nfiles: 513
    - path: kdd_nsl/models/knn/gzip/0.6/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: kdd_nsl/reports/condense/knn/gzip/0.6
      hash: md5
      md5: 86afc2adaf4ad4a827c8538e179e4e6e.dir
      size: 318724
      nfiles: 345
  condense@kdd_nsl-knn-0.5-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.5 ++model.init.distance_matrix=kdd_nsl/models/knn/gzip/0.5/distance_matrix.npz
      files.directory=kdd_nsl files.reports=reports/condense/knn/gzip/0.5/ hydra.sweeper.study_name=condense_knn_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/knn/gzip/0.5/
      hydra.callbacks.study_dump.output_file=kdd_nsl/knn/gzip/0.5/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/knn/gzip/0.5
      hash: md5
      md5: 9a48effb02b40325dfd447331adfc6ec.dir
      size: 1045228
      nfiles: 513
    - path: kdd_nsl/models/knn/gzip/0.5/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: kdd_nsl/reports/condense/knn/gzip/0.5
      hash: md5
      md5: f18788386d94f67e7b7ec82cb4e98150.dir
      size: 290924
      nfiles: 315
  condense@kdd_nsl-knn-0.4-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.4 ++model.init.distance_matrix=kdd_nsl/models/knn/gzip/0.4/distance_matrix.npz
      files.directory=kdd_nsl files.reports=reports/condense/knn/gzip/0.4/ hydra.sweeper.study_name=condense_knn_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/knn/gzip/0.4/
      hydra.callbacks.study_dump.output_file=kdd_nsl/knn/gzip/0.4/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/knn/gzip/0.4
      hash: md5
      md5: 31dbceaff14683f96b649d7a3b05a0b9.dir
      size: 1045298
      nfiles: 513
    - path: kdd_nsl/models/knn/gzip/0.4/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: kdd_nsl/reports/condense/knn/gzip/0.4
      hash: md5
      md5: a93ff52c044184d010d2607daed5301c.dir
      size: 257676
      nfiles: 279
  condense@kdd_nsl-knn-0.3-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.3 ++model.init.distance_matrix=kdd_nsl/models/knn/gzip/0.3/distance_matrix.npz
      files.directory=kdd_nsl files.reports=reports/condense/knn/gzip/0.3/ hydra.sweeper.study_name=condense_knn_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/knn/gzip/0.3/
      hydra.callbacks.study_dump.output_file=kdd_nsl/knn/gzip/0.3/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/knn/gzip/0.3
      hash: md5
      md5: e0bee1ff1753fc5ca107c25292089989.dir
      size: 1045580
      nfiles: 513
    - path: kdd_nsl/models/knn/gzip/0.3/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: kdd_nsl/reports/condense/knn/gzip/0.3
      hash: md5
      md5: bfdcb57e9c739d891f6531504c966a53.dir
      size: 302061
      nfiles: 327
  condense@kdd_nsl-knn-0.2-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.2 ++model.init.distance_matrix=kdd_nsl/models/knn/gzip/0.2/distance_matrix.npz
      files.directory=kdd_nsl files.reports=reports/condense/knn/gzip/0.2/ hydra.sweeper.study_name=condense_knn_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/knn/gzip/0.2/
      hydra.callbacks.study_dump.output_file=kdd_nsl/knn/gzip/0.2/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/knn/gzip/0.2
      hash: md5
      md5: dd4688a62d3f53e8962ab0b2f05ab573.dir
      size: 1045443
      nfiles: 513
    - path: kdd_nsl/models/knn/gzip/0.2/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: kdd_nsl/reports/condense/knn/gzip/0.2
      hash: md5
      md5: 15995bc1ccfef8aa69cd2f190dd92246.dir
      size: 279871
      nfiles: 303
  condense@kdd_nsl-knn-0.1-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.1 ++model.init.distance_matrix=kdd_nsl/models/knn/gzip/0.1/distance_matrix.npz
      files.directory=kdd_nsl files.reports=reports/condense/knn/gzip/0.1/ hydra.sweeper.study_name=condense_knn_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/knn/gzip/0.1/
      hydra.callbacks.study_dump.output_file=kdd_nsl/knn/gzip/0.1/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/knn/gzip/0.1
      hash: md5
      md5: 08fb6324c5e98c597f9ee2aba62a5ef7.dir
      size: 1045335
      nfiles: 513
    - path: kdd_nsl/models/knn/gzip/0.1/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: kdd_nsl/reports/condense/knn/gzip/0.1
      hash: md5
      md5: 1e373e6f60157768be938e659dd33e62.dir
      size: 264377
      nfiles: 258
  condense@kdd_nsl-svc-1-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=1 ++model.init.distance_matrix=kdd_nsl/models/svc/gzip/1/distance_matrix.npz
      files.directory=kdd_nsl files.reports=reports/condense/svc/gzip/1/ hydra.sweeper.study_name=condense_svc_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/svc/gzip/1/
      hydra.callbacks.study_dump.output_file=kdd_nsl/svc/gzip/1/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/svc/gzip/1
      hash: md5
      md5: b39548e8702b9491ae3b2841971ed282.dir
      size: 1053673
      nfiles: 513
    - path: kdd_nsl/models/svc/gzip/1/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: kdd_nsl/reports/condense/svc/gzip/1
      hash: md5
      md5: 93077bbc68d8bede48473f3fa254ecfc.dir
      size: 426179
      nfiles: 217
  condense@kdd_nsl-svc-0.9-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.9 ++model.init.distance_matrix=kdd_nsl/models/svc/gzip/0.9/distance_matrix.npz
      files.directory=kdd_nsl files.reports=reports/condense/svc/gzip/0.9/ hydra.sweeper.study_name=condense_svc_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/svc/gzip/0.9/
      hydra.callbacks.study_dump.output_file=kdd_nsl/svc/gzip/0.9/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/svc/gzip/0.9
      hash: md5
      md5: 453ee1fde28ad2271643d6fdb541383e.dir
      size: 1068119
      nfiles: 513
    - path: kdd_nsl/models/svc/gzip/0.9/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: kdd_nsl/reports/condense/svc/gzip/0.9
      hash: md5
      md5: 3ba8ed914b32abb8ffcf870aed5e24a5.dir
      size: 264602
      nfiles: 181
  condense@kdd_nsl-svc-0.8-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.8 ++model.init.distance_matrix=kdd_nsl/models/svc/gzip/0.8/distance_matrix.npz
      files.directory=kdd_nsl files.reports=reports/condense/svc/gzip/0.8/ hydra.sweeper.study_name=condense_svc_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/svc/gzip/0.8/
      hydra.callbacks.study_dump.output_file=kdd_nsl/svc/gzip/0.8/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/svc/gzip/0.8
      hash: md5
      md5: 2394838e1b6a76dcd45483d507424391.dir
      size: 1084678
      nfiles: 513
    - path: kdd_nsl/models/svc/gzip/0.8/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: kdd_nsl/reports/condense/svc/gzip/0.8
      hash: md5
      md5: 82e3e432408dda484e2a6404392ed746.dir
      size: 677262
      nfiles: 463
  condense@kdd_nsl-svc-0.7-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.7 ++model.init.distance_matrix=kdd_nsl/models/svc/gzip/0.7/distance_matrix.npz
      files.directory=kdd_nsl files.reports=reports/condense/svc/gzip/0.7/ hydra.sweeper.study_name=condense_svc_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/svc/gzip/0.7/
      hydra.callbacks.study_dump.output_file=kdd_nsl/svc/gzip/0.7/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/svc/gzip/0.7
      hash: md5
      md5: ee3b8edc4341696dec674d55cadd3572.dir
      size: 1068814
      nfiles: 513
    - path: kdd_nsl/models/svc/gzip/0.7/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: kdd_nsl/reports/condense/svc/gzip/0.7
      hash: md5
      md5: 29986cf96539f942f8d0d2f9e31743ae.dir
      size: 377656
      nfiles: 258
  condense@kdd_nsl-svc-0.6-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.6 ++model.init.distance_matrix=kdd_nsl/models/svc/gzip/0.6/distance_matrix.npz
      files.directory=kdd_nsl files.reports=reports/condense/svc/gzip/0.6/ hydra.sweeper.study_name=condense_svc_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/svc/gzip/0.6/
      hydra.callbacks.study_dump.output_file=kdd_nsl/svc/gzip/0.6/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/svc/gzip/0.6
      hash: md5
      md5: 2cf1763fa6b8ffd280e17c22349578f4.dir
      size: 1068217
      nfiles: 513
    - path: kdd_nsl/models/svc/gzip/0.6/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: kdd_nsl/reports/condense/svc/gzip/0.6
      hash: md5
      md5: 9ebe7e28e19185dc28e94fc602122235.dir
      size: 290983
      nfiles: 199
  condense@kdd_nsl-svc-0.5-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.5 ++model.init.distance_matrix=kdd_nsl/models/svc/gzip/0.5/distance_matrix.npz
      files.directory=kdd_nsl files.reports=reports/condense/svc/gzip/0.5/ hydra.sweeper.study_name=condense_svc_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/svc/gzip/0.5/
      hydra.callbacks.study_dump.output_file=kdd_nsl/svc/gzip/0.5/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/svc/gzip/0.5
      hash: md5
      md5: 3f7e6b80273dc9e95373b9afcfc5840d.dir
      size: 1069035
      nfiles: 513
    - path: kdd_nsl/models/svc/gzip/0.5/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: kdd_nsl/reports/condense/svc/gzip/0.5
      hash: md5
      md5: c4207f5e0b4f0e17d78b5f668357b358.dir
      size: 487493
      nfiles: 333
  condense@kdd_nsl-svc-0.4-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.4 ++model.init.distance_matrix=kdd_nsl/models/svc/gzip/0.4/distance_matrix.npz
      files.directory=kdd_nsl files.reports=reports/condense/svc/gzip/0.4/ hydra.sweeper.study_name=condense_svc_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/svc/gzip/0.4/
      hydra.callbacks.study_dump.output_file=kdd_nsl/svc/gzip/0.4/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/svc/gzip/0.4
      hash: md5
      md5: 82d3025359244b79a5774400516c1fce.dir
      size: 1069028
      nfiles: 513
    - path: kdd_nsl/models/svc/gzip/0.4/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: kdd_nsl/reports/condense/svc/gzip/0.4
      hash: md5
      md5: b3cb9e21eec52f52b167d05a9d4d2e1b.dir
      size: 540205
      nfiles: 369
  condense@kdd_nsl-svc-0.3-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.3 ++model.init.distance_matrix=kdd_nsl/models/svc/gzip/0.3/distance_matrix.npz
      files.directory=kdd_nsl files.reports=reports/condense/svc/gzip/0.3/ hydra.sweeper.study_name=condense_svc_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/svc/gzip/0.3/
      hydra.callbacks.study_dump.output_file=kdd_nsl/svc/gzip/0.3/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/svc/gzip/0.3
      hash: md5
      md5: f452b6cb583f27edaacbe5ee99cc87a8.dir
      size: 1069049
      nfiles: 513
    - path: kdd_nsl/models/svc/gzip/0.3/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: kdd_nsl/reports/condense/svc/gzip/0.3
      hash: md5
      md5: af256b9b4fd024ada16a4ee2aa3e7fb7.dir
      size: 540230
      nfiles: 369
  condense@kdd_nsl-svc-0.2-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.2 ++model.init.distance_matrix=kdd_nsl/models/svc/gzip/0.2/distance_matrix.npz
      files.directory=kdd_nsl files.reports=reports/condense/svc/gzip/0.2/ hydra.sweeper.study_name=condense_svc_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/svc/gzip/0.2/
      hydra.callbacks.study_dump.output_file=kdd_nsl/svc/gzip/0.2/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/svc/gzip/0.2
      hash: md5
      md5: eeb29c5f493140c5dcbeb3a09d410a63.dir
      size: 1068901
      nfiles: 513
    - path: kdd_nsl/models/svc/gzip/0.2/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: kdd_nsl/reports/condense/svc/gzip/0.2
      hash: md5
      md5: 6f398349d82d137d7eea913de81ae99e.dir
      size: 544545
      nfiles: 372
  condense@kdd_nsl-svc-0.1-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.1 ++model.init.distance_matrix=kdd_nsl/models/svc/gzip/0.1/distance_matrix.npz
      files.directory=kdd_nsl files.reports=reports/condense/svc/gzip/0.1/ hydra.sweeper.study_name=condense_svc_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/svc/gzip/0.1/
      hydra.callbacks.study_dump.output_file=kdd_nsl/svc/gzip/0.1/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/svc/gzip/0.1
      hash: md5
      md5: 05fa3d25b648ad09705a8e20d2a8862d.dir
      size: 1068934
      nfiles: 513
    - path: kdd_nsl/models/svc/gzip/0.1/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: kdd_nsl/reports/condense/svc/gzip/0.1
      hash: md5
      md5: e22984cec95152f1c4ec0f8a9c963977.dir
      size: 527402
      nfiles: 359
  condense@kdd_nsl-logistic-1-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=1000 data.sample.test_size=400 model_name=logistic model=gzip_logistic
      ++model.init.m=1 files.directory=kdd_nsl hydra.sweeper.study_name=gzip_logistic_kdd_nsl
      files.reports=reports/condense/logistic/gzip/1/ hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8
      hydra.sweep.dir=kdd_nsl/logs/condense/logistic/gzip/1/ hydra.callbacks.study_dump.output_file=kdd_nsl/logistic/gzip/1/study.csv
      hydra.launcher.n_jobs=-1 --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: a0b4f1732c5500eb098e9270777ea5e4
      size: 2094
    - path: kdd_nsl/models/logistic/gzip/
      hash: md5
      md5: d93ab8648b2f96e88e16dda51eb2c099.dir
      size: 3411312
      nfiles: 2
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/logistic/gzip/1
      hash: md5
      md5: c15fabbc3871f2229c76a3863024e7a8.dir
      size: 1051251
      nfiles: 513
  condense@kdd_nsl-logistic-0.9-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=1000 data.sample.test_size=400 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.9 ++model.init.distance_matrix=null files.directory=kdd_nsl
      files.reports=reports/condense/logistic/gzip/0.9/ hydra.sweeper.study_name=condense_logistic_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/logistic/gzip/0.9/
      hydra.callbacks.study_dump.output_file=kdd_nsl/logistic/gzip/0.9/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: b1c796f85633c91291f46f07084dc601
      size: 2216
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/logistic/gzip/0.9
      hash: md5
      md5: 0f1c56de5f4101b1658fa703007fb033.dir
      size: 1091514
      nfiles: 513
  condense@kdd_nsl-logistic-0.8-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.8 
      ++model.init.distance_matrix=kdd_nsl/models/logistic/gzip/0.8/distance_matrix.npz
      files.directory=kdd_nsl files.reports=reports/condense/logistic/gzip/0.8/ hydra.sweeper.study_name=condense_logistic_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/logistic/gzip/0.8/
      hydra.callbacks.study_dump.output_file=kdd_nsl/logistic/gzip/0.8/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: b52399ed877cfdd5fea482ac5ec149dc
      size: 2186
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/logistic/gzip/0.8
      hash: md5
      md5: 8ee346a10e6eb57ef9c3b35c0da650a3.dir
      size: 1119067
      nfiles: 513
    - path: kdd_nsl/models/logistic/gzip/0.8/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
  condense@kdd_nsl-logistic-0.7-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.7 
      ++model.init.distance_matrix=kdd_nsl/models/logistic/gzip/0.7/distance_matrix.npz
      files.directory=kdd_nsl files.reports=reports/condense/logistic/gzip/0.7/ hydra.sweeper.study_name=condense_logistic_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/logistic/gzip/0.7/
      hydra.callbacks.study_dump.output_file=kdd_nsl/logistic/gzip/0.7/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: 660bbad8794269b39527b0928f154910
      size: 2194
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/logistic/gzip/0.7
      hash: md5
      md5: e667885dbb78a9136c5f1d5d48a8ac44.dir
      size: 1114682
      nfiles: 513
    - path: kdd_nsl/models/logistic/gzip/0.7/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: kdd_nsl/reports/condense/logistic/gzip/0.7
      hash: md5
      md5: 6a2e0236ffa2c2f9c45cb0871a07ff21.dir
      size: 497560
      nfiles: 308
  condense@kdd_nsl-logistic-0.6-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.6 
      ++model.init.distance_matrix=kdd_nsl/models/logistic/gzip/0.6/distance_matrix.npz
      files.directory=kdd_nsl files.reports=reports/condense/logistic/gzip/0.6/ hydra.sweeper.study_name=condense_logistic_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/logistic/gzip/0.6/
      hydra.callbacks.study_dump.output_file=kdd_nsl/logistic/gzip/0.6/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: 660bbad8794269b39527b0928f154910
      size: 2194
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/logistic/gzip/0.6
      hash: md5
      md5: c8132879fc978af1ab3f15bc2d821ae3.dir
      size: 1111144
      nfiles: 513
    - path: kdd_nsl/models/logistic/gzip/0.6/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: kdd_nsl/reports/condense/logistic/gzip/0.6
      hash: md5
      md5: f09dd4648c9e388635c48aa038efa12a.dir
      size: 409897
      nfiles: 241
  condense@kdd_nsl-logistic-0.5-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.5 
      ++model.init.distance_matrix=kdd_nsl/models/logistic/gzip/0.5/distance_matrix.npz
      files.directory=kdd_nsl files.reports=reports/condense/logistic/gzip/0.5/ hydra.sweeper.study_name=condense_logistic_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/logistic/gzip/0.5/
      hydra.callbacks.study_dump.output_file=kdd_nsl/logistic/gzip/0.5/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: 660bbad8794269b39527b0928f154910
      size: 2194
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/logistic/gzip/0.5
      hash: md5
      md5: 586aa17ca5b8114d3ab66584c2627fdd.dir
      size: 1111206
      nfiles: 513
    - path: kdd_nsl/models/logistic/gzip/0.5/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: kdd_nsl/reports/condense/logistic/gzip/0.5
      hash: md5
      md5: c9d41b830a9a19dd9cbc93098ca2e1a2.dir
      size: 397367
      nfiles: 223
  condense@kdd_nsl-logistic-0.4-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.4 
      ++model.init.distance_matrix=kdd_nsl/models/logistic/gzip/0.4/distance_matrix.npz
      files.directory=kdd_nsl files.reports=reports/condense/logistic/gzip/0.4/ hydra.sweeper.study_name=condense_logistic_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/logistic/gzip/0.4/
      hydra.callbacks.study_dump.output_file=kdd_nsl/logistic/gzip/0.4/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: 660bbad8794269b39527b0928f154910
      size: 2194
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/logistic/gzip/0.4
      hash: md5
      md5: db97f89163526483ba48699b0e5bb5c1.dir
      size: 1109425
      nfiles: 513
    - path: kdd_nsl/models/logistic/gzip/0.4/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: kdd_nsl/reports/condense/logistic/gzip/0.4
      hash: md5
      md5: 00aa2d810acfac8409300a8996ad4ada.dir
      size: 353123
      nfiles: 197
  condense@kdd_nsl-logistic-0.3-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.3 
      ++model.init.distance_matrix=kdd_nsl/models/logistic/gzip/0.3/distance_matrix.npz
      files.directory=kdd_nsl files.reports=reports/condense/logistic/gzip/0.3/ hydra.sweeper.study_name=condense_logistic_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/logistic/gzip/0.3/
      hydra.callbacks.study_dump.output_file=kdd_nsl/logistic/gzip/0.3/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: 660bbad8794269b39527b0928f154910
      size: 2194
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/logistic/gzip/0.3
      hash: md5
      md5: 4899beff8964db81b230aafaa497c372.dir
      size: 1109271
      nfiles: 513
    - path: kdd_nsl/models/logistic/gzip/0.3/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: kdd_nsl/reports/condense/logistic/gzip/0.3
      hash: md5
      md5: 7818f0f6142dc06d593f3f1d0d0ef2db.dir
      size: 367299
      nfiles: 193
  condense@kdd_nsl-logistic-0.2-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.2 
      ++model.init.distance_matrix=kdd_nsl/models/logistic/gzip/0.2/distance_matrix.npz
      files.directory=kdd_nsl files.reports=reports/condense/logistic/gzip/0.2/ hydra.sweeper.study_name=condense_logistic_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/logistic/gzip/0.2/
      hydra.callbacks.study_dump.output_file=kdd_nsl/logistic/gzip/0.2/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: 660bbad8794269b39527b0928f154910
      size: 2194
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/logistic/gzip/0.2
      hash: md5
      md5: 0a53a70d2d2a0a10edf221aad4bfc653.dir
      size: 1108172
      nfiles: 513
    - path: kdd_nsl/models/logistic/gzip/0.2/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: kdd_nsl/reports/condense/logistic/gzip/0.2
      hash: md5
      md5: 13211fe5dcf72ffa8d9dbdaf4839b383.dir
      size: 379139
      nfiles: 191
  condense@kdd_nsl-logistic-0.1-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.1 
      ++model.init.distance_matrix=kdd_nsl/models/logistic/gzip/0.1/distance_matrix.npz
      files.directory=kdd_nsl files.reports=reports/condense/logistic/gzip/0.1/ hydra.sweeper.study_name=condense_logistic_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/logistic/gzip/0.1/
      hydra.callbacks.study_dump.output_file=kdd_nsl/logistic/gzip/0.1/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: 660bbad8794269b39527b0928f154910
      size: 2194
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/logistic/gzip/0.1
      hash: md5
      md5: 0915467a23680ad03d0ab53580930a78.dir
      size: 1107709
      nfiles: 513
    - path: kdd_nsl/models/logistic/gzip/0.1/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: kdd_nsl/reports/condense/logistic/gzip/0.1
      hash: md5
      md5: cb3ae2afd8e9d61fa27a3f87e9492e4c.dir
      size: 369008
      nfiles: 184
  condense@truthseeker-knn-1-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=1000 data.sample.test_size=400 model_name=knn model=gzip_knn
      ++model.init.m=1 files.directory=truthseeker hydra.sweeper.study_name=gzip_knn_truthseeker
      files.reports=reports/condense/knn/gzip/1/ hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8
      hydra.sweep.dir=truthseeker/logs/condense/knn/gzip/1/ hydra.callbacks.study_dump.output_file=truthseeker/knn/gzip/1/study.csv
      hydra.launcher.n_jobs=-1 --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 18662f67a2a6744e2079f98759ca96b6
      size: 1933
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    - path: truthseeker/models/knn/gzip/
      hash: md5
      md5: c74582055a014f2771217cb66e85c573.dir
      size: 2444563
      nfiles: 2
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/knn/gzip/1
      hash: md5
      md5: fdeb2a67416882a55844389340c57ee8.dir
      size: 981748
      nfiles: 513
  condense@truthseeker-knn-0.9-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=1000 data.sample.test_size=400 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.9 ++model.init.distance_matrix=null files.directory=truthseeker
      files.reports=reports/condense/knn/gzip/0.9/ hydra.sweeper.study_name=condense_knn_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/knn/gzip/0.9/
      hydra.callbacks.study_dump.output_file=truthseeker/knn/gzip/0.9/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 656748d0afcf960f44886e5272318833
      size: 2056
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/knn/gzip/0.9
      hash: md5
      md5: be04d4bb2accdb81cb81ae4a264e6a97.dir
      size: 1009969
      nfiles: 513
  condense@truthseeker-knn-0.8-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.8 ++model.init.distance_matrix=truthseeker/models/knn/gzip/0.8/distance_matrix.npz
      files.directory=truthseeker files.reports=reports/condense/knn/gzip/0.8/ hydra.sweeper.study_name=condense_knn_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/knn/gzip/0.8/
      hydra.callbacks.study_dump.output_file=truthseeker/knn/gzip/0.8/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/knn/gzip/0.8
      hash: md5
      md5: 1d57bb9f78bc1c1cb374ac15dd424a0d.dir
      size: 1050609
      nfiles: 513
    - path: truthseeker/models/knn/gzip/0.8/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: truthseeker/reports/condense/knn/gzip/0.8
      hash: md5
      md5: c97218c4e10e4acb23a898e84add7d40.dir
      size: 132245
      nfiles: 146
  condense@truthseeker-knn-0.7-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.7 ++model.init.distance_matrix=truthseeker/models/knn/gzip/0.7/distance_matrix.npz
      files.directory=truthseeker files.reports=reports/condense/knn/gzip/0.7/ hydra.sweeper.study_name=condense_knn_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/knn/gzip/0.7/
      hydra.callbacks.study_dump.output_file=truthseeker/knn/gzip/0.7/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/knn/gzip/0.7
      hash: md5
      md5: 331b2ee2c6b46f7e1c580d8dfc7b4219.dir
      size: 1045371
      nfiles: 513
    - path: truthseeker/models/knn/gzip/0.7/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: truthseeker/reports/condense/knn/gzip/0.7
      hash: md5
      md5: 35382f03ee875c84d4b3cc9c1c2ebcd5.dir
      size: 105169
      nfiles: 116
  condense@truthseeker-knn-0.6-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.6 ++model.init.distance_matrix=truthseeker/models/knn/gzip/0.6/distance_matrix.npz
      files.directory=truthseeker files.reports=reports/condense/knn/gzip/0.6/ hydra.sweeper.study_name=condense_knn_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/knn/gzip/0.6/
      hydra.callbacks.study_dump.output_file=truthseeker/knn/gzip/0.6/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/knn/gzip/0.6
      hash: md5
      md5: cae1db2e819ed2d036d2235a3e0300c1.dir
      size: 1053181
      nfiles: 513
    - path: truthseeker/models/knn/gzip/0.6/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: truthseeker/reports/condense/knn/gzip/0.6
      hash: md5
      md5: fe4348aa3970a84beab6618e5c9d7ba1.dir
      size: 257373
      nfiles: 285
  condense@truthseeker-knn-0.5-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.5 ++model.init.distance_matrix=truthseeker/models/knn/gzip/0.5/distance_matrix.npz
      files.directory=truthseeker files.reports=reports/condense/knn/gzip/0.5/ hydra.sweeper.study_name=condense_knn_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/knn/gzip/0.5/
      hydra.callbacks.study_dump.output_file=truthseeker/knn/gzip/0.5/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/knn/gzip/0.5
      hash: md5
      md5: 2f438755148379b5e44ef19aa9deb213.dir
      size: 1053093
      nfiles: 513
    - path: truthseeker/models/knn/gzip/0.5/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: truthseeker/reports/condense/knn/gzip/0.5
      hash: md5
      md5: 626572dbf9e8465fe36e721f68f50ede.dir
      size: 306119
      nfiles: 339
  condense@truthseeker-knn-0.4-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.4 ++model.init.distance_matrix=truthseeker/models/knn/gzip/0.4/distance_matrix.npz
      files.directory=truthseeker files.reports=reports/condense/knn/gzip/0.4/ hydra.sweeper.study_name=condense_knn_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/knn/gzip/0.4/
      hydra.callbacks.study_dump.output_file=truthseeker/knn/gzip/0.4/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/knn/gzip/0.4
      hash: md5
      md5: a785fcf13243bd44c29173b875b35ae7.dir
      size: 1053027
      nfiles: 513
    - path: truthseeker/models/knn/gzip/0.4/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: truthseeker/reports/condense/knn/gzip/0.4
      hash: md5
      md5: 9ebab6fdfc63fbf4bdaadbac6e533e04.dir
      size: 295292
      nfiles: 327
  condense@truthseeker-knn-0.3-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.3 ++model.init.distance_matrix=truthseeker/models/knn/gzip/0.3/distance_matrix.npz
      files.directory=truthseeker files.reports=reports/condense/knn/gzip/0.3/ hydra.sweeper.study_name=condense_knn_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/knn/gzip/0.3/
      hydra.callbacks.study_dump.output_file=truthseeker/knn/gzip/0.3/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/knn/gzip/0.3
      hash: md5
      md5: 6ebd324e85fd1d6e7c40f92d1e1f401d.dir
      size: 1052893
      nfiles: 513
    - path: truthseeker/models/knn/gzip/0.3/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: truthseeker/reports/condense/knn/gzip/0.3
      hash: md5
      md5: 20c634e86b5411c9d000175473eded5a.dir
      size: 289873
      nfiles: 321
  condense@truthseeker-knn-0.2-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.2 ++model.init.distance_matrix=truthseeker/models/knn/gzip/0.2/distance_matrix.npz
      files.directory=truthseeker files.reports=reports/condense/knn/gzip/0.2/ hydra.sweeper.study_name=condense_knn_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/knn/gzip/0.2/
      hydra.callbacks.study_dump.output_file=truthseeker/knn/gzip/0.2/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/knn/gzip/0.2
      hash: md5
      md5: 6910a8c19d60dc52ce2f5495ca663ea3.dir
      size: 1053146
      nfiles: 513
    - path: truthseeker/models/knn/gzip/0.2/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: truthseeker/reports/condense/knn/gzip/0.2
      hash: md5
      md5: 2c029dd0a7fcc2abb78935ad18b01b16.dir
      size: 279065
      nfiles: 309
  condense@truthseeker-knn-0.1-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.1 ++model.init.distance_matrix=truthseeker/models/knn/gzip/0.1/distance_matrix.npz
      files.directory=truthseeker files.reports=reports/condense/knn/gzip/0.1/ hydra.sweeper.study_name=condense_knn_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/knn/gzip/0.1/
      hydra.callbacks.study_dump.output_file=truthseeker/knn/gzip/0.1/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/knn/gzip/0.1
      hash: md5
      md5: 5bfb1b56a9686f08408627eb7a54b4b7.dir
      size: 1052831
      nfiles: 513
    - path: truthseeker/models/knn/gzip/0.1/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: truthseeker/reports/condense/knn/gzip/0.1
      hash: md5
      md5: fa6d24ec9aa33f3a0a5ff04a06a3debb.dir
      size: 258037
      nfiles: 260
  condense@truthseeker-svc-1-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=1 ++model.init.distance_matrix=truthseeker/models/svc/gzip/1/distance_matrix.npz
      files.directory=truthseeker files.reports=reports/condense/svc/gzip/1/ hydra.sweeper.study_name=condense_svc_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/svc/gzip/1/
      hydra.callbacks.study_dump.output_file=truthseeker/svc/gzip/1/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/svc/gzip/1
      hash: md5
      md5: e8cb8039bf97cff02e3278116aef9fa6.dir
      size: 1064350
      nfiles: 513
    - path: truthseeker/models/svc/gzip/1/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: truthseeker/reports/condense/svc/gzip/1
      hash: md5
      md5: cf4855a6860ae977c4c6ce735f8d7914.dir
      size: 308272
      nfiles: 162
  condense@truthseeker-svc-0.9-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.9 ++model.init.distance_matrix=truthseeker/models/svc/gzip/0.9/distance_matrix.npz
      files.directory=truthseeker files.reports=reports/condense/svc/gzip/0.9/ hydra.sweeper.study_name=condense_svc_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/svc/gzip/0.9/
      hydra.callbacks.study_dump.output_file=truthseeker/svc/gzip/0.9/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/svc/gzip/0.9
      hash: md5
      md5: 7b3d3c23cf343f692bd6a1605d0f67a1.dir
      size: 1065745
      nfiles: 513
    - path: truthseeker/models/svc/gzip/0.9/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: truthseeker/reports/condense/svc/gzip/0.9
      hash: md5
      md5: 5c2bfb483d1d32d62849ee05a5b4ba44.dir
      size: 66017
      nfiles: 46
  condense@truthseeker-svc-0.8-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.8 ++model.init.distance_matrix=truthseeker/models/svc/gzip/0.8/distance_matrix.npz
      files.directory=truthseeker files.reports=reports/condense/svc/gzip/0.8/ hydra.sweeper.study_name=condense_svc_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/svc/gzip/0.8/
      hydra.callbacks.study_dump.output_file=truthseeker/svc/gzip/0.8/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/svc/gzip/0.8
      hash: md5
      md5: 54b8adf96ea79930a3e1a0580fb68240.dir
      size: 1079522
      nfiles: 513
    - path: truthseeker/models/svc/gzip/0.8/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: truthseeker/reports/condense/svc/gzip/0.8
      hash: md5
      md5: 881618cc39200f7bbbdac0a8c546d401.dir
      size: 317711
      nfiles: 220
  condense@truthseeker-svc-0.7-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=1000 data.sample.test_size=1000 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.7 ++model.init.distance_matrix=null files.directory=truthseeker
      files.reports=reports/condense/svc/gzip/0.7/ hydra.sweeper.study_name=condense_svc_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/svc/gzip/0.7/
      hydra.callbacks.study_dump.output_file=truthseeker/svc/gzip/0.7/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 1e917cc2f9a6f70ad4fe49483edbd0e6
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/svc/gzip/0.7
      hash: md5
      md5: ff2e4f788bb5e9d45ba6e5d14e22a4dd.dir
      size: 1060981
      nfiles: 513
  condense@truthseeker-svc-0.6-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.6 ++model.init.distance_matrix=truthseeker/models/svc/gzip/0.6/distance_matrix.npz
      files.directory=truthseeker files.reports=reports/condense/svc/gzip/0.6/ hydra.sweeper.study_name=condense_svc_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/svc/gzip/0.6/
      hydra.callbacks.study_dump.output_file=truthseeker/svc/gzip/0.6/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/svc/gzip/0.6
      hash: md5
      md5: 81ba9190c1157494765269e1c3f8b098.dir
      size: 1074060
      nfiles: 513
    - path: truthseeker/models/svc/gzip/0.6/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: truthseeker/reports/condense/svc/gzip/0.6
      hash: md5
      md5: 83862678b4e897c4a0f8e57b2a91c19f.dir
      size: 231812
      nfiles: 161
  condense@truthseeker-svc-0.5-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.5 ++model.init.distance_matrix=truthseeker/models/svc/gzip/0.5/distance_matrix.npz
      files.directory=truthseeker files.reports=reports/condense/svc/gzip/0.5/ hydra.sweeper.study_name=condense_svc_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/svc/gzip/0.5/
      hydra.callbacks.study_dump.output_file=truthseeker/svc/gzip/0.5/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/svc/gzip/0.5
      hash: md5
      md5: 536168d2c82d9dded09dd46d52cc3fe4.dir
      size: 1068349
      nfiles: 513
    - path: truthseeker/models/svc/gzip/0.5/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: truthseeker/reports/condense/svc/gzip/0.5
      hash: md5
      md5: fb0179808c75a1fe1184755cd50b650a.dir
      size: 74646
      nfiles: 52
  condense@truthseeker-svc-0.4-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.4 ++model.init.distance_matrix=truthseeker/models/svc/gzip/0.4/distance_matrix.npz
      files.directory=truthseeker files.reports=reports/condense/svc/gzip/0.4/ hydra.sweeper.study_name=condense_svc_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/svc/gzip/0.4/
      hydra.callbacks.study_dump.output_file=truthseeker/svc/gzip/0.4/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/svc/gzip/0.4
      hash: md5
      md5: 262b4ee9efe951a60df0dc5d08e806d0.dir
      size: 1078722
      nfiles: 513
    - path: truthseeker/models/svc/gzip/0.4/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: truthseeker/reports/condense/svc/gzip/0.4
      hash: md5
      md5: 998647f75362f9865a6d875c24bdc55b.dir
      size: 303350
      nfiles: 210
  condense@truthseeker-svc-0.3-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.3 ++model.init.distance_matrix=truthseeker/models/svc/gzip/0.3/distance_matrix.npz
      files.directory=truthseeker files.reports=reports/condense/svc/gzip/0.3/ hydra.sweeper.study_name=condense_svc_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/svc/gzip/0.3/
      hydra.callbacks.study_dump.output_file=truthseeker/svc/gzip/0.3/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/svc/gzip/0.3
      hash: md5
      md5: bd718f8e33c4139b30732605bcfcd6ec.dir
      size: 1076771
      nfiles: 513
    - path: truthseeker/models/svc/gzip/0.3/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: truthseeker/reports/condense/svc/gzip/0.3
      hash: md5
      md5: 3460b5b6c00d8fe7c720170e4fbaa66e.dir
      size: 284007
      nfiles: 197
  condense@truthseeker-svc-0.2-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.2 ++model.init.distance_matrix=truthseeker/models/svc/gzip/0.2/distance_matrix.npz
      files.directory=truthseeker files.reports=reports/condense/svc/gzip/0.2/ hydra.sweeper.study_name=condense_svc_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/svc/gzip/0.2/
      hydra.callbacks.study_dump.output_file=truthseeker/svc/gzip/0.2/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/svc/gzip/0.2
      hash: md5
      md5: ee929bec9ab2be8143b2240f1dac84f4.dir
      size: 1076272
      nfiles: 513
    - path: truthseeker/models/svc/gzip/0.2/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: truthseeker/reports/condense/svc/gzip/0.2
      hash: md5
      md5: 04a62f94b12c1968200c2f5f87a2dbde.dir
      size: 273959
      nfiles: 190
  condense@truthseeker-svc-0.1-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.1 ++model.init.distance_matrix=truthseeker/models/svc/gzip/0.1/distance_matrix.npz
      files.directory=truthseeker files.reports=reports/condense/svc/gzip/0.1/ hydra.sweeper.study_name=condense_svc_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/svc/gzip/0.1/
      hydra.callbacks.study_dump.output_file=truthseeker/svc/gzip/0.1/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/svc/gzip/0.1
      hash: md5
      md5: 04ecd87e712cd10de8c7f511ba5d13fb.dir
      size: 1075111
      nfiles: 513
    - path: truthseeker/models/svc/gzip/0.1/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: truthseeker/reports/condense/svc/gzip/0.1
      hash: md5
      md5: 7e863e090f4c563cdcb0ae8a7c95ef30.dir
      size: 455986
      nfiles: 311
  condense@truthseeker-logistic-1-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=1000 data.sample.test_size=400 model_name=logistic model=gzip_logistic
      ++model.init.m=1 files.directory=truthseeker hydra.sweeper.study_name=gzip_logistic_truthseeker
      files.reports=reports/condense/logistic/gzip/1/ hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8
      hydra.sweep.dir=truthseeker/logs/condense/logistic/gzip/1/ hydra.callbacks.study_dump.output_file=truthseeker/logistic/gzip/1/study.csv
      hydra.launcher.n_jobs=-1 --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: a0b4f1732c5500eb098e9270777ea5e4
      size: 2094
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    - path: truthseeker/models/logistic/gzip/
      hash: md5
      md5: 64703d8c4d9693322003dfad42563381.dir
      size: 4873136
      nfiles: 2
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/logistic/gzip/1
      hash: md5
      md5: 505e8565a5d6cf2f4787b865cce087ab.dir
      size: 1063971
      nfiles: 513
  condense@truthseeker-logistic-0.9-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.9 
      ++model.init.distance_matrix=truthseeker/models/logistic/gzip/0.9/distance_matrix.npz
      files.directory=truthseeker files.reports=reports/condense/logistic/gzip/0.9/
      hydra.sweeper.study_name=condense_logistic_truthseeker hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/logistic/gzip/0.9/
      hydra.callbacks.study_dump.output_file=truthseeker/logistic/gzip/0.9/study.csv
      hydra.launcher.n_jobs=-1 --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: 660bbad8794269b39527b0928f154910
      size: 2194
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/logistic/gzip/0.9
      hash: md5
      md5: ee346f0b970c53e940b66e085a2e693b.dir
      size: 1123150
      nfiles: 513
    - path: truthseeker/models/logistic/gzip/0.9/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: truthseeker/reports/condense/logistic/gzip/0.9
      hash: md5
      md5: 2b0271f416cac851c343a59b6a898262.dir
      size: 364152
      nfiles: 205
  condense@truthseeker-logistic-0.8-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.8 
      ++model.init.distance_matrix=truthseeker/models/logistic/gzip/0.8/distance_matrix.npz
      files.directory=truthseeker files.reports=reports/condense/logistic/gzip/0.8/
      hydra.sweeper.study_name=condense_logistic_truthseeker hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/logistic/gzip/0.8/
      hydra.callbacks.study_dump.output_file=truthseeker/logistic/gzip/0.8/study.csv
      hydra.launcher.n_jobs=-1 --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: 660bbad8794269b39527b0928f154910
      size: 2194
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/logistic/gzip/0.8
      hash: md5
      md5: d3649f7e97a1a759a9e03403b9e6fccd.dir
      size: 1121126
      nfiles: 513
    - path: truthseeker/models/logistic/gzip/0.8/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: truthseeker/reports/condense/logistic/gzip/0.8
      hash: md5
      md5: 91e65e45815d5994f270cfe53f64f72e.dir
      size: 399901
      nfiles: 235
  condense@truthseeker-logistic-0.7-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.7 
      ++model.init.distance_matrix=truthseeker/models/logistic/gzip/0.7/distance_matrix.npz
      files.directory=truthseeker files.reports=reports/condense/logistic/gzip/0.7/
      hydra.sweeper.study_name=condense_logistic_truthseeker hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/logistic/gzip/0.7/
      hydra.callbacks.study_dump.output_file=truthseeker/logistic/gzip/0.7/study.csv
      hydra.launcher.n_jobs=-1 --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: 660bbad8794269b39527b0928f154910
      size: 2194
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/logistic/gzip/0.7
      hash: md5
      md5: a850850fd9c0041c951f7d64e890b1ac.dir
      size: 1120965
      nfiles: 513
    - path: truthseeker/models/logistic/gzip/0.7/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: truthseeker/reports/condense/logistic/gzip/0.7
      hash: md5
      md5: 01393f3b30881adf38b7dde2895f0657.dir
      size: 378242
      nfiles: 214
  condense@truthseeker-logistic-0.6-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.6 
      ++model.init.distance_matrix=truthseeker/models/logistic/gzip/0.6/distance_matrix.npz
      files.directory=truthseeker files.reports=reports/condense/logistic/gzip/0.6/
      hydra.sweeper.study_name=condense_logistic_truthseeker hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/logistic/gzip/0.6/
      hydra.callbacks.study_dump.output_file=truthseeker/logistic/gzip/0.6/study.csv
      hydra.launcher.n_jobs=-1 --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: 660bbad8794269b39527b0928f154910
      size: 2194
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/logistic/gzip/0.6
      hash: md5
      md5: 445e24fec9bce665cde830901e66bb4a.dir
      size: 1118400
      nfiles: 513
    - path: truthseeker/models/logistic/gzip/0.6/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: truthseeker/reports/condense/logistic/gzip/0.6
      hash: md5
      md5: 6614f326a1fd8a8c3715138009149f4d.dir
      size: 487314
      nfiles: 280
  condense@truthseeker-logistic-0.5-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.5 
      ++model.init.distance_matrix=truthseeker/models/logistic/gzip/0.5/distance_matrix.npz
      files.directory=truthseeker files.reports=reports/condense/logistic/gzip/0.5/
      hydra.sweeper.study_name=condense_logistic_truthseeker hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/logistic/gzip/0.5/
      hydra.callbacks.study_dump.output_file=truthseeker/logistic/gzip/0.5/study.csv
      hydra.launcher.n_jobs=-1 --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: 660bbad8794269b39527b0928f154910
      size: 2194
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/logistic/gzip/0.5
      hash: md5
      md5: 704ef6870b6643be283134fe75f5d766.dir
      size: 1116700
      nfiles: 513
    - path: truthseeker/models/logistic/gzip/0.5/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: truthseeker/reports/condense/logistic/gzip/0.5
      hash: md5
      md5: 6146c4ce423441229150e9d12b683178.dir
      size: 462270
      nfiles: 249
  condense@truthseeker-logistic-0.4-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.4 
      ++model.init.distance_matrix=truthseeker/models/logistic/gzip/0.4/distance_matrix.npz
      files.directory=truthseeker files.reports=reports/condense/logistic/gzip/0.4/
      hydra.sweeper.study_name=condense_logistic_truthseeker hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/logistic/gzip/0.4/
      hydra.callbacks.study_dump.output_file=truthseeker/logistic/gzip/0.4/study.csv
      hydra.launcher.n_jobs=-1 --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: 660bbad8794269b39527b0928f154910
      size: 2194
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/logistic/gzip/0.4
      hash: md5
      md5: 230f0cb8c0fe5564aa39a7b13eb20038.dir
      size: 1114883
      nfiles: 513
    - path: truthseeker/models/logistic/gzip/0.4/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: truthseeker/reports/condense/logistic/gzip/0.4
      hash: md5
      md5: 2e52eb22a27035c41220323ff5e5aebd.dir
      size: 441742
      nfiles: 223
  condense@truthseeker-logistic-0.3-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.3 
      ++model.init.distance_matrix=truthseeker/models/logistic/gzip/0.3/distance_matrix.npz
      files.directory=truthseeker files.reports=reports/condense/logistic/gzip/0.3/
      hydra.sweeper.study_name=condense_logistic_truthseeker hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/logistic/gzip/0.3/
      hydra.callbacks.study_dump.output_file=truthseeker/logistic/gzip/0.3/study.csv
      hydra.launcher.n_jobs=-1 --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: 660bbad8794269b39527b0928f154910
      size: 2194
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/logistic/gzip/0.3
      hash: md5
      md5: 773c701da35450478843e2f20416f4e8.dir
      size: 1113091
      nfiles: 513
    - path: truthseeker/models/logistic/gzip/0.3/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: truthseeker/reports/condense/logistic/gzip/0.3
      hash: md5
      md5: 694b2dbf1233820f977d828927c539d8.dir
      size: 402173
      nfiles: 192
  condense@truthseeker-logistic-0.2-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.2 
      ++model.init.distance_matrix=truthseeker/models/logistic/gzip/0.2/distance_matrix.npz
      files.directory=truthseeker files.reports=reports/condense/logistic/gzip/0.2/
      hydra.sweeper.study_name=condense_logistic_truthseeker hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/logistic/gzip/0.2/
      hydra.callbacks.study_dump.output_file=truthseeker/logistic/gzip/0.2/study.csv
      hydra.launcher.n_jobs=-1 --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: 660bbad8794269b39527b0928f154910
      size: 2194
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/logistic/gzip/0.2
      hash: md5
      md5: 19ad2fb5415ae78bf463f1ba29d01aba.dir
      size: 1113056
      nfiles: 513
    - path: truthseeker/models/logistic/gzip/0.2/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: truthseeker/reports/condense/logistic/gzip/0.2
      hash: md5
      md5: a482e7a26702836d233b2baeb1a40344.dir
      size: 400680
      nfiles: 189
  condense@truthseeker-logistic-0.1-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.1 
      ++model.init.distance_matrix=truthseeker/models/logistic/gzip/0.1/distance_matrix.npz
      files.directory=truthseeker files.reports=reports/condense/logistic/gzip/0.1/
      hydra.sweeper.study_name=condense_logistic_truthseeker hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/logistic/gzip/0.1/
      hydra.callbacks.study_dump.output_file=truthseeker/logistic/gzip/0.1/study.csv
      hydra.launcher.n_jobs=-1 --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: 660bbad8794269b39527b0928f154910
      size: 2194
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/logistic/gzip/0.1
      hash: md5
      md5: c134e884c7b7247c3803a5a5b6aa6e79.dir
      size: 1113215
      nfiles: 513
    - path: truthseeker/models/logistic/gzip/0.1/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: truthseeker/reports/condense/logistic/gzip/0.1
      hash: md5
      md5: b9b13d9981bd45a15bae4a05bc09778e.dir
      size: 390432
      nfiles: 186
  condense@sms_spam-knn-1-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=1000 data.sample.test_size=400 model_name=knn model=gzip_knn
      ++model.init.m=1 files.directory=sms_spam hydra.sweeper.study_name=gzip_knn_sms_spam
      files.reports=reports/condense/knn/gzip/1/ hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8
      hydra.sweep.dir=sms_spam/logs/condense/knn/gzip/1/ hydra.callbacks.study_dump.output_file=sms_spam/knn/gzip/1/study.csv
      hydra.launcher.n_jobs=-1 --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 18662f67a2a6744e2079f98759ca96b6
      size: 1933
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    - path: sms_spam/models/knn/gzip/
      hash: md5
      md5: eb5b0a0848b12d096940808b2a82e4e4.dir
      size: 2367068
      nfiles: 2
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/knn/gzip/1
      hash: md5
      md5: aec18e03ca38d81f1b0ab5053750820f.dir
      size: 973345
      nfiles: 513
  condense@sms_spam-knn-0.9-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=1000 data.sample.test_size=400 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.9 ++model.init.distance_matrix=null files.directory=sms_spam
      files.reports=reports/condense/knn/gzip/0.9/ hydra.sweeper.study_name=condense_knn_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/knn/gzip/0.9/
      hydra.callbacks.study_dump.output_file=sms_spam/knn/gzip/0.9/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 656748d0afcf960f44886e5272318833
      size: 2056
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/knn/gzip/0.9
      hash: md5
      md5: e93fd5fbe5080aba0fcb2cbca18f2a49.dir
      size: 1001136
      nfiles: 513
  condense@sms_spam-knn-0.8-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.8 ++model.init.distance_matrix=sms_spam/models/knn/gzip/0.8/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/knn/gzip/0.8/ hydra.sweeper.study_name=condense_knn_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/knn/gzip/0.8/
      hydra.callbacks.study_dump.output_file=sms_spam/knn/gzip/0.8/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/knn/gzip/0.8
      hash: md5
      md5: 3a774ceba79b7207812cf80fc8fd4cdb.dir
      size: 1043674
      nfiles: 513
    - path: sms_spam/models/knn/gzip/0.8/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/knn/gzip/0.8
      hash: md5
      md5: e30895b7a1645779045ee8f1ae10b3b8.dir
      size: 104415
      nfiles: 117
  condense@sms_spam-knn-0.7-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.7 ++model.init.distance_matrix=sms_spam/models/knn/gzip/0.7/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/knn/gzip/0.7/ hydra.sweeper.study_name=condense_knn_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/knn/gzip/0.7/
      hydra.callbacks.study_dump.output_file=sms_spam/knn/gzip/0.7/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/knn/gzip/0.7
      hash: md5
      md5: e5ec2db0a9d126d2fc60c55a2c3f7be4.dir
      size: 1043245
      nfiles: 513
    - path: sms_spam/models/knn/gzip/0.7/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/knn/gzip/0.7
      hash: md5
      md5: 2112b705829ba8d9346da978fb67ae78.dir
      size: 216795
      nfiles: 243
  condense@sms_spam-knn-0.6-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.6 ++model.init.distance_matrix=sms_spam/models/knn/gzip/0.6/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/knn/gzip/0.6/ hydra.sweeper.study_name=condense_knn_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/knn/gzip/0.6/
      hydra.callbacks.study_dump.output_file=sms_spam/knn/gzip/0.6/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/knn/gzip/0.6
      hash: md5
      md5: 6e9c486f7c64785973618977af839d01.dir
      size: 1042386
      nfiles: 513
    - path: sms_spam/models/knn/gzip/0.6/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/knn/gzip/0.6
      hash: md5
      md5: d5a943d8f41905635e1ce5e91b9ac0ea.dir
      size: 217969
      nfiles: 244
  condense@sms_spam-knn-0.5-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.5 ++model.init.distance_matrix=sms_spam/models/knn/gzip/0.5/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/knn/gzip/0.5/ hydra.sweeper.study_name=condense_knn_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/knn/gzip/0.5/
      hydra.callbacks.study_dump.output_file=sms_spam/knn/gzip/0.5/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/knn/gzip/0.5
      hash: md5
      md5: f785398f999a015ae9147584e6645c9a.dir
      size: 1041996
      nfiles: 513
    - path: sms_spam/models/knn/gzip/0.5/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/knn/gzip/0.5
      hash: md5
      md5: 421642381915d777839e9f04c09b2c20.dir
      size: 128378
      nfiles: 144
  condense@sms_spam-knn-0.4-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.4 ++model.init.distance_matrix=sms_spam/models/knn/gzip/0.4/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/knn/gzip/0.4/ hydra.sweeper.study_name=condense_knn_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/knn/gzip/0.4/
      hydra.callbacks.study_dump.output_file=sms_spam/knn/gzip/0.4/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/knn/gzip/0.4
      hash: md5
      md5: 2b56a4cca8d52d88ce0e9a02f420f193.dir
      size: 1042076
      nfiles: 513
    - path: sms_spam/models/knn/gzip/0.4/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/knn/gzip/0.4
      hash: md5
      md5: ca846956ddd7c06501137dc6c2b57671.dir
      size: 286176
      nfiles: 321
  condense@sms_spam-knn-0.3-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.3 ++model.init.distance_matrix=sms_spam/models/knn/gzip/0.3/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/knn/gzip/0.3/ hydra.sweeper.study_name=condense_knn_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/knn/gzip/0.3/
      hydra.callbacks.study_dump.output_file=sms_spam/knn/gzip/0.3/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/knn/gzip/0.3
      hash: md5
      md5: fc6fa96f7d0a99657dfea370482057a1.dir
      size: 1042280
      nfiles: 513
    - path: sms_spam/models/knn/gzip/0.3/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/knn/gzip/0.3
      hash: md5
      md5: bae5a5103b81f3a1920e54503712ff04.dir
      size: 251420
      nfiles: 282
  condense@sms_spam-knn-0.2-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.2 ++model.init.distance_matrix=sms_spam/models/knn/gzip/0.2/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/knn/gzip/0.2/ hydra.sweeper.study_name=condense_knn_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/knn/gzip/0.2/
      hydra.callbacks.study_dump.output_file=sms_spam/knn/gzip/0.2/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/knn/gzip/0.2
      hash: md5
      md5: 18ed970d9dc3e89e7e39335ad611bb2d.dir
      size: 1042271
      nfiles: 513
    - path: sms_spam/models/knn/gzip/0.2/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/knn/gzip/0.2
      hash: md5
      md5: dd3b83654405a91a4f2f0a7da96f3d19.dir
      size: 250018
      nfiles: 280
  condense@sms_spam-knn-0.1-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.1 ++model.init.distance_matrix=sms_spam/models/knn/gzip/0.1/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/knn/gzip/0.1/ hydra.sweeper.study_name=condense_knn_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/knn/gzip/0.1/
      hydra.callbacks.study_dump.output_file=sms_spam/knn/gzip/0.1/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 9f3052f993ca92192963f53878c8d8ca
      size: 2049
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/knn/gzip/0.1
      hash: md5
      md5: b651815c35e7c4e5dc0f1f2c65e2417d.dir
      size: 1042240
      nfiles: 513
    - path: sms_spam/models/knn/gzip/0.1/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/knn/gzip/0.1
      hash: md5
      md5: 0b2e431bb3044ed3a803f94bfb6b0252.dir
      size: 266948
      nfiles: 268
  condense@sms_spam-svc-1-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=1 ++model.init.distance_matrix=sms_spam/models/svc/gzip/1/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/svc/gzip/1/ hydra.sweeper.study_name=condense_svc_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/svc/gzip/1/
      hydra.callbacks.study_dump.output_file=sms_spam/svc/gzip/1/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/svc/gzip/1
      hash: md5
      md5: 358055a1baf520ec2bf870a6222e5e0c.dir
      size: 1053785
      nfiles: 513
    - path: sms_spam/models/svc/gzip/1/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/svc/gzip/1
      hash: md5
      md5: 7cd4d8ac92768baf38b3444bf018c473.dir
      size: 343507
      nfiles: 185
  condense@sms_spam-svc-0.9-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.9 ++model.init.distance_matrix=sms_spam/models/svc/gzip/0.9/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/svc/gzip/0.9/ hydra.sweeper.study_name=condense_svc_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/svc/gzip/0.9/
      hydra.callbacks.study_dump.output_file=sms_spam/svc/gzip/0.9/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/svc/gzip/0.9
      hash: md5
      md5: 646ede64669d5bc3d99148e2074d216c.dir
      size: 1062958
      nfiles: 513
    - path: sms_spam/models/svc/gzip/0.9/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/svc/gzip/0.9
      hash: md5
      md5: 7b8ba8eeb1166a56793b845dba0b27c6.dir
      size: 225657
      nfiles: 158
  condense@sms_spam-svc-0.8-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.8 ++model.init.distance_matrix=sms_spam/models/svc/gzip/0.8/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/svc/gzip/0.8/ hydra.sweeper.study_name=condense_svc_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/svc/gzip/0.8/
      hydra.callbacks.study_dump.output_file=sms_spam/svc/gzip/0.8/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/svc/gzip/0.8
      hash: md5
      md5: c06ae18dd6b8a92a4751b255948fbeff.dir
      size: 1063300
      nfiles: 513
    - path: sms_spam/models/svc/gzip/0.8/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/svc/gzip/0.8
      hash: md5
      md5: 43f8e780a688f236ce78e52db3ca6430.dir
      size: 222606
      nfiles: 156
  condense@sms_spam-svc-0.7-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.7 ++model.init.distance_matrix=sms_spam/models/svc/gzip/0.7/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/svc/gzip/0.7/ hydra.sweeper.study_name=condense_svc_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/svc/gzip/0.7/
      hydra.callbacks.study_dump.output_file=sms_spam/svc/gzip/0.7/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/svc/gzip/0.7
      hash: md5
      md5: c067fe0bb0194cb7f01afc92faa3eccf.dir
      size: 1082029
      nfiles: 513
    - path: sms_spam/models/svc/gzip/0.7/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/svc/gzip/0.7
      hash: md5
      md5: 63697542b5e7a855d4ecba8efc5794e3.dir
      size: 772886
      nfiles: 540
  condense@sms_spam-svc-0.6-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.6 ++model.init.distance_matrix=sms_spam/models/svc/gzip/0.6/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/svc/gzip/0.6/ hydra.sweeper.study_name=condense_svc_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/svc/gzip/0.6/
      hydra.callbacks.study_dump.output_file=sms_spam/svc/gzip/0.6/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/svc/gzip/0.6
      hash: md5
      md5: c487d8f41cd499673e25644c6223b56a.dir
      size: 1065016
      nfiles: 513
    - path: sms_spam/models/svc/gzip/0.6/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/svc/gzip/0.6
      hash: md5
      md5: e80178d3dbded568e40a1de71c283c5d.dir
      size: 468203
      nfiles: 327
  condense@sms_spam-svc-0.5-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.5 ++model.init.distance_matrix=sms_spam/models/svc/gzip/0.5/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/svc/gzip/0.5/ hydra.sweeper.study_name=condense_svc_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/svc/gzip/0.5/
      hydra.callbacks.study_dump.output_file=sms_spam/svc/gzip/0.5/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/svc/gzip/0.5
      hash: md5
      md5: 1bd06366babf53cee8d022fd9dd8f999.dir
      size: 1065446
      nfiles: 513
    - path: sms_spam/models/svc/gzip/0.5/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/svc/gzip/0.5
      hash: md5
      md5: 4f8d5848e33a9488ae93f1b5bbc8b87f.dir
      size: 485459
      nfiles: 339
  condense@sms_spam-svc-0.4-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.4 ++model.init.distance_matrix=sms_spam/models/svc/gzip/0.4/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/svc/gzip/0.4/ hydra.sweeper.study_name=condense_svc_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/svc/gzip/0.4/
      hydra.callbacks.study_dump.output_file=sms_spam/svc/gzip/0.4/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/svc/gzip/0.4
      hash: md5
      md5: 52b77f30532f6586dd41941a5061bebc.dir
      size: 1065170
      nfiles: 513
    - path: sms_spam/models/svc/gzip/0.4/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/svc/gzip/0.4
      hash: md5
      md5: 74d44a9b4aa521e5014377e4d4b9ba2f.dir
      size: 506917
      nfiles: 354
  condense@sms_spam-svc-0.3-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.3 ++model.init.distance_matrix=sms_spam/models/svc/gzip/0.3/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/svc/gzip/0.3/ hydra.sweeper.study_name=condense_svc_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/svc/gzip/0.3/
      hydra.callbacks.study_dump.output_file=sms_spam/svc/gzip/0.3/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/svc/gzip/0.3
      hash: md5
      md5: 4e801a365573e0a8de189cf552bcc80d.dir
      size: 1065087
      nfiles: 513
    - path: sms_spam/models/svc/gzip/0.3/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/svc/gzip/0.3
      hash: md5
      md5: 0d86f792ca2317e92255fcd05214fe4a.dir
      size: 463981
      nfiles: 324
  condense@sms_spam-svc-0.2-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.2 ++model.init.distance_matrix=sms_spam/models/svc/gzip/0.2/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/svc/gzip/0.2/ hydra.sweeper.study_name=condense_svc_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/svc/gzip/0.2/
      hydra.callbacks.study_dump.output_file=sms_spam/svc/gzip/0.2/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/svc/gzip/0.2
      hash: md5
      md5: 1df252ca68213560b06cad39292e71e2.dir
      size: 1065667
      nfiles: 513
    - path: sms_spam/models/svc/gzip/0.2/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/svc/gzip/0.2
      hash: md5
      md5: 42192911d5038c21be469eed88c9a222.dir
      size: 489872
      nfiles: 342
  condense@sms_spam-svc-0.1-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.1 ++model.init.distance_matrix=sms_spam/models/svc/gzip/0.1/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/svc/gzip/0.1/ hydra.sweeper.study_name=condense_svc_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/svc/gzip/0.1/
      hydra.callbacks.study_dump.output_file=sms_spam/svc/gzip/0.1/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: 6f839f9f140b701e3852fc8231688e4d
      size: 2107
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/svc/gzip/0.1
      hash: md5
      md5: 3b6e0bc651ecf7b9ad0b60690768ec42.dir
      size: 1065027
      nfiles: 513
    - path: sms_spam/models/svc/gzip/0.1/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/svc/gzip/0.1
      hash: md5
      md5: 1d19dee0a3394ac686d421ea86d800e1.dir
      size: 515428
      nfiles: 360
  condense@sms_spam-logistic-1-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=1 ++model.init.distance_matrix=sms_spam/models/logistic/gzip/1/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/logistic/gzip/1/ hydra.sweeper.study_name=condense_logistic_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/logistic/gzip/1/
      hydra.callbacks.study_dump.output_file=sms_spam/logistic/gzip/1/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: 660bbad8794269b39527b0928f154910
      size: 2194
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/logistic/gzip/1
      hash: md5
      md5: 7d46c630a2acf71f9d6a89d7edc5daf9.dir
      size: 1103886
      nfiles: 513
    - path: sms_spam/models/logistic/gzip/1/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/logistic/gzip/1
      hash: md5
      md5: 88eefb5d237d3014e78200e24ea7ada6.dir
      size: 425623
      nfiles: 211
  condense@sms_spam-logistic-0.9-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.9 
      ++model.init.distance_matrix=sms_spam/models/logistic/gzip/0.9/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/logistic/gzip/0.9/ hydra.sweeper.study_name=condense_logistic_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/logistic/gzip/0.9/
      hydra.callbacks.study_dump.output_file=sms_spam/logistic/gzip/0.9/study.csv
      hydra.launcher.n_jobs=-1 --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: 660bbad8794269b39527b0928f154910
      size: 2194
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/logistic/gzip/0.9
      hash: md5
      md5: 61dd1089e3d9f855ee966de65e233db4.dir
      size: 1113586
      nfiles: 513
    - path: sms_spam/models/logistic/gzip/0.9/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/logistic/gzip/0.9
      hash: md5
      md5: 0d1a806b791a9cc3d6a21e4f895fb72c.dir
      size: 351139
      nfiles: 196
  condense@sms_spam-logistic-0.8-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.8 
      ++model.init.distance_matrix=sms_spam/models/logistic/gzip/0.8/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/logistic/gzip/0.8/ hydra.sweeper.study_name=condense_logistic_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/logistic/gzip/0.8/
      hydra.callbacks.study_dump.output_file=sms_spam/logistic/gzip/0.8/study.csv
      hydra.launcher.n_jobs=-1 --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: 660bbad8794269b39527b0928f154910
      size: 2194
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/logistic/gzip/0.8
      hash: md5
      md5: 9320903dc717f3595e027e78f384a66a.dir
      size: 1112400
      nfiles: 513
    - path: sms_spam/models/logistic/gzip/0.8/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/logistic/gzip/0.8
      hash: md5
      md5: daf8c199244f0f022e58d9d80e707533.dir
      size: 638613
      nfiles: 351
  condense@sms_spam-logistic-0.7-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.7 
      ++model.init.distance_matrix=sms_spam/models/logistic/gzip/0.7/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/logistic/gzip/0.7/ hydra.sweeper.study_name=condense_logistic_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/logistic/gzip/0.7/
      hydra.callbacks.study_dump.output_file=sms_spam/logistic/gzip/0.7/study.csv
      hydra.launcher.n_jobs=-1 --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: 660bbad8794269b39527b0928f154910
      size: 2194
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/logistic/gzip/0.7
      hash: md5
      md5: db959c6e65d9047df20afbd79d0d0cf8.dir
      size: 1111064
      nfiles: 513
    - path: sms_spam/models/logistic/gzip/0.7/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/logistic/gzip/0.7
      hash: md5
      md5: 1d1ef91746e2cbb429ee142127398b85.dir
      size: 459905
      nfiles: 274
  condense@sms_spam-logistic-0.6-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.6 
      ++model.init.distance_matrix=sms_spam/models/logistic/gzip/0.6/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/logistic/gzip/0.6/ hydra.sweeper.study_name=condense_logistic_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/logistic/gzip/0.6/
      hydra.callbacks.study_dump.output_file=sms_spam/logistic/gzip/0.6/study.csv
      hydra.launcher.n_jobs=-1 --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: 660bbad8794269b39527b0928f154910
      size: 2194
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/logistic/gzip/0.6
      hash: md5
      md5: c203ce76776eb0610dad49a9715d10fa.dir
      size: 1108164
      nfiles: 513
    - path: sms_spam/models/logistic/gzip/0.6/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/logistic/gzip/0.6
      hash: md5
      md5: a8faee3d75a41a8d20e721dadece810d.dir
      size: 399087
      nfiles: 240
  condense@sms_spam-logistic-0.5-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.5 
      ++model.init.distance_matrix=sms_spam/models/logistic/gzip/0.5/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/logistic/gzip/0.5/ hydra.sweeper.study_name=condense_logistic_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/logistic/gzip/0.5/
      hydra.callbacks.study_dump.output_file=sms_spam/logistic/gzip/0.5/study.csv
      hydra.launcher.n_jobs=-1 --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: 660bbad8794269b39527b0928f154910
      size: 2194
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/logistic/gzip/0.5
      hash: md5
      md5: 90a8e1e36ca2aa431e0655007533e1d4.dir
      size: 1106071
      nfiles: 513
    - path: sms_spam/models/logistic/gzip/0.5/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/logistic/gzip/0.5
      hash: md5
      md5: 02691fd41faab8e4f7130ed420346d92.dir
      size: 330692
      nfiles: 185
  condense@sms_spam-logistic-0.4-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.4 
      ++model.init.distance_matrix=sms_spam/models/logistic/gzip/0.4/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/logistic/gzip/0.4/ hydra.sweeper.study_name=condense_logistic_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/logistic/gzip/0.4/
      hydra.callbacks.study_dump.output_file=sms_spam/logistic/gzip/0.4/study.csv
      hydra.launcher.n_jobs=-1 --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: 660bbad8794269b39527b0928f154910
      size: 2194
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/logistic/gzip/0.4
      hash: md5
      md5: 7ef103878a44a5f7a80dfddb0cdecd36.dir
      size: 1104642
      nfiles: 513
    - path: sms_spam/models/logistic/gzip/0.4/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/logistic/gzip/0.4
      hash: md5
      md5: 7ba01de54c21a0d335dc4452b2a82030.dir
      size: 288566
      nfiles: 156
  condense@sms_spam-logistic-0.3-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.3 
      ++model.init.distance_matrix=sms_spam/models/logistic/gzip/0.3/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/logistic/gzip/0.3/ hydra.sweeper.study_name=condense_logistic_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/logistic/gzip/0.3/
      hydra.callbacks.study_dump.output_file=sms_spam/logistic/gzip/0.3/study.csv
      hydra.launcher.n_jobs=-1 --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: 660bbad8794269b39527b0928f154910
      size: 2194
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/logistic/gzip/0.3
      hash: md5
      md5: 7d087d362a4a52cf4f1952266aa2f73f.dir
      size: 1104375
      nfiles: 513
    - path: sms_spam/models/logistic/gzip/0.3/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/logistic/gzip/0.3
      hash: md5
      md5: b57607f58149bfbaf3251cd2a2522fa5.dir
      size: 276991
      nfiles: 150
  condense@sms_spam-logistic-0.2-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.2 
      ++model.init.distance_matrix=sms_spam/models/logistic/gzip/0.2/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/logistic/gzip/0.2/ hydra.sweeper.study_name=condense_logistic_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/logistic/gzip/0.2/
      hydra.callbacks.study_dump.output_file=sms_spam/logistic/gzip/0.2/study.csv
      hydra.launcher.n_jobs=-1 --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: 660bbad8794269b39527b0928f154910
      size: 2194
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/logistic/gzip/0.2
      hash: md5
      md5: d8a3bf403ac868c0ca06bb170e7dbb44.dir
      size: 1103444
      nfiles: 513
    - path: sms_spam/models/logistic/gzip/0.2/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/logistic/gzip/0.2
      hash: md5
      md5: a71f31e27d7cc269993196ea949c8c4e.dir
      size: 282604
      nfiles: 140
  condense@sms_spam-logistic-0.1-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=100 data.sample.test_size=100 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.1 
      ++model.init.distance_matrix=sms_spam/models/logistic/gzip/0.1/distance_matrix.npz
      files.directory=sms_spam files.reports=reports/condense/logistic/gzip/0.1/ hydra.sweeper.study_name=condense_logistic_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/logistic/gzip/0.1/
      hydra.callbacks.study_dump.output_file=sms_spam/logistic/gzip/0.1/study.csv
      hydra.launcher.n_jobs=-1 --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: 660bbad8794269b39527b0928f154910
      size: 2194
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/logistic/gzip/0.1
      hash: md5
      md5: 068bfb57362d32930adc0a19136bcd77.dir
      size: 1102685
      nfiles: 513
    - path: sms_spam/models/logistic/gzip/0.1/
      hash: md5
      md5: 5c1b82fb27b551ab50abad2b1dac31fa.dir
      size: 306
      nfiles: 1
    - path: sms_spam/reports/condense/logistic/gzip/0.1
      hash: md5
      md5: 7c5ed1bd4430f0be3eb4425ea6bb5475.dir
      size: 262299
      nfiles: 126
  compile@kdd_nsl-gzip_knn:
    cmd: python -m deckard.layers.compile  --report_folder kdd_nsl/reports/gzip_knn  --results_file
      kdd_nsl/reports/gzip_knn.csv
    deps:
    - path: kdd_nsl/reports/gzip_knn/
      hash: md5
      md5: d30aaee43e72d1392e96d1ed64220ab7.dir
      size: 1603607
      nfiles: 1527
    outs:
    - path: kdd_nsl/reports/gzip_knn.csv
      hash: md5
      md5: bd313900a4176a3f52bb687b1ed67685
      size: 712255
  compile@kdd_nsl-gzip_svc:
    cmd: python -m deckard.layers.compile  --report_folder kdd_nsl/reports/gzip_svc  --results_file
      kdd_nsl/reports/gzip_svc.csv
    deps:
    - path: kdd_nsl/reports/gzip_svc/
      hash: md5
      md5: 9b688eaec16d8fb94d8fb7c80c79313a.dir
      size: 4442105
      nfiles: 3072
    outs:
    - path: kdd_nsl/reports/gzip_svc.csv
      hash: md5
      md5: 8cce447ffd02091345d09ae6950e3c10
      size: 1423691
  compile@kdd_nsl-gzip_logistic:
    cmd: python -m deckard.layers.compile  --report_folder kdd_nsl/reports/gzip_logistic  --results_file
      kdd_nsl/reports/gzip_logistic.csv
    deps:
    - path: kdd_nsl/reports/gzip_logistic/
      hash: md5
      md5: 5fac082eca0a191aab92706220080062.dir
      size: 5243991
      nfiles: 2536
    outs:
    - path: kdd_nsl/reports/gzip_logistic.csv
      hash: md5
      md5: 48b20e1f0c5bc8ed8a997f477e863f4a
      size: 1322010
  compile@kdd_nsl-condense/knn:
    cmd: python -m deckard.layers.compile  --report_folder kdd_nsl/reports/condense/knn  --results_file
      kdd_nsl/reports/condense/knn.csv
    deps:
    - path: kdd_nsl/reports/condense/knn/
      hash: md5
      md5: b9f3f619e141e631b9311545e3781cfd.dir
      size: 2481713
      nfiles: 2562
    outs:
    - path: kdd_nsl/reports/condense/knn.csv
      hash: md5
      md5: 7f02784208bceeff1eae81b1b9d18e83
      size: 1230527
  compile@kdd_nsl-condense/svc:
    cmd: python -m deckard.layers.compile  --report_folder kdd_nsl/reports/condense/svc  --results_file
      kdd_nsl/reports/condense/svc.csv
    deps:
    - path: kdd_nsl/reports/condense/svc/
      hash: md5
      md5: 89b4e64ad675852f850ca2fd2da3e004.dir
      size: 4676557
      nfiles: 3120
    outs:
    - path: kdd_nsl/reports/condense/svc.csv
      hash: md5
      md5: fd4d2f89ec51b5b68589164bf0bf98a8
      size: 1495270
  compile@kdd_nsl-condense/logistic:
    cmd: python -m deckard.layers.compile  --report_folder kdd_nsl/reports/condense/logistic  --results_file
      kdd_nsl/reports/condense/logistic.csv
    deps:
    - path: kdd_nsl/reports/condense/logistic/
      hash: md5
      md5: 068dae4ba00d3aac13a6042293c5e52a.dir
      size: 3891031
      nfiles: 2223
    outs:
    - path: kdd_nsl/reports/condense/logistic.csv
      hash: md5
      md5: 867e4962cfb9603f6eff4fdb7364fa27
      size: 1188336
  compile@sms_spam-gzip_knn:
    cmd: python -m deckard.layers.compile  --report_folder sms_spam/reports/gzip_knn  --results_file
      sms_spam/reports/gzip_knn.csv
    deps:
    - path: sms_spam/reports/gzip_knn/
      hash: md5
      md5: 80d7bec56c802088cb73de7d2215e84f.dir
      size: 1464740
      nfiles: 1466
    outs:
    - path: sms_spam/reports/gzip_knn.csv
      hash: md5
      md5: 4a17855f53d2f84e70a495d058b01899
      size: 646870
  compile@sms_spam-gzip_svc:
    cmd: python -m deckard.layers.compile  --report_folder sms_spam/reports/gzip_svc  --results_file
      sms_spam/reports/gzip_svc.csv
    deps:
    - path: sms_spam/reports/gzip_svc/
      hash: md5
      md5: 821ee38a32dafb65fff22a8c98f8b118.dir
      size: 4346103
      nfiles: 3072
    outs:
    - path: sms_spam/reports/gzip_svc.csv
      hash: md5
      md5: c05548df9f102f92361afa9b7476fdff
      size: 1350809
  compile@sms_spam-gzip_logistic:
    cmd: python -m deckard.layers.compile  --report_folder sms_spam/reports/gzip_logistic  --results_file
      sms_spam/reports/gzip_logistic.csv
    deps:
    - path: sms_spam/reports/gzip_logistic/
      hash: md5
      md5: b38bcbdbf807a475244eea3ee96fcc5c.dir
      size: 5121803
      nfiles: 2550
    outs:
    - path: sms_spam/reports/gzip_logistic.csv
      hash: md5
      md5: 6776a26690c4f3d00775f6e99eac99d0
      size: 1250342
  compile@sms_spam-condense/knn:
    cmd: python -m deckard.layers.compile  --report_folder sms_spam/reports/condense/knn  --results_file
      sms_spam/reports/condense/knn.csv
    deps:
    - path: sms_spam/reports/condense/knn/
      hash: md5
      md5: b8538674b1fedf0f386a52a2cc9d41fc.dir
      size: 2356362
      nfiles: 2503
    outs:
    - path: sms_spam/reports/condense/knn.csv
      hash: md5
      md5: 5e322d2d99e5491cd40efb76cb576d15
      size: 1141722
  compile@sms_spam-condense/svc:
    cmd: python -m deckard.layers.compile  --report_folder sms_spam/reports/condense/svc  --results_file
      sms_spam/reports/condense/svc.csv
    deps:
    - path: sms_spam/reports/condense/svc/
      hash: md5
      md5: af6f0ed979e18a12442ba77748203ea9.dir
      size: 4494515
      nfiles: 3085
    outs:
    - path: sms_spam/reports/condense/svc.csv
      hash: md5
      md5: 5ead82ad572519728e9f571b7120ef21
      size: 1397197
  compile@sms_spam-condense/logistic:
    cmd: python -m deckard.layers.compile  --report_folder sms_spam/reports/condense/logistic  --results_file
      sms_spam/reports/condense/logistic.csv
    deps:
    - path: sms_spam/reports/condense/logistic/
      hash: md5
      md5: e7ee047601cf436c53bd55152b0afe11.dir
      size: 3715519
      nfiles: 2029
    outs:
    - path: sms_spam/reports/condense/logistic.csv
      hash: md5
      md5: 53489828bf0d55ab22d5dba310488dd8
      size: 1047981
  compile@ddos-gzip_knn:
    cmd: python -m deckard.layers.compile  --report_folder ddos/reports/gzip_knn  --results_file
      ddos/reports/gzip_knn.csv
    deps:
    - path: ddos/reports/gzip_knn/
      hash: md5
      md5: 5e4ffe028681db74e9d5ac1f32134a72.dir
      size: 1774059
      nfiles: 1949
    outs:
    - path: ddos/reports/gzip_knn.csv
      hash: md5
      md5: 5ea2e6e2263d3933ee3c290ad22d162b
      size: 870650
  compile@ddos-gzip_logistic:
    cmd: python -m deckard.layers.compile  --report_folder ddos/reports/gzip_logistic  --results_file
      ddos/reports/gzip_logistic.csv
    deps:
    - path: ddos/reports/gzip_logistic/
      hash: md5
      md5: ce5c624f9a89874f06c47d32ae2b4538.dir
      size: 5390876
      nfiles: 2405
    outs:
    - path: ddos/reports/gzip_logistic.csv
      hash: md5
      md5: 9afc2bc076a953a5187992fba51b64ba
      size: 1252312
  compile@ddos-gzip_svc:
    cmd: python -m deckard.layers.compile  --report_folder ddos/reports/gzip_svc  --results_file
      ddos/reports/gzip_svc.csv
    deps:
    - path: ddos/reports/gzip_svc/
      hash: md5
      md5: 8825dee6d90fc610e6c4a610ebfac585.dir
      size: 4419303
      nfiles: 3072
    outs:
    - path: ddos/reports/gzip_svc.csv
      hash: md5
      md5: e53c4b21a4c4bcbb4aa78008e21062c4
      size: 1396669
  compile@truthseeker-gzip_knn:
    cmd: python -m deckard.layers.compile  --report_folder truthseeker/reports/gzip_knn  --results_file
      truthseeker/reports/gzip_knn.csv
    deps:
    - path: truthseeker/reports/gzip_knn/
      hash: md5
      md5: c0758e88bfaa3539073e6b65c2b5b10e.dir
      size: 1766951
      nfiles: 1758
    outs:
    - path: truthseeker/reports/gzip_knn.csv
      hash: md5
      md5: b9bea03c06d3f4dc30282441e36c700a
      size: 793437
  compile@truthseeker-gzip_logistic:
    cmd: python -m deckard.layers.compile  --report_folder truthseeker/reports/gzip_logistic  --results_file
      truthseeker/reports/gzip_logistic.csv
    deps:
    - path: truthseeker/reports/gzip_logistic/
      hash: md5
      md5: 15dc5499e9233f6deecba69e01195eee.dir
      size: 5034881
      nfiles: 2649
    outs:
    - path: truthseeker/reports/gzip_logistic.csv
      hash: md5
      md5: 06ba1ec0435fac93c0204286ee88ca26
      size: 1313525
  compile@truthseeker-gzip_svc:
    cmd: python -m deckard.layers.compile  --report_folder truthseeker/reports/gzip_svc  --results_file
      truthseeker/reports/gzip_svc.csv
    deps:
    - path: truthseeker/reports/gzip_svc/
      hash: md5
      md5: b5e79545c7e071c323cb9aee1f707ce4.dir
      size: 4585446
      nfiles: 3217
    outs:
    - path: truthseeker/reports/gzip_svc.csv
      hash: md5
      md5: a6f40e3c4f1a2242a43632576013334c
      size: 1452411
  compile@ddos-condense/knn:
    cmd: python -m deckard.layers.compile  --report_folder ddos/reports/condense/knn  --results_file
      ddos/reports/condense/knn.csv
    deps:
    - path: ddos/reports/condense/knn/
      hash: md5
      md5: e55cfed8c96d357b82c4b055adf63233.dir
      size: 2838222
      nfiles: 2967
    outs:
    - path: ddos/reports/condense/knn.csv
      hash: md5
      md5: 7a526d5c2cd6d10b1bdc6894f6c17217
      size: 1394408
  compile@ddos-condense/svc:
    cmd: python -m deckard.layers.compile  --report_folder ddos/reports/condense/svc  --results_file
      ddos/reports/condense/svc.csv
    deps:
    - path: ddos/reports/condense/svc/
      hash: md5
      md5: 1843e4ff7d9c1882ac399d5faffa30f0.dir
      size: 3997629
      nfiles: 2665
    outs:
    - path: ddos/reports/condense/svc.csv
      hash: md5
      md5: 603d872c7bc5d8ce3e2d087537f1171d
      size: 1247829
  compile@ddos-condense/logistic:
    cmd: python -m deckard.layers.compile  --report_folder ddos/reports/condense/logistic  --results_file
      ddos/reports/condense/logistic.csv
    deps:
    - path: ddos/reports/condense/logistic/
      hash: md5
      md5: d11dba16e4ed27222f4fc084c7ccce80.dir
      size: 4273565
      nfiles: 2307
    outs:
    - path: ddos/reports/condense/logistic.csv
      hash: md5
      md5: 6d9471c0d92c1df6a07fbcdb150496c7
      size: 1229006
  compile@truthseeker-condense/knn:
    cmd: python -m deckard.layers.compile  --report_folder truthseeker/reports/condense/knn  --results_file
      truthseeker/reports/condense/knn.csv
    deps:
    - path: truthseeker/reports/condense/knn/
      hash: md5
      md5: 341aeb54ec3d2b7b434088a6f72fc027.dir
      size: 2352931
      nfiles: 2464
    outs:
    - path: truthseeker/reports/condense/knn.csv
      hash: md5
      md5: e6033070a5d7a22c4f63820d16430dc2
      size: 1155179
  compile@truthseeker-condense/svc:
    cmd: python -m deckard.layers.compile  --report_folder truthseeker/reports/condense/svc  --results_file
      truthseeker/reports/condense/svc.csv
    deps:
    - path: truthseeker/reports/condense/svc/
      hash: md5
      md5: 283cd2bbc598f4fd697fdd9b17c1ed99.dir
      size: 2623541
      nfiles: 1762
    outs:
    - path: truthseeker/reports/condense/svc.csv
      hash: md5
      md5: f1bf0ad1190078b036db2bc05f470ff5
      size: 825142
  compile@truthseeker-condense/logistic:
    cmd: python -m deckard.layers.compile  --report_folder truthseeker/reports/condense/logistic  --results_file
      truthseeker/reports/condense/logistic.csv
    deps:
    - path: truthseeker/reports/condense/logistic/
      hash: md5
      md5: fe1ce507e0d5f37b9e4fbbdc8b4308e4.dir
      size: 4216043
      nfiles: 2216
    outs:
    - path: truthseeker/reports/condense/logistic.csv
      hash: md5
      md5: 07bb4c331d67a498e8d88cb9521cc1f0
      size: 1192308
  condense@kdd_nsl-knn-0.95-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=1000 data.sample.test_size=400 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.95 ++model.init.distance_matrix=null files.directory=kdd_nsl
      files.reports=reports/condense/knn/gzip/0.95/ hydra.sweeper.study_name=condense_knn_kdd_nsl
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=kdd_nsl/logs/condense/knn/gzip/0.95/
      hydra.callbacks.study_dump.output_file=kdd_nsl/knn/gzip/0.95/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 656748d0afcf960f44886e5272318833
      size: 2056
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/condense/knn/gzip/0.95
      hash: md5
      md5: 8b20c73d97c40fd641298955efbeee12.dir
      size: 1006382
      nfiles: 513
  condense@sms_spam-knn-0.95-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=1000 data.sample.test_size=400 model_name=condensed_knn
      model=gzip_knn ++model.init.m=0.95 ++model.init.distance_matrix=null files.directory=sms_spam
      files.reports=reports/condense/knn/gzip/0.95/ hydra.sweeper.study_name=condense_knn_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/knn/gzip/0.95/
      hydra.callbacks.study_dump.output_file=sms_spam/knn/gzip/0.95/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 656748d0afcf960f44886e5272318833
      size: 2056
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/knn/gzip/0.95
      hash: md5
      md5: b2472ee820753cd8aaea5490eebf043d.dir
      size: 1002809
      nfiles: 513
  condense@truthseeker-svc-0.95-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=1000 data.sample.test_size=400 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.95 ++model.init.distance_matrix=null files.directory=truthseeker
      files.reports=reports/condense/svc/gzip/0.95/ hydra.sweeper.study_name=condense_svc_truthseeker
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=truthseeker/logs/condense/svc/gzip/0.95/
      hydra.callbacks.study_dump.output_file=truthseeker/svc/gzip/0.95/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: d70c19b4a058f81a485d6dd9e99a294f
      size: 2069
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/condense/svc/gzip/0.95
      hash: md5
      md5: 439ad8d9a48b6a3b6dd86a48d9ca0768.dir
      size: 1043363
      nfiles: 513
  condense@sms_spam-logistic-0.95-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=1000 data.sample.test_size=400 model_name=condensed_logistic
      model=gzip_logistic ++model.init.m=0.95 ++model.init.distance_matrix=null files.directory=sms_spam
      files.reports=reports/condense/logistic/gzip/0.95/ hydra.sweeper.study_name=condense_logistic_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/logistic/gzip/0.95/
      hydra.callbacks.study_dump.output_file=sms_spam/logistic/gzip/0.95/study.csv
      hydra.launcher.n_jobs=-1 --config-name condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: b1c796f85633c91291f46f07084dc601
      size: 2216
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/logistic/gzip/0.95
      hash: md5
      md5: fac08c7ed8b6de73d2aec7bd9c13bde9.dir
      size: 1089594
      nfiles: 513
  condense@sms_spam-svc-0.95-gzip:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=1000 data.sample.test_size=400 model_name=condensed_svc
      model=gzip_svc ++model.init.m=0.95 ++model.init.distance_matrix=null files.directory=sms_spam
      files.reports=reports/condense/svc/gzip/0.95/ hydra.sweeper.study_name=condense_svc_sms_spam
      hydra.sweeper.n_trials=128 hydra.sweeper.n_jobs=8 hydra.sweep.dir=sms_spam/logs/condense/svc/gzip/0.95/
      hydra.callbacks.study_dump.output_file=sms_spam/svc/gzip/0.95/study.csv hydra.launcher.n_jobs=-1
      --config-name condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: d70c19b4a058f81a485d6dd9e99a294f
      size: 2069
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/condense/svc/gzip/0.95
      hash: md5
      md5: dba581bffc831234ab109c874878c75a.dir
      size: 1034170
      nfiles: 513
  precompute_matrices@ddos-knn-gzip-true:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=1000
      data.sample.test_size=400 model_name=gzip_knn model=gzip_knn ++model.init.m=1
      files.directory=ddos hydra.sweeper.study_name=gzip_knn_ddos files.reports=reports/condense/knn/gzip/symmetry_true/
      ++hydra.sweeper.n_trials=1 ++hydra.sweeper.n_jobs=1 hydra.sweep.dir=ddos/logs/precompute/knn/gzip/symmetry_true/
      hydra.callbacks.study_dump.output_file=ddos/knn/gzip/symmetry_true/study.csv
      hydra.launcher.n_jobs=-1 ++model.init.distance_matrix=ddos/models/knn/gzip/symmetry_true/1000-400-0.npz  --config-name
      condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 18662f67a2a6744e2079f98759ca96b6
      size: 1933
    - path: ddos/reports/gzip_knn/
      hash: md5
      md5: b24dccb646b23f71d0a723fb5c6a4085.dir
      size: 1869750
      nfiles: 2034
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/precompute/knn/gzip/symmetry_true
      hash: md5
      md5: eabb2196a5ed8005d3a46823bf458471.dir
      size: 9130
      nfiles: 5
    - path: ddos/models/knn/gzip/symmetry_true/
      hash: md5
      md5: 6e3dbfb0f95801ec50ba9b5893efde06.dir
      size: 2954262
      nfiles: 1
  precompute_matrices@truthseeker-knn-gzip-false:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=1000 data.sample.test_size=400 model_name=gzip_knn model=gzip_knn
      ++model.init.m=1 files.directory=truthseeker hydra.sweeper.study_name=gzip_knn_truthseeker
      files.reports=reports/condense/knn/gzip/symmetry_false/ ++hydra.sweeper.n_trials=1
      ++hydra.sweeper.n_jobs=1 hydra.sweep.dir=truthseeker/logs/precompute/knn/gzip/symmetry_false/
      hydra.callbacks.study_dump.output_file=truthseeker/knn/gzip/symmetry_false/study.csv
      hydra.launcher.n_jobs=-1 
      ++model.init.distance_matrix=truthseeker/models/knn/gzip/symmetry_false/1000-400-0.npz  --config-name
      condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 18662f67a2a6744e2079f98759ca96b6
      size: 1933
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    - path: truthseeker/reports/gzip_knn/
      hash: md5
      md5: 6a75f76edeac58c83b75e56543791de2.dir
      size: 1833311
      nfiles: 1819
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/precompute/knn/gzip/symmetry_false
      hash: md5
      md5: 8af0fa27a8b96a442aaae1cc223157fd.dir
      size: 8160
      nfiles: 5
    - path: truthseeker/models/knn/gzip/symmetry_false/
      hash: md5
      md5: 9b5d74ccd9ed10ab57bfa065156771c6.dir
      size: 7995
      nfiles: 1
  precompute_matrices@ddos-logistic-gzip-false:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=1000
      data.sample.test_size=400 model_name=gzip_logistic model=gzip_logistic ++model.init.m=1
      files.directory=ddos hydra.sweeper.study_name=gzip_logistic_ddos files.reports=reports/condense/logistic/gzip/symmetry_false/
      ++hydra.sweeper.n_trials=1 ++hydra.sweeper.n_jobs=1 hydra.sweep.dir=ddos/logs/precompute/logistic/gzip/symmetry_false/
      hydra.callbacks.study_dump.output_file=ddos/logistic/gzip/symmetry_false/study.csv
      hydra.launcher.n_jobs=-1 
      ++model.init.distance_matrix=ddos/models/logistic/gzip/symmetry_false/1000-400-0.npz  --config-name
      condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: a0b4f1732c5500eb098e9270777ea5e4
      size: 2094
    - path: ddos/reports/gzip_logistic/
      hash: md5
      md5: ce5c624f9a89874f06c47d32ae2b4538.dir
      size: 5390876
      nfiles: 2405
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/precompute/logistic/gzip/symmetry_false
      hash: md5
      md5: c76fb22927e16842310f837b941acf1b.dir
      size: 8726
      nfiles: 5
    - path: ddos/models/logistic/gzip/symmetry_false/
      hash: md5
      md5: 6e3dbfb0f95801ec50ba9b5893efde06.dir
      size: 2954262
      nfiles: 1
  precompute_matrices@truthseeker-logistic-gzip-true:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=1000 data.sample.test_size=400 model_name=gzip_logistic
      model=gzip_logistic ++model.init.m=1 files.directory=truthseeker hydra.sweeper.study_name=gzip_logistic_truthseeker
      files.reports=reports/condense/logistic/gzip/symmetry_true/ hydra.sweeper.n_trials=1
      hydra.sweeper.n_jobs=1 hydra.sweep.dir=truthseeker/logs/precompute/logistic/gzip/symmetry_true/
      hydra.callbacks.study_dump.output_file=truthseeker/logistic/gzip/symmetry_true/study.csv
      hydra.launcher.n_jobs=-1 
      ++model.init.distance_matrix=truthseeker/models/logistic/gzip/symmetry_true/1000-400-0.npz  --config-name
      condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: a0b4f1732c5500eb098e9270777ea5e4
      size: 2094
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    - path: truthseeker/reports/gzip_logistic/
      hash: md5
      md5: 15dc5499e9233f6deecba69e01195eee.dir
      size: 5034881
      nfiles: 2649
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/precompute/logistic/gzip/symmetry_true
      hash: md5
      md5: 5407c79b5407aa77a68c098847f540d1.dir
      size: 8870
      nfiles: 5
    - path: truthseeker/models/logistic/gzip/symmetry_true/
      hash: md5
      md5: 8e3a408957febba5ae093ddc8b77d5d5.dir
      size: 2436568
      nfiles: 1
  precompute_matrices@truthseeker-logistic-gzip-false:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=1000 data.sample.test_size=400 model_name=gzip_logistic
      model=gzip_logistic ++model.init.m=1 files.directory=truthseeker hydra.sweeper.study_name=gzip_logistic_truthseeker
      files.reports=reports/condense/logistic/gzip/symmetry_false/ ++hydra.sweeper.n_trials=1
      ++hydra.sweeper.n_jobs=1 hydra.sweep.dir=truthseeker/logs/precompute/logistic/gzip/symmetry_false/
      hydra.callbacks.study_dump.output_file=truthseeker/logistic/gzip/symmetry_false/study.csv
      hydra.launcher.n_jobs=-1 
      ++model.init.distance_matrix=truthseeker/models/logistic/gzip/symmetry_false/1000-400-0.npz  --config-name
      condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: a0b4f1732c5500eb098e9270777ea5e4
      size: 2094
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    - path: truthseeker/reports/gzip_logistic/
      hash: md5
      md5: 15dc5499e9233f6deecba69e01195eee.dir
      size: 5034881
      nfiles: 2649
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/precompute/logistic/gzip/symmetry_false
      hash: md5
      md5: 03d5632ebd903d583a88100913dc88b2.dir
      size: 8863
      nfiles: 5
    - path: truthseeker/models/logistic/gzip/symmetry_false/
      hash: md5
      md5: 8e3a408957febba5ae093ddc8b77d5d5.dir
      size: 2436568
      nfiles: 1
  precompute_matrices@truthseeker-knn-gzip-true:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=1000 data.sample.test_size=400 model_name=gzip_knn model=gzip_knn
      ++model.init.m=1 files.directory=truthseeker hydra.sweeper.study_name=gzip_knn_truthseeker
      files.reports=reports/condense/knn/gzip/symmetry_true/ ++hydra.sweeper.n_trials=1
      ++hydra.sweeper.n_jobs=1 hydra.sweep.dir=truthseeker/logs/precompute/knn/gzip/symmetry_true/
      hydra.callbacks.study_dump.output_file=truthseeker/knn/gzip/symmetry_true/study.csv
      hydra.launcher.n_jobs=-1 
      ++model.init.distance_matrix=truthseeker/models/knn/gzip/symmetry_true/1000-400-0.npz  --config-name
      condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 18662f67a2a6744e2079f98759ca96b6
      size: 1933
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    - path: truthseeker/reports/gzip_knn/
      hash: md5
      md5: 6a75f76edeac58c83b75e56543791de2.dir
      size: 1833311
      nfiles: 1819
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/precompute/knn/gzip/symmetry_true
      hash: md5
      md5: bd037753fd73b282cc52f2a91abe0580.dir
      size: 8131
      nfiles: 5
    - path: truthseeker/models/knn/gzip/symmetry_true/
      hash: md5
      md5: 8e3a408957febba5ae093ddc8b77d5d5.dir
      size: 2436568
      nfiles: 1
  precompute_matrices@sms_spam-knn-gzip-false:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=1000 data.sample.test_size=400 model_name=gzip_knn model=gzip_knn
      ++model.init.m=1 files.directory=sms_spam hydra.sweeper.study_name=gzip_knn_sms_spam
      files.reports=reports/condense/knn/gzip/symmetry_false/ ++hydra.sweeper.n_trials=1
      ++hydra.sweeper.n_jobs=1 hydra.sweep.dir=sms_spam/logs/precompute/knn/gzip/symmetry_false/
      hydra.callbacks.study_dump.output_file=sms_spam/knn/gzip/symmetry_false/study.csv
      hydra.launcher.n_jobs=-1 
      ++model.init.distance_matrix=sms_spam/models/knn/gzip/symmetry_false/1000-400-0.npz  --config-name
      condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 18662f67a2a6744e2079f98759ca96b6
      size: 1933
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    - path: sms_spam/reports/gzip_knn/
      hash: md5
      md5: f7a627aef369cd3ee5d8071e903079ef.dir
      size: 1591964
      nfiles: 1582
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/precompute/knn/gzip/symmetry_false
      hash: md5
      md5: f36947bbb454c1b206919d4418d3ab8f.dir
      size: 8078
      nfiles: 5
    - path: sms_spam/models/knn/gzip/symmetry_false/
      hash: md5
      md5: 9b5d74ccd9ed10ab57bfa065156771c6.dir
      size: 7995
      nfiles: 1
  precompute_matrices@truthseeker-svc-gzip-false:
    cmd: python -m deckard.layers.optimise stage=train data=truthseeker dataset=truthseeker
      data.sample.train_size=1000 data.sample.test_size=400 model_name=gzip_svc model=gzip_svc
      ++model.init.m=1 files.directory=truthseeker hydra.sweeper.study_name=gzip_svc_truthseeker
      files.reports=reports/condense/svc/gzip/symmetry_false/ ++hydra.sweeper.n_trials=1
      ++hydra.sweeper.n_jobs=1 hydra.sweep.dir=truthseeker/logs/precompute/svc/gzip/symmetry_false/
      hydra.callbacks.study_dump.output_file=truthseeker/svc/gzip/symmetry_false/study.csv
      hydra.launcher.n_jobs=-1 
      ++model.init.distance_matrix=truthseeker/models/svc/gzip/symmetry_false/1000-400-0.npz  --config-name
      condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: d75c54fc33a8fb1b9c9103b6159890d0
      size: 1948
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    - path: truthseeker/reports/gzip_svc/
      hash: md5
      md5: b5e79545c7e071c323cb9aee1f707ce4.dir
      size: 4585446
      nfiles: 3217
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: truthseeker/logs/precompute/svc/gzip/symmetry_false
      hash: md5
      md5: 40a3a07ee220919a437b1b350231a117.dir
      size: 8527
      nfiles: 5
    - path: truthseeker/models/svc/gzip/symmetry_false/
      hash: md5
      md5: 8e3a408957febba5ae093ddc8b77d5d5.dir
      size: 2436568
      nfiles: 1
  precompute_matrices@kdd_nsl-logistic-gzip-true:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=1000 data.sample.test_size=400 model_name=gzip_logistic
      model=gzip_logistic ++model.init.m=1 files.directory=kdd_nsl hydra.sweeper.study_name=gzip_logistic_kdd_nsl
      files.reports=reports/condense/logistic/gzip/symmetry_true/ ++hydra.sweeper.n_trials=1
      ++hydra.sweeper.n_jobs=1 hydra.sweep.dir=kdd_nsl/logs/precompute/logistic/gzip/symmetry_true/
      hydra.callbacks.study_dump.output_file=kdd_nsl/logistic/gzip/symmetry_true/study.csv
      hydra.launcher.n_jobs=-1 
      ++model.init.distance_matrix=kdd_nsl/models/logistic/gzip/symmetry_true/1000-400-0.npz  --config-name
      condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: a0b4f1732c5500eb098e9270777ea5e4
      size: 2094
    - path: kdd_nsl/reports/gzip_logistic/
      hash: md5
      md5: 5fac082eca0a191aab92706220080062.dir
      size: 5243991
      nfiles: 2536
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/precompute/logistic/gzip/symmetry_true
      hash: md5
      md5: bc9d9a782e4b4a808d064d573b37d2d7.dir
      size: 8794
      nfiles: 5
    - path: kdd_nsl/models/logistic/gzip/symmetry_true/
      hash: md5
      md5: cf134076d2259c5a69b968c4d2a15931.dir
      size: 1705656
      nfiles: 1
  precompute_matrices@kdd_nsl-logistic-gzip-false:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=1000 data.sample.test_size=400 model_name=gzip_logistic
      model=gzip_logistic ++model.init.m=1 files.directory=kdd_nsl hydra.sweeper.study_name=gzip_logistic_kdd_nsl
      files.reports=reports/condense/logistic/gzip/symmetry_false/ ++hydra.sweeper.n_trials=1
      ++hydra.sweeper.n_jobs=1 hydra.sweep.dir=kdd_nsl/logs/precompute/logistic/gzip/symmetry_false/
      hydra.callbacks.study_dump.output_file=kdd_nsl/logistic/gzip/symmetry_false/study.csv
      hydra.launcher.n_jobs=-1 
      ++model.init.distance_matrix=kdd_nsl/models/logistic/gzip/symmetry_false/1000-400-0.npz  --config-name
      condense_logistic --multirun
    deps:
    - path: conf/condense_logistic.yaml
      hash: md5
      md5: a0b4f1732c5500eb098e9270777ea5e4
      size: 2094
    - path: kdd_nsl/reports/gzip_logistic/
      hash: md5
      md5: 5fac082eca0a191aab92706220080062.dir
      size: 5243991
      nfiles: 2536
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/precompute/logistic/gzip/symmetry_false
      hash: md5
      md5: 0490241ee1f7b5833370917f2d5d3f4d.dir
      size: 8807
      nfiles: 5
    - path: kdd_nsl/models/logistic/gzip/symmetry_false/
      hash: md5
      md5: cf134076d2259c5a69b968c4d2a15931.dir
      size: 1705656
      nfiles: 1
  precompute_matrices@ddos-knn-gzip-false:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=1000
      data.sample.test_size=400 model_name=gzip_knn model=gzip_knn ++model.init.m=1
      files.directory=ddos hydra.sweeper.study_name=gzip_knn_ddos files.reports=reports/condense/knn/gzip/symmetry_false/
      ++hydra.sweeper.n_trials=1 ++hydra.sweeper.n_jobs=1 hydra.sweep.dir=ddos/logs/precompute/knn/gzip/symmetry_false/
      hydra.callbacks.study_dump.output_file=ddos/knn/gzip/symmetry_false/study.csv
      hydra.launcher.n_jobs=-1 ++model.init.distance_matrix=ddos/models/knn/gzip/symmetry_false/1000-400-0.npz  --config-name
      condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 18662f67a2a6744e2079f98759ca96b6
      size: 1933
    - path: ddos/reports/gzip_knn/
      hash: md5
      md5: b24dccb646b23f71d0a723fb5c6a4085.dir
      size: 1869750
      nfiles: 2034
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/precompute/knn/gzip/symmetry_false
      hash: md5
      md5: cadf62a6e6aa42cfcd2b4c1d79fc9668.dir
      size: 8023
      nfiles: 5
    - path: ddos/models/knn/gzip/symmetry_false/
      hash: md5
      md5: 9b5d74ccd9ed10ab57bfa065156771c6.dir
      size: 7995
      nfiles: 1
  precompute_matrices@sms_spam-knn-gzip-true:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=1000 data.sample.test_size=400 model_name=gzip_knn model=gzip_knn
      ++model.init.m=1 files.directory=sms_spam hydra.sweeper.study_name=gzip_knn_sms_spam
      files.reports=reports/condense/knn/gzip/symmetry_true/ ++hydra.sweeper.n_trials=1
      ++hydra.sweeper.n_jobs=1 hydra.sweep.dir=sms_spam/logs/precompute/knn/gzip/symmetry_true/
      hydra.callbacks.study_dump.output_file=sms_spam/knn/gzip/symmetry_true/study.csv
      hydra.launcher.n_jobs=-1 
      ++model.init.distance_matrix=sms_spam/models/knn/gzip/symmetry_true/1000-400-0.npz  --config-name
      condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 18662f67a2a6744e2079f98759ca96b6
      size: 1933
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    - path: sms_spam/reports/gzip_knn/
      hash: md5
      md5: f7a627aef369cd3ee5d8071e903079ef.dir
      size: 1591964
      nfiles: 1582
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/precompute/knn/gzip/symmetry_true
      hash: md5
      md5: 31ae769dd14c33daf3fa1804b635ebba.dir
      size: 8049
      nfiles: 5
    - path: sms_spam/models/knn/gzip/symmetry_true/
      hash: md5
      md5: 401810469df2f04c3edd9a765880e31b.dir
      size: 2359073
      nfiles: 1
  precompute_matrices@kdd_nsl-knn-gzip-true:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=1000 data.sample.test_size=400 model_name=gzip_knn model=gzip_knn
      ++model.init.m=1 files.directory=kdd_nsl hydra.sweeper.study_name=gzip_knn_kdd_nsl
      files.reports=reports/condense/knn/gzip/symmetry_true/ ++hydra.sweeper.n_trials=1
      ++hydra.sweeper.n_jobs=1 hydra.sweep.dir=kdd_nsl/logs/precompute/knn/gzip/symmetry_true/
      hydra.callbacks.study_dump.output_file=kdd_nsl/knn/gzip/symmetry_true/study.csv
      hydra.launcher.n_jobs=-1 
      ++model.init.distance_matrix=kdd_nsl/models/knn/gzip/symmetry_true/1000-400-0.npz  --config-name
      condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 18662f67a2a6744e2079f98759ca96b6
      size: 1933
    - path: kdd_nsl/reports/gzip_knn/
      hash: md5
      md5: d30aaee43e72d1392e96d1ed64220ab7.dir
      size: 1603607
      nfiles: 1527
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/precompute/knn/gzip/symmetry_true
      hash: md5
      md5: 998daf9bbdedba02dfc1c62188917f28.dir
      size: 8083
      nfiles: 5
    - path: kdd_nsl/models/knn/gzip/symmetry_true/
      hash: md5
      md5: 9b5d74ccd9ed10ab57bfa065156771c6.dir
      size: 7995
      nfiles: 1
  precompute_matrices@kdd_nsl-knn-gzip-false:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=1000 data.sample.test_size=400 model_name=gzip_knn model=gzip_knn
      ++model.init.m=1 files.directory=kdd_nsl hydra.sweeper.study_name=gzip_knn_kdd_nsl
      files.reports=reports/condense/knn/gzip/symmetry_false/ ++hydra.sweeper.n_trials=1
      ++hydra.sweeper.n_jobs=1 hydra.sweep.dir=kdd_nsl/logs/precompute/knn/gzip/symmetry_false/
      hydra.callbacks.study_dump.output_file=kdd_nsl/knn/gzip/symmetry_false/study.csv
      hydra.launcher.n_jobs=-1 
      ++model.init.distance_matrix=kdd_nsl/models/knn/gzip/symmetry_false/1000-400-0.npz  --config-name
      condense_knn --multirun
    deps:
    - path: conf/condense_knn.yaml
      hash: md5
      md5: 18662f67a2a6744e2079f98759ca96b6
      size: 1933
    - path: kdd_nsl/reports/gzip_knn/
      hash: md5
      md5: d30aaee43e72d1392e96d1ed64220ab7.dir
      size: 1603607
      nfiles: 1527
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/precompute/knn/gzip/symmetry_false
      hash: md5
      md5: e54dbf294566aa70ab96567ab4931f73.dir
      size: 8080
      nfiles: 5
    - path: kdd_nsl/models/knn/gzip/symmetry_false/
      hash: md5
      md5: cf134076d2259c5a69b968c4d2a15931.dir
      size: 1705656
      nfiles: 1
  precompute_matrices@ddos-svc-gzip-true:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=1000
      data.sample.test_size=400 model_name=gzip_svc model=gzip_svc ++model.init.m=1
      files.directory=ddos hydra.sweeper.study_name=gzip_svc_ddos files.reports=reports/condense/svc/gzip/symmetry_true/
      ++hydra.sweeper.n_trials=1 ++hydra.sweeper.n_jobs=1 hydra.sweep.dir=ddos/logs/precompute/svc/gzip/symmetry_true/
      hydra.callbacks.study_dump.output_file=ddos/svc/gzip/symmetry_true/study.csv
      hydra.launcher.n_jobs=-1 ++model.init.distance_matrix=ddos/models/svc/gzip/symmetry_true/1000-400-0.npz  --config-name
      condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: d75c54fc33a8fb1b9c9103b6159890d0
      size: 1948
    - path: ddos/reports/gzip_svc/
      hash: md5
      md5: 8825dee6d90fc610e6c4a610ebfac585.dir
      size: 4419303
      nfiles: 3072
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/precompute/svc/gzip/symmetry_true
      hash: md5
      md5: c1f76f303649305f5e09884655ea521b.dir
      size: 8353
      nfiles: 5
    - path: ddos/models/svc/gzip/symmetry_true/
      hash: md5
      md5: 6e3dbfb0f95801ec50ba9b5893efde06.dir
      size: 2954262
      nfiles: 1
  precompute_matrices@ddos-svc-gzip-false:
    cmd: python -m deckard.layers.optimise stage=train data=ddos dataset=ddos data.sample.train_size=1000
      data.sample.test_size=400 model_name=gzip_svc model=gzip_svc ++model.init.m=1
      files.directory=ddos hydra.sweeper.study_name=gzip_svc_ddos files.reports=reports/condense/svc/gzip/symmetry_false/
      ++hydra.sweeper.n_trials=1 ++hydra.sweeper.n_jobs=1 hydra.sweep.dir=ddos/logs/precompute/svc/gzip/symmetry_false/
      hydra.callbacks.study_dump.output_file=ddos/svc/gzip/symmetry_false/study.csv
      hydra.launcher.n_jobs=-1 ++model.init.distance_matrix=ddos/models/svc/gzip/symmetry_false/1000-400-0.npz  --config-name
      condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: d75c54fc33a8fb1b9c9103b6159890d0
      size: 1948
    - path: ddos/reports/gzip_svc/
      hash: md5
      md5: 8825dee6d90fc610e6c4a610ebfac585.dir
      size: 4419303
      nfiles: 3072
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: ddos/logs/precompute/svc/gzip/symmetry_false
      hash: md5
      md5: 7210c9672f1752d2848fd83d8036c231.dir
      size: 8358
      nfiles: 5
    - path: ddos/models/svc/gzip/symmetry_false/
      hash: md5
      md5: 9b5d74ccd9ed10ab57bfa065156771c6.dir
      size: 7995
      nfiles: 1
  precompute_matrices@sms_spam-svc-gzip-true:
    cmd: python -m deckard.layers.optimise stage=train data=sms_spam dataset=sms_spam
      data.sample.train_size=1000 data.sample.test_size=400 model_name=gzip_svc model=gzip_svc
      ++model.init.m=1 files.directory=sms_spam hydra.sweeper.study_name=gzip_svc_sms_spam
      files.reports=reports/condense/svc/gzip/symmetry_true/ hydra.sweeper.n_trials=1
      hydra.sweeper.n_jobs=1 hydra.sweep.dir=sms_spam/logs/precompute/svc/gzip/symmetry_true/
      hydra.callbacks.study_dump.output_file=sms_spam/svc/gzip/symmetry_true/study.csv
      hydra.launcher.n_jobs=-1 
      ++model.init.distance_matrix=sms_spam/models/svc/gzip/symmetry_true/1000-400-0.npz  --config-name
      condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: b31c24ed895da2a2542b91cf78f2004d
      size: 2000
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    - path: sms_spam/reports/gzip_svc/
      hash: md5
      md5: 821ee38a32dafb65fff22a8c98f8b118.dir
      size: 4346103
      nfiles: 3072
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: sms_spam/logs/precompute/svc/gzip/symmetry_true
      hash: md5
      md5: f508702dfc863a9382f1eb88b86848ed.dir
      size: 8355
      nfiles: 5
    - path: sms_spam/models/svc/gzip/symmetry_true/
      hash: md5
      md5: 401810469df2f04c3edd9a765880e31b.dir
      size: 2359073
      nfiles: 1
  precompute_matrices@kdd_nsl-svc-gzip-true:
    cmd: python -m deckard.layers.optimise stage=train data=kdd_nsl dataset=kdd_nsl
      data.sample.train_size=1000 data.sample.test_size=400 model_name=gzip_svc model=gzip_svc
      ++model.init.m=1 files.directory=kdd_nsl hydra.sweeper.study_name=gzip_svc_kdd_nsl
      files.reports=reports/condense/svc/gzip/symmetry_true/ hydra.sweeper.n_trials=1
      hydra.sweeper.n_jobs=1 hydra.sweep.dir=kdd_nsl/logs/precompute/svc/gzip/symmetry_true/
      hydra.callbacks.study_dump.output_file=kdd_nsl/svc/gzip/symmetry_true/study.csv
      hydra.launcher.n_jobs=-1 
      ++model.init.distance_matrix=kdd_nsl/models/svc/gzip/symmetry_true/1000-400-0.npz  --config-name
      condense_svc --multirun
    deps:
    - path: conf/condense_svc.yaml
      hash: md5
      md5: b31c24ed895da2a2542b91cf78f2004d
      size: 2000
    - path: kdd_nsl/reports/gzip_svc/
      hash: md5
      md5: 9b688eaec16d8fb94d8fb7c80c79313a.dir
      size: 4442105
      nfiles: 3072
    - path: params.yaml
      hash: md5
      md5: 486532089f9aed37612260a1f0a2bead
      size: 1469
    params:
      conf/condense.yaml:
        hydra:
          run:
            dir: ${dataset}/logs/condense/
          sweep:
            dir: ???
            subdir: ${hydra.job.num}
          callbacks:
            study_dump:
              _target_: database.OptunaStudyDumpCallback
              storage: ${hydra.sweeper.storage}
              study_name: ${hydra.sweeper.study_name}
              directions: ${direction}
              metric_names: ${optimizers}
              output_file: ${dataset}/logs/${model_name}/${data.sample.train_size}/study.csv
          sweeper:
            sampler:
              _target_: optuna.samplers.TPESampler
              seed: 123
              consider_prior: true
              prior_weight: 1.0
              consider_magic_clip: true
              consider_endpoints: false
              n_startup_trials: 10
              n_ei_candidates: 24
              multivariate: true
            _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
            study_name: ${dataset}_${model_name}
            storage: sqlite:///optuna.db
            n_jobs: 2
            n_trials: 2
            direction: ${direction}
            max_failure_rate: 1.0
            params:
              ++data.sample.train_size: 1000
              ++data.sample.random_state: int(interval(10000, 20000))
              model.init.m: tag(log, interval(.01, .1))
              +model.init.sampling_method: medoid,sum,svc,random,hardness,nearmiss,knn
          launcher:
            _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
            n_jobs: 8
            prefer: processes
            verbose: 1
            timeout:
            pre_dispatch: ${hydra.sweeper.n_jobs}
            batch_size: auto
            temp_folder: /tmp/deckard
            max_nbytes: 100000
            mmap_mode: r
    outs:
    - path: kdd_nsl/logs/precompute/svc/gzip/symmetry_true
      hash: md5
      md5: a01270e6209c266d4f35bfa1edffeaf7.dir
      size: 8434
      nfiles: 5
    - path: kdd_nsl/models/svc/gzip/symmetry_true/
      hash: md5
      md5: cf134076d2259c5a69b968c4d2a15931.dir
      size: 1705656
      nfiles: 1
