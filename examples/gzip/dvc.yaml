vars:
  - conf/default.yaml:hydra
  - conf/plots.yaml:line_plot
stages:
  ##############################################################################
  # These stages use the dvc API to run a single experiment at a time using a
  # deckard.Experiment object. This parses this file, saves the default hydra configuration
  # to params.yaml, and then runs the experiment with the given parameters.
  # This can be used to define a stage that runs a single experiment, or a stage for the
  # optimisation using the optimise.py script and the hydrasweeper API. This API is primarily used for
  # development and testing, as it is easier to run a single experiment at a time and debug it using
  # DVC's git-like features to track changes and minimise run time. 

  # This stage will parse the conf/default.yaml file and save it to params.yaml
  # In addition, it will define a schema stage that will will 
  # 1. Determine the file paths for the data and model files (if specified)
  # 2. Run the experiment with the given parameters
  # 3. Save the results to the given file paths
  # 4. Save a 'params.yaml' file with the scores
  # 5. Save the predictions to the given file paths (if specified)
  # 6. Save the probabilities to the given file paths (if specified)
  # 7. Save the train/test labels to the given file paths (if specified)
  # You can arbitrarily define parameters in the 'conf' folder.
  # To parse the parameters, you can use the 'hydra' API to define a schema for the parameters
  # Or run `deckard.layers.parse` to parse the parameters and save them to a file.  
  ##############################################################################
  train:
    cmd: python -m deckard.layers.experiment train
    metrics:
    - ${files.directory}/${files.reports}/train/${files.name}/${files.score_dict_file}
    outs:
    # - ${files.directory}/${files.data_dir}/${files.data_file}${files.data_type}
    # - ${files.directory}/${files.model_dir}/${files.model_file}${files.model_type}
    - ${files.directory}/${files.reports}/train/${files.name}/${files.predictions_file}
    params:
    - data
    - model
    - scorers
    - files
    - dataset
    - model_name
    - device_id
  ##############################################################################
  test_symmetric_methods:
    matrix:
      symmetric: [true, false]
      dataset : [kdd_nsl, truthseeker]
    cmd : >-
      python -m deckard.layers.optimise 
      stage=train 
      model.init.method=random
      model.init.m=10 
      files.name=symmetric_${item.symmetric}
      files.directory=${item.dataset}
      data=${item.dataset}
      dataset=${item.dataset}
      model_name=${model_name}
      model.init.symmetric=${item.symmetric}
      model.init.distance_matrix=${item.dataset}/${files.model_dir}/${model_name}/${model.init.method}/symmetric_${item.symmetric}.npz
      ++raise_exception=True 
    deps:
    - params.yaml
    - ${files.directory}/${files.reports}/train/default/${files.score_dict_file}
    outs:
    - ${item.dataset}/${files.reports}/train/symmetric_${item.symmetric}/${files.score_dict_file}
    - ${item.dataset}/${files.model_dir}/${model_name}/${model.init.method}/symmetric_${item.symmetric}.npz:
        cache: true
        persist: true
    params:
      - data
      - model
      - scorers
      - files
      - dataset
      - model_name
      - device_id
  ##############################################################################
  test_each_method:
    matrix:
      method: [knn, svc, medoid, sum, random]
      dataset : [kdd_nsl, truthseeker]
    cmd : >-
      python -m deckard.layers.optimise 
      stage=train 
      model.init.method=${item.method} 
      model.init.m=10 
      files.name=${item.method}
      files.directory=${item.dataset}
      data=${item.dataset}
      dataset=${item.dataset}
      model_name=${model_name}
      model.init.distance_matrix=${item.dataset}/${files.model_dir}/${model_name}/${model.init.method}/${item.method}.npz
      ++raise_exception=True 
    deps:
    - params.yaml
    - ${files.directory}/${files.reports}/train/default/${files.score_dict_file}
    outs:
    - ${item.dataset}/${files.reports}/train/${item.method}/${files.score_dict_file}
    params:
      - data
      - model
      - scorers
      - files
      - dataset
      - model_name
      - device_id
  ##############################################################################
  test_each_compressor:
    matrix:
      compressor: [gzip, lzma, zstd, pkl, bz2]
      dataset : [kdd_nsl, truthseeker]
    cmd : >-
      python -m deckard.layers.optimise 
      stage=train 
      files.name=${item.compressor}
      files.directory=${item.dataset}
      data=${item.dataset}
      dataset=${item.dataset}
      model_name=${model_name}
      model.init.method=random
      model.init.distance_matrix=${item.dataset}/${files.model_dir}/${model_name}/${model.init.method}/${item.compressor}.npz
      model.init.compressor=${item.compressor} 
      model.init.m=10 
      ++raise_exception=True 
    deps:
    - params.yaml
    - ${files.directory}/${files.reports}/train/default/${files.score_dict_file}
    outs:
    - ${item.dataset}/${files.reports}/train/${item.compressor}/${files.score_dict_file}
    params:
      - data
      - model
      - scorers
      - files
      - dataset
      - model_name
      - device_id
  ##############################################################################
  test_each_precompute:
    matrix:
      precompute: ["True", "False", 'ball_tree', 'kd_tree', 'brute']
      dataset : [kdd_nsl, truthseeker]
    cmd : >-
      python -m deckard.layers.optimise 
      stage=train 
      files.name=precompute_${item.precompute}
      files.directory=${item.dataset}
      data=${item.dataset}
      dataset=${item.dataset}
      model_name=${model_name}
      model.init.method=random
      model.init.distance_matrix=${item.dataset}/${files.model_dir}/${model_name}/${model.init.method}/${item.precompute}.npz
      +model.init.precompute=${item.precompute} 
      model.init.m=10 
      ++raise_exception=True 
    deps:
    - params.yaml
    - ${files.directory}/${files.reports}/train/default/${files.score_dict_file}
    outs:
    - ${item.dataset}/${files.reports}/train/precompute_${item.precompute}/${files.score_dict_file}
    params:
      - data
      - model
      - scorers
      - files
      - dataset
      - model_name
      - device_id
  ##############################################################################
  test_each_metric:
    matrix:
      metric: [levenshtein, ratio, hamming, jaro, jaro_winkler, seqratio, ncd]
      dataset : [kdd_nsl, truthseeker]
    cmd : >-
      python -m deckard.layers.optimise 
      stage=train 
      model.init.metric=${item.metric} 
      files.name=${item.metric}
      files.directory=${item.dataset}
      data=${item.dataset}
      dataset=${item.dataset}
      model_name=${model_name}
      model.init.distance_matrix=${item.dataset}/${files.model_dir}/${model_name}/${model.init.metric}/${item.metric}.npz
      ++raise_exception=True 
    deps:
    - params.yaml
    - ${files.directory}/${files.reports}/train/default/${files.score_dict_file}
    outs:
    - ${item.dataset}/${files.reports}/train/${item.metric}/${files.score_dict_file}
    params:
      - data
      - model
      - scorers
      - files
      - dataset
      - model_name
      - device_id
  ##############################################################################
  grid_search_compressors:
    matrix:
      random_state: [0,1,2,3,4,5,6,7,8,9] 
      train_size: [.8]
      dataset : [kdd_nsl, truthseeker]
      compressor : [gzip, lzma, zstd, pkl, bz2]
    cmd: >-
      python -m deckard.layers.optimise 
      stage=train 
      data=${item.dataset}
      dataset=${item.dataset}
      data.sample.random_state=${item.random_state}
      data.sample.train_size=${item.train_size}
      dataset=${dataset}
      files.directory=${item.dataset}
      model_name=${model_name}
      model=${model_name}
      model.init.distance_matrix=${item.dataset}/${files.model_dir}/${model_name}/${item.compressor}/${item.random_state}
      model.init.method=random,svc,medoid,sum,knn
      model.init.m=10,20,50,100,200,500,1000,-1
      model.init.compressor=${item.compressor}
      model.init.symmetric=True,False
      +model.init.precompute="auto",null,ball_tree,kd_tree,brute
      hydra.sweep.dir=${item.dataset}/logs/compressor/${item.compressor} 
      --multirun
    deps:
    - ${files.directory}/${files.reports}/train/default/${files.score_dict_file}
    outs:
    - ${item.dataset}/${files.model_dir}/${model_name}/${item.compressor}/${item.random_state}-${item.train_size}.npz:
        cache: true
        persist: true
    params:
    - data
    - model
    - scorers
    - files
    - dataset
    - model_name
    - device_id
  ##############################################################################
  grid_search_metrics:
    matrix:
      random_state: [0,1,2,3,4,5,6,7,8,9]#
      train_size: [.8]
      dataset : [kdd_nsl, truthseeker]
      metric : [levenshtein, ratio, hamming, jaro, jaro_winkler, seqratio, ncd]
    cmd: >-
      python -m deckard.layers.optimise 
      stage=train 
      data=${item.dataset}
      dataset=${item.dataset}
      data.sample.random_state=${item.random_state}
      data.sample.train_size=${item.train_size}
      dataset=${dataset}
      files.directory=${item.dataset}
      model_name=${model_name}
      model=${model_name}
      model.init.distance_matrix=${item.dataset}/${files.model_dir}/${model_name}/${item.metric}/${item.random_state}-${item.train_size}.npz
      model.init.m=10,20,50,100,200,500,1000,-1
      model.init.method=random,svc,medoid,sum,knn
      +model.init.precompute=True,False,ball_tree,kd_tree,brute
      model.init.symmetric=True,False
      model.init.metric=${item.metric}
      hydra.sweep.dir=${item.dataset}/logs/k/${item.metric}
      --multirun
    deps:
    - ${files.directory}/${files.reports}/train/default/${files.score_dict_file}
    outs:
    - ${item.dataset}/${files.model_dir}/${model_name}/${item.metric}/${item.random_state}-${item.train_size}.npz:
        cache: true
        persist: true
    params:
    - data
    - model
    - scorers
    - files
    - dataset
    - model_name
    - device_id
  ##############################################################################

  # # attack:
  # #   cmd: python -m deckard.layers.experiment attack
  # #   deps:
  # #   - ${files.directory}/${files.data_dir}/${files.data_file}${files.data_type}
  # #   - ${files.directory}/${files.model_dir}/${files.model_file}${files.model_type}
  # #   metrics:
  # #   - ${files.directory}/${files.reports}/attack/${files.name}/${files.score_dict_file}
  # #   outs:
  # #   - ${files.directory}/${files.reports}/attack/${files.name}/${files.adv_probabilities_file}
  # #   params:
  # #   - data
  # #   - model
  # #   - attack
  # #   - scorers
  # #   - files
  # # ##############################################################################

  # compile:
  #   matrix:
  #     dataset : [kdd_nsl, truthseeker]
  #     model_name : [gzip_classifier]
  #     stage : [train]
  #   deps:
  #     - ${item.dataset}/logs/m/${item.model_name}
  #     - conf/model/best_m_${item.model_name}_${item.dataset}.yaml
  #   outs:
  #   - ${item.dataset}/${files.reports}/${item.stage}-${item.model_name}.csv
  #   cmd: >-
  #    python -m deckard.layers.compile 
  #    --report_folder ${item.dataset}/${files.reports}/${item.stage} 
  #    --results_file ${item.dataset}/${files.reports}/${item.stage}-${item.model_name}.csv
  # clean:
  #   matrix:
  #     dataset : [kdd_nsl, truthseeker]
  #     model_name : [gzip_classifier]
  #     stage : [train]
  #   deps:
  #     - ${item.dataset}/${files.reports}/${item.stage}-${item.model_name}.csv
  #   cmd: >-
  #     python -m deckard.layers.clean_data 
  #     -i ${item.dataset}/${files.reports}/${item.stage}-${item.model_name}.csv
  #     -o ${item.dataset}/plots/clean_${item.stage}-${item.model_name}.csv
  #     -c conf/clean.yaml
  #   outs:
  #     - ${item.dataset}/plots/clean_${item.stage}-${item.model_name}.csv
  # plot:
  #   matrix:
  #     dataset : [kdd_nsl, truthseeker]
  #     model_name : [gzip_classifier]
  #     stage : [train]
  #   cmd: >-
  #     python -m deckard.layers.plots --path ${item.dataset}/plots/ --file ${item.dataset}/plots/clean_${item.stage}-${item.model_name}.csv -c conf/plots.yaml
  #   deps:
  #     - ${item.dataset}/plots/clean_${item.stage}-${item.model_name}.csv
  #   plots:
  #     - ${item.dataset}/plots/${line_plot[0].file}
  #     - ${item.dataset}/plots/${line_plot[1].file}
  #     - ${item.dataset}/plots/${line_plot[2].file}
  #     - ${item.dataset}/plots/${line_plot[3].file}
  #     - ${item.dataset}/plots/${line_plot[4].file}
  #     - ${item.dataset}/plots/${line_plot[5].file}
  #   params:
  #     - conf/plots.yaml:
  #         - line_plot
  ##############################################################################
  # attack_optimise:
  #   cmd: python -m deckard.layers.optimise +stage=attack +optimizers=adv_accuracy model=best --multirun --config-name attack
  #   deps:
  #   - ${files.directory}/${files.data_dir}/${files.data_file}${files.data_type}
  #   - ${files.directory}/${files.model_dir}/${files.model_file}${files.model_type}
  #   - conf/model/best.yaml
  #   outs:
  #   - attack.db
  #   params:
  #   - conf/attack.yaml:
  #     - hydra
  # find_best_attack:
  #   cmd: python -m deckard.layers.find_best attack.yaml
  #   deps:
  #   - attack.db
  #   outs:
  #   - conf/attack/best.yaml
