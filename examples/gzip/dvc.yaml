vars:
  - conf/default.yaml:hydra
  - conf/plots.yaml:line_plot
  - conf/plots.yaml:cat_plot
  # - conf/condensed_plots.yaml:line_plot
  # - conf/clean.yaml:params
  # - conf/clean.yaml:fillna
  - conf/clean.yaml:replace
stages:
  ##############################################################################
  # These stages use the dvc API to run a single experiment at a time using a
  # deckard.Experiment object. This parses this file, saves the default hydra configuration
  # to params.yaml, and then runs the experiment with the given parameters.
  # This can be used to define a stage that runs a single experiment, or a stage for the
  # optimisation using the optimise.py script and the hydrasweeper API. This API is primarily used for
  # development and testing, as it is easier to run a single experiment at a time and debug it using
  # DVC's git-like features to track changes and minimise run time. 

  # This stage will parse the conf/default.yaml file and save it to params.yaml
  # In addition, it will define a schema stage that will will 
  # 1. Determine the file paths for the data and model files (if specified)
  # 2. Run the experiment with the given parameters
  # 3. Save the results to the given file paths (will always save a score_dict_file, and a params_file to files.directory/files.reports/stage/)
  # 4. Save a 'params.yaml' file with the scores (Always)
  # 5. Save the predictions to the given file paths (if specified)
  # 6. Save the probabilities to the given file paths (if specified)
  # 7. Save the (final) losses to the given file paths (if specified)
  # 8. Save the train/test labels to the given file paths (if specified)

  # You can arbitrarily define parameters in the 'conf' folder.
  # To parse the parameters, you can use the 'hydra' API to define a schema for the parameters
  # Or run `deckard.layers.parse` to parse the parameters and save them to a file.  
  ##############################################################################
  data:
    desc: "This stage will parse the conf/default.yaml file and save it to params.yaml"
    cmd: python data_prep.py
    outs:
      - raw_data/
    deps:
      - data_prep.py
  parse_params:
    cmd: python -m deckard.layers.parse
    deps:
      - conf/default.yaml
      - conf/data/default.yaml
      - conf/model/default.yaml
      - conf/files/default.yaml
      - conf/scorers/default.yaml
    outs:
      - params.yaml:
          cache: true
          desc : "Parsed parameters for the experiment"
          persist: true
          push : true
  
  train:
    cmd: python -m deckard.layers.experiment train
    metrics:
    - ${files.directory}/${files.reports}/train/${files.name}/${files.score_dict_file}
    outs:
    - ${files.directory}/${files.reports}/train/${files.name}/${files.predictions_file}
    params:
    - data
    - model
    - scorers
    - files
    - dataset
    - model_name
    - device_id
    deps:
    - params.yaml
    - raw_data/ # Raw data
  ##############################################################################
  grid_search:
    matrix: 
      train_size: [20, 100,  300, 500] #  
      dataset : [ddos, kdd_nsl, sms_spam, truthseeker] # 
      configs: [gzip_knn, gzip_logistic, gzip_svc] 
      symmetric : [True, False]
      # model.init.metric : [gzip, lzma, bz2, pkl, zstd, levenshtein, ratio, hamming, jaro, jaro_winkler, seqratio]
    cmd: >-
      python -m deckard.layers.optimise
      stage=train
      data=${item.dataset}
      dataset=${item.dataset}
      data.sample.train_size=${item.train_size}
      data.sample.test_size=100
      model_name=${item.configs}
      model.init.distance_matrix=null
      model.init.symmetric=${item.symmetric}
      hydra.sweeper.study_name=${item.configs}_${item.dataset}
      hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8
      hydra.sweep.dir=${item.dataset}/logs/${item.configs}/${item.train_size}/symmetry_${item.symmetric}
      hydra.callbacks.study_dump.output_file=${item.dataset}/logs/${item.configs}/${item.train_size}/study.csv
      files.directory=${item.dataset}
      files.reports=${files.reports}/${item.configs}/${item.train_size}/symmetry_${item.symmetric}
      hydra.launcher.n_jobs=-1
      ++data.sample.random_state=1,2,3,4,5,6,7,8,9,10
      model.init.metric=gzip,lzma,bz2,pkl,zstd,levenshtein,ratio,hamming,jaro,jaro_winkler,seqratio
      ++raise_exception=True               
      --config-name ${item.configs}
      --multirun
    # ++model.init.metric=${item.metric}
    deps:
      - params.yaml
      - conf/${item.configs}.yaml
    outs:
        # - ${item.dataset}/logs/${item.configs}/${item.train_size}/symmetry_${item.symmetric}/${item.metric}/train/
        - ${item.dataset}/logs/${item.configs}/${item.train_size}/symmetry_${item.symmetric}:
            cache: true
            persist: true
            push: true
        # - ${item.dataset}/${files.reports}/${item.configs}/${item.train_size}/symmetry_${item.symmetric}/${item.metric}/train/
        - ${item.dataset}/${files.reports}/${item.configs}/${item.train_size}/symmetry_${item.symmetric}/train/:
            cache: true
            persist: true
            push: true
    params:
      - conf/${item.configs}.yaml:
          - hydra
  ##############################################################################
  # find_best_model: # This isn't actually used in later steps, but it's handy to have these configs ready for a line search instead of a massive grid search
  #   matrix:
  #     dataset : [ddos, kdd_nsl, sms_spam,] #  
  #     model : [gzip_knn, gzip_svc, gzip_logistic]
  #   deps:
  #     - ${item.dataset}/logs/${item.model}/
  #   cmd: >-
  #        python -m deckard.layers.find_best --storage sqlite:///optuna.db --study_name ${item.model}_${item.dataset} --config_subdir model --params_file best_${item.model}_${item.dataset} --default_config ${item.model}
  #   outs:
  #     - conf/model/best_${item.model}_${item.dataset}.yaml
  ##############################################################################
  precompute_matrices:
    matrix:
      dataset : [ddos,  kdd_nsl, truthseeker, sms_spam,] # kdd_nsl, truthseeker, sms_spam, 
      model_name : [knn, svc, logistic]
      metric : [gzip] #, lzma, bz2, pkl, zstd, levenshtein, ratio, hamming, jaro, jaro_winkler, seqratio]
      symmetric : [True, False]
    deps:
      - params.yaml
      - conf/condense_${item.model_name}.yaml
      - ${item.dataset}/${files.reports}/gzip_${item.model_name}/ #Ensures that this runs after the grid_search
    cmd: >-
      python -m deckard.layers.optimise
      stage=train
      data=${item.dataset}
      dataset=${item.dataset}
      data.sample.train_size=1000
      data.sample.test_size=400
      model_name=gzip_${item.model_name}
      model=gzip_${item.model_name}
      ++model.init.m=1
      files.directory=${item.dataset}
      hydra.sweeper.study_name=gzip_${item.model_name}_${item.dataset}
      files.reports=${files.reports}/condense/${item.model_name}/${item.metric}/symmetry_${item.symmetric}/
      hydra.sweeper.n_trials=1
      hydra.sweeper.n_jobs=1
      hydra.sweep.dir=${item.dataset}/logs/precompute/${item.model_name}/${item.metric}/symmetry_${item.symmetric}/
      hydra.callbacks.study_dump.output_file=${item.dataset}/logs/${item.model_name}/${item.metric}/symmetry_${item.symmetric}/study.csv
      hydra.launcher.n_jobs=-1
      ++model.init.distance_matrix=${item.dataset}/models/${item.model_name}/${item.metric}/symmetry_${item.symmetric}/1000-400-0.npz 
      ~hydra.callbacks.study_dump
      --config-name condense_${item.model_name}
      --multirun
    outs:
      - ${item.dataset}/logs/precompute/${item.model_name}/${item.metric}/symmetry_${item.symmetric}:
          cache: true
          persist: true
          push: true
      - ${item.dataset}/models/${item.model_name}/${item.metric}/symmetry_${item.symmetric}/:
          cache: true
          persist: true
          push: true
    params:
      - conf/condense.yaml:
          - hydra
  ############################################################################## 
  condense:
    matrix:
      dataset : [ddos,  kdd_nsl, truthseeker, sms_spam,] # kdd_nsl, truthseeker, sms_spam, 
      model_name : [knn, svc, logistic]
      ratio : [.9, .8, .7, .6, .5, .4, .3, .2, .1]
      metric : [gzip] #, lzma, bz2, pkl, zstd, levenshtein, ratio, hamming, jaro, jaro_winkler, seqratio]
      symmetric : [True, False]
    deps:
      - params.yaml
      - conf/condense_${item.model_name}.yaml
      - ${item.dataset}/models/${item.model_name}/${item.metric}/ #Ensures that this runs after the grid_search
    cmd: >-
      python -m deckard.layers.optimise
      stage=train
      data=${item.dataset}
      dataset=${item.dataset}
      data.sample.train_size=1000
      data.sample.test_size=400
      model_name=${item.model_name}
      model=gzip_${item.model_name}
      ++model.init.m=${item.ratio}
      files.directory=${item.dataset}
      ++model.init.distance_matrix=${item.dataset}/models/${item.model_name}/${item.metric}/symmetry_${item.symmetric}/1000-400-0.npz
      hydra.sweeper.study_name=gzip_${item.model_name}_${item.dataset}
      files.reports=${files.reports}/condense/${item.model_name}/${item.metric}/${item.ratio}/symmetry_${item.symmetric}/
      hydra.sweeper.n_trials=128
      hydra.sweeper.n_jobs=8
      hydra.sweep.dir=${item.dataset}/logs/condense/${item.model_name}/${item.metric}/${item.ratio}/symmetry_${item.symmetric}/
      hydra.callbacks.study_dump.output_file=${item.dataset}/logs/${item.model_name}/${item.metric}/${item.ratio}/symmetry_${item.symmetric}/study.csv
      hydra.launcher.n_jobs=-1
      --config-name condense_${item.model_name}
      --multirun
    outs:
      - ${item.dataset}/logs/condense/${item.model_name}/${item.metric}/${item.ratio}/symmetry_${item.symmetric}/:
          cache: true
          persist: true
          push: true
    params:
      - conf/condense_${item.model_name}.yaml:
          - hydra
  compile:
    matrix:
      dataset : [kdd_nsl, sms_spam, ddos, truthseeker]
      stage : [gzip_knn, gzip_svc, gzip_logistic, condense/knn, condense/svc, condense/logistic]
    deps:
      - ${item.dataset}/${files.reports}/${item.stage}/
    outs:
    - ${item.dataset}/${files.reports}/${item.stage}.csv
    cmd: >-
     python -m deckard.layers.compile 
     --report_folder ${item.dataset}/${files.reports}/${item.stage} 
     --results_file ${item.dataset}/${files.reports}/${item.stage}.csv
  ##############################################################################
  clean:
    matrix:
      dataset : [kdd_nsl, sms_spam, ddos, truthseeker]
      stage : [gzip_knn, gzip_svc, gzip_logistic, condense/knn, condense/svc, condense/logistic]
    deps:
      - ${item.dataset}/${files.reports}/${item.stage}.csv
    cmd: >-
      python -m deckard.layers.clean_data 
      -i ${item.dataset}/${files.reports}/${item.stage}.csv
      -o ${item.dataset}/plots/clean/${item.stage}.csv
      -c conf/clean.yaml
    outs:
      - ${item.dataset}/plots/clean/${item.stage}.csv
    params:
      - conf/clean.yaml:
        - replace
        - drop_values
        - replace_cols
  ##############################################################################
  merge:
    matrix:
      dataset : [kdd_nsl, sms_spam, ddos, truthseeker]
    deps:
      - ${item.dataset}/plots/clean/gzip_knn.csv
      - ${item.dataset}/plots/clean/gzip_logistic.csv
      - ${item.dataset}/plots/clean/gzip_svc.csv
    cmd: >-
      python merge.py
      --big_dir ${item.dataset}/plots/
      --data_file clean/gzip_knn.csv
      --little_dir_data_file clean/gzip_logistic.csv clean/gzip_svc.csv
      --output_folder ${item.dataset}/plots
      --output_file merged.csv
    outs:
      - ${item.dataset}/plots/merged.csv
  ##############################################################################
  merge_condense:
    matrix:
      dataset : [kdd_nsl, sms_spam, ddos, truthseeker]
    deps:
      - ${item.dataset}/plots/clean/condense/knn.csv
      - ${item.dataset}/plots/clean/condense/logistic.csv
      - ${item.dataset}/plots/clean/condense/svc.csv
    cmd: >-
      python merge.py
      --big_dir ${item.dataset}/plots/
      --data_file clean/condense/knn.csv
      --little_dir_data_file  clean/condense/logistic.csv clean/condense/svc.csv
      --output_folder ${item.dataset}/plots/
      --output_file condensed_merged.csv
    outs:
      - ${item.dataset}/plots/condensed_merged.csv
  ##############################################################################
  plot:
    matrix:
      dataset : [kdd_nsl, sms_spam, ddos, truthseeker]
    cmd: >-
      python -m deckard.layers.plots 
      --path ${item.dataset}/plots/ 
      --file ${item.dataset}/plots/merged.csv 
      -c conf/plots.yaml
    deps:
      - ${item.dataset}/plots/merged.csv
      - conf/plots.yaml
    plots:
      - ${item.dataset}/plots/${line_plot[0].file}
      - ${item.dataset}/plots/${line_plot[1].file}
      - ${item.dataset}/plots/${line_plot[2].file}
      - ${item.dataset}/plots/${cat_plot[0].file}
      - ${item.dataset}/plots/${cat_plot[1].file}
      - ${item.dataset}/plots/${cat_plot[2].file}
      - ${item.dataset}/plots/${cat_plot[3].file}
      - ${item.dataset}/plots/${cat_plot[4].file}
    params:
      - conf/plots.yaml:
          - line_plot
          - cat_plot
  ##############################################################################
  plot_condense:
    matrix:
      dataset : [kdd_nsl, sms_spam, ddos, truthseeker]
    cmd: >-
      python -m deckard.layers.plots 
      --path ${item.dataset}/plots/ 
      --file ${item.dataset}/plots/condensed_merged.csv 
      -c conf/condensed_plots.yaml
    deps:
      - ${item.dataset}/plots/condensed_merged.csv
      - conf/condensed_plots.yaml
    plots:
      - ${item.dataset}/plots/condensing_method_vs_accuracy.pdf
      - ${item.dataset}/plots/condensing_method_vs_train_time.pdf
      - ${item.dataset}/plots/condensing_method_vs_predict_time.pdf
    params:
      - conf/condensed_plots.yaml:
          - cat_plot
  ##############################################################################
  merge_datasets:
    cmd: >-
      python merge.py
      --big_dir .
      --little_dir .
      --data_file sms_spam/plots/merged.csv
      --little_dir_data_file  kdd_nsl/plots/merged.csv ddos/plots/merged.csv truthseeker/plots/merged.csv kdd_nsl/plots/condensed_merged.csv ddos/plots/condensed_merged.csv truthseeker/plots/condensed_merged.csv sms_spam/plots/condensed_merged.csv
      --output_folder combined/plots/
      --output_file merged.csv
    deps:
      - sms_spam/plots/merged.csv
      - kdd_nsl/plots/merged.csv
      - ddos/plots/merged.csv
      - truthseeker/plots/merged.csv
    outs:
      - combined/plots/merged.csv
  ##############################################################################
  plot_merged:
    cmd: >-
      python -m deckard.layers.plots 
      --path combined/plots/ 
      --file combined/plots/merged.csv 
      -c conf/merged_plots.yaml
    deps:
      - combined/plots/merged.csv
      - conf/merged_plots.yaml
    plots:
      - combined/plots/compressor_metric_vs_accuracy.pdf
      - combined/plots/compressor_metric_vs_train_time.pdf
      - combined/plots/compressor_metric_vs_predict_time.pdf
      - combined/plots/string_metric_vs_accuracy.pdf
      - combined/plots/string_metric_vs_train_time.pdf
      - combined/plots/string_metric_vs_predict_time.pdf
      - combined/plots/symmetric_models_vs_accuracy.pdf
      - combined/plots/symmetric_models_vs_train_time.pdf
      - combined/plots/symmetric_models_vs_predict_time.pdf
      - combined/plots/condensing_methods_vs_accuracy.pdf
      - combined/plots/condensing_methods_vs_train_time.pdf
      - combined/plots/condensing_methods_vs_predict_time.pdf
      - combined/plots/models_vs_accuracy.pdf
      - combined/plots/models_vs_train_time.pdf
      - combined/plots/models_vs_predict_time.pdf
    params:
      - conf/merged_plots.yaml:
          - cat_plot
      - conf/merged_plots.yaml:
          - line_plot
  copy:
    matrix:
      dataset : [kdd_nsl, truthseeker, sms_spam, ddos, combined]
    cmd: >-
      rm -rf ~/Gzip-KNN/figs/${item.dataset}/ &&
      mkdir -p ~/Gzip-KNN/figs/${item.dataset}/ &&
      cp -r ${item.dataset}/plots/* ~/Gzip-KNN/figs/${item.dataset}/ &&
      rm -rf ~/Gzip-KNN/figs/${item.dataset}/.gitignore
    deps:
      - ${item.dataset}/plots/
  # ##############################################################################
  # # attack:
  # #   cmd: python -m deckard.layers.experiment attack
  # #   deps:
  # #   - ${files.directory}/${files.data_dir}/${files.data_file}${files.data_type}
  # #   - ${files.directory}/${files.model_dir}/${files.model_file}${files.model_type}
  # #   metrics:
  # #   - ${files.directory}/${files.reports}/attack/${files.name}/${files.score_dict_file}
  # #   outs:
  # #   - ${files.directory}/${files.reports}/attack/${files.name}/${files.adv_probabilities_file}
  # #   params:
  # #   - data
  # #   - model
  # #   - attack
  # #   - scorers
  # #   - files
  # ##############################################################################
  # # attack_optimise:
  # #   cmd: python -m deckard.layers.optimise +stage=attack +optimizers=adv_accuracy model=best --multirun --config-name attack
  # #   deps:
  # #   - ${files.directory}/${files.data_dir}/${files.data_file}${files.data_type}
  # #   - ${files.directory}/${files.model_dir}/${files.model_file}${files.model_type}
  # #   - conf/model/best.yaml
  # #   outs:
  # #   - attack.db
  # #   params:
  # #   - conf/attack.yaml:
  # #     - hydra
  # # find_best_attack:
  # #   cmd: python -m deckard.layers.find_best attack.yaml
  # #   deps:
  # #   - attack.db
  # #   outs:
  # #   - conf/attack/best.yaml
