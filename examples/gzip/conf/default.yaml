defaults:
    # - _target_ : deckard.base.experiment.Experiment
    - _self_
    - data: kdd_nsl
    - model: gzip_classifier
    - files: default
    - scorers: default
    - override hydra/sweeper : optuna
    - override hydra/sweeper/sampler : tpe
    - override hydra/launcher : joblib
dataset : kdd_nsl
model_name : gzip_classifier
stage : train
direction : 
  - maximize
optimizers: 
   - accuracy
device_id : ${oc.env:DECKARD_DEVICE_ID, "cpu"}
hydra:
  run:
    dir: ${files.directory}/logs/${stage}/
  sweep:
    dir: ${files.directory}/logs/
    subdir : ${hydra.sweeper.study_name}/${hydra.job.num}
  sweeper:
    sampler:
      _target_: optuna.samplers.TPESampler
    _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
    study_name: ${model_name}_${dataset}
    storage: sqlite:///optuna.db
    n_jobs: 128
    n_trials : ???
    params:
      # I'm optimizing inside the dvc.yaml in stages to reduce the search space and run-time
      # You can enable these to optimize over the entire space
      # model.init.k : int(1,3,5,7,11)
      # model.init.m : int(10, 20, 50, 100, 200, 500, 1000)
      # model.init.method : choice("random", "svc", "medoid", "sum")
      # model.init.compressor : choice("gzip", "lzma", "zstd", "pkl")
    direction: ${direction}
  launcher:
    _target_: hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher
    n_jobs: -1
    prefer : processes
    verbose: 1
    timeout: null
    pre_dispatch: n_jobs
    batch_size: auto
    temp_folder: /tmp/deckard
    max_nbytes: 100000
    mmap_mode: r
